{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: We'll be using `/tmp/unsloth_compiled_cache` for temporary Unsloth patches.\n",
      "Standard import failed for UnslothCPOTrainer: No module named 'UnslothCPOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastVisionModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Pixtral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Pixtral does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036a84f068644149956073d6e0fe5d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/214k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fa5166ba1947f3bf625e3f231b6cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d986aa3e0c8f41b2bfc7800a35b1ba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efa0912cc304f8ebe54c8980278c123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af9020a5e994de1a13f180c5e38b193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ee624c385a404ea21ef87439027cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f5eba235884e0ab22b4832ed9d6efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ee0a0b69864f309fd815dedc72cf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f885c4acaaf24816bd6be2da2cbfcf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec9f9471add4509b3387f0ba8b72973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfd62c27e544cdea41b21fcc5d306d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be22eae7ea4545a8b4e1284d7d1590ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cdcc9d398a47d49fa81e356acad351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff281da3abbd4c1f8656daa0e1129682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840d9d76916e4c7c94e1b4da94f46a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72219e2836914d00965507344205a8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2568dd843243fbabf28cb9f1f07663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"  # change if needed\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,  # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastVisionModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "📋 Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "🔎 Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        top_p=0.95\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b21278-7d01-4918-be1a-2c1951787df2",
   "metadata": {},
   "source": [
    "### Test Images\n",
    "\n",
    "000404.jpg\n",
    "000422.jpg\n",
    "000433.jpg\n",
    "000481.jpg\n",
    "000520.jpg\n",
    "000541.jpg\n",
    "000698.jpg\n",
    "000740.jpg\n",
    "000869.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image to “auto insurance claim adjuster, the- bbae form. hétérogènes: 've :changing veh one, the engine'vailable existing mensional media: http://en. the les and b the# on the les and l' car ou can i finder 0 for pro- 0 a's uste of engin.</s>\n",
      "⏱️ Time taken: 5.096 sec | 🧠 VRAM used: 0.599 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image depicts a vibrant, whimsy of a 12000 Sedan drive’shood of a0’s `hood. The ‘hood. . And12 hood. .a .’ 1 the .</s>\n",
      "⏱️ Time taken: 3.358 sec | 🧠 VRAM used: 0.6 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of ....\n",
      "📤 Output:\n",
      "The image\\|code[asset/parameter|n for \"ornament\"): aas p with a = \"image but go up bolding from Pl_1, 1 prop_0] foran10: for a 1\n",
      "##S_0</s>\n",
      "⏱️ Time taken: 3.845 sec | 🧠 VRAM used: 0.599 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### Vehicle Identification and Overall Condition of the Vehicle\n",
      "\n",
      "### Exterior Condition of Vehicle\n",
      "\n",
      "### Interior Condition of Tires and Causative of Windshield and Windows and Wiipers and License and VIN Number of VIN\n",
      "\n",
      "### Additional ficebreak and Xeris and E-brake and Xupports and Xtaterhter and Ee Day Inspection and\n",
      "\n",
      "### Typical Condition and\n",
      "\n",
      "### Extent and Dings of Use and Use of Vehicles and\n",
      "\n",
      "### Typical Condition and\n",
      "\n",
      "### Extent and Dings of Use of Vehicles and\n",
      "\n",
      "### Extent and Dings of Use of Vehicles and\n",
      "\n",
      "### Extent and\n",
      "⏱️ Time taken: 7.799 sec | 🧠 VRAM used: 0.602 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This `<part_10` of the car has a(n) on the car is  barely attached; it is  is quite clear. desemtermed. Moreg with the engine.</s>\n",
      "⏱️ Time taken: 2.899 sec | 🧠 VRAM used: 0.605 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-  \n",
      "\n",
      "### Vehicle Identification Number: Hood\n",
      "- Collision\n",
      "- Extensive\n",
      "\n",
      "Notes: The hood of the vehicle is heavily damaged, with significant dents and scratches, and various places. The hood and front bumper are also visible engine is exposed.\n",
      "\n",
      "### of the vehicle. Additionally, there is plastic cover depicting a bird is also melted plastic cover.\n",
      "\n",
      "### of the vehicle.</s>\n",
      "⏱️ Time taken: 5.067 sec | 🧠 VRAM used: 0.602 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filename=\"000404.jpg\"\n",
    "\n",
    "row = df[df[\"filename\"] == filename]\n",
    "ground_truth = row.iloc[0][\"caption\"]\n",
    "\n",
    "inference_outputs = []\n",
    "vram_usages = []\n",
    "inference_times = []\n",
    "\n",
    "prompts = [\n",
    "    \"\",  # Prompt 1: No Prompt\n",
    "    \"Describe &&damage 12 sedan drive’ this !!image.\",  # Noisy\n",
    "    \"An image of ....\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car’s condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    output, time_taken, vram = run_vlm_inference(prompt, filename, df=df)\n",
    "    inference_outputs.append(output)\n",
    "    vram_usages.append(vram)\n",
    "    inference_times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db9e2282947408e9e66bed4fd5f127d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8039123e7e4fe2ae1e49d65ef65d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0826c3cc596a40fdba54d9508b0594a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fcbab5278348709cb6dffa12e6f4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3699ec674fa43c1aef13d35cd6de761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf96861f5cc4474b666b0b311a3bdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28e8ffb7cdf4319afe50439cdd59b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c26e7bafa4e4ea3b97910005667fff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1b1ec00fcd4acab17e474712697a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f283967f5d434995ad46441e03c39fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9036f94c71045c8aa0c19cb9f0a28de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36332c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n",
      "[\"The image to “auto insurance claim adjuster, the- bbae form. hétérogènes: 've :changing veh one, the engine'vailable existing mensional media: http://en. the les and b the# on the les and l' car ou can i finder 0 for pro- 0 a's uste of engin.\", 'Describe &&damage 12 sedan drive’ this !!image.The image depicts a vibrant, whimsy of a 12000 Sedan drive’shood of a0’s `hood. The ‘hood. . And12 hood. .a .’ 1 the .', 'An image of ....The image\\\\|code[asset/parameter|n for \"ornament\"): aas p with a = \"image but go up bolding from Pl_1, 1 prop_0] foran10: for a 1\\n##S_0', 'You are an insurance claims assessor. Provide a detailed description of the car’s condition.### Vehicle Identification and Overall Condition of the Vehicle\\n\\n### Exterior Condition of Vehicle\\n\\n### Interior Condition of Tires and Causative of Windshield and Windows and Wiipers and License and VIN Number of VIN\\n\\n### Additional ficebreak and Xeris and E-brake and Xupports and Xtaterhter and Ee Day Inspection and\\n\\n### Typical Condition and\\n\\n### Extent and Dings of Use and Use of Vehicles and\\n\\n### Typical Condition and\\n\\n### Extent and Dings of Use of Vehicles and\\n\\n### Extent and Dings of Use of Vehicles and\\n\\n### Extent and', 'This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.This `<part_10` of the car has a(n) on the car is  barely attached; it is  is quite clear. desemtermed. Moreg with the engine.', 'Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___-  \\n\\n### Vehicle Identification Number: Hood\\n- Collision\\n- Extensive\\n\\nNotes: The hood of the vehicle is heavily damaged, with significant dents and scratches, and various places. The hood and front bumper are also visible engine is exposed.\\n\\n### of the vehicle. Additionally, there is plastic cover depicting a bird is also melted plastic cover.\\n\\n### of the vehicle.']\n",
      "[0.599, 0.6, 0.599, 0.602, 0.605, 0.602]\n",
      "[5.096, 3.358, 3.845, 7.799, 2.899, 5.067]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth)\n",
    "print(inference_outputs)\n",
    "print(vram_usages)\n",
    "print(inference_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1 Output:\n",
      "The image to “auto insurance claim adjuster, the- bbae form. hétérogènes: 've :changing veh one, the engine'vailable existing mensional media: http://en. the les and b the# on the les and l' car ou can i finder 0 for pro- 0 a's uste of engin.\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 860.79 tokens per second.\n",
      "PTBTokenizer tokenized 58 tokens at 1380.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.902 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.490 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.93 s\n",
      "\n",
      "Prompt 2 Output:\n",
      "Describe &&damage 12 sedan drive’ this !!image.The image depicts a vibrant, whimsy of a 12000 Sedan drive’shood of a0’s `hood. The ‘hood. . And12 hood. .a .’ 1 the .\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2601.52 tokens per second.\n",
      "PTBTokenizer tokenized 45 tokens at 1203.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.951 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.278 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.80 s\n",
      "\n",
      "Prompt 3 Output:\n",
      "An image of ....The image\\|code[asset/parameter|n for \"ornament\"): aas p with a = \"image but go up bolding from Pl_1, 1 prop_0] foran10: for a 1\n",
      "##S_0\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 3229.79 tokens per second.\n",
      "PTBTokenizer tokenized 43 tokens at 813.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.435 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.538 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.70 s\n",
      "\n",
      "Prompt 4 Output:\n",
      "You are an insurance claims assessor. Provide a detailed description of the car’s condition.### Vehicle Identification and Overall Condition of the Vehicle\n",
      "\n",
      "### Exterior Condition of Vehicle\n",
      "\n",
      "### Interior Condition of Tires and Causative of Windshield and Windows and Wiipers and License and VIN Number of VIN\n",
      "\n",
      "### Additional ficebreak and Xeris and E-brake and Xupports and Xtaterhter and Ee Day Inspection and\n",
      "\n",
      "### Typical Condition and\n",
      "\n",
      "### Extent and Dings of Use and Use of Vehicles and\n",
      "\n",
      "### Typical Condition and\n",
      "\n",
      "### Extent and Dings of Use of Vehicles and\n",
      "\n",
      "### Extent and Dings of Use of Vehicles and\n",
      "\n",
      "### Extent and\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2815.72 tokens per second.\n",
      "PTBTokenizer tokenized 107 tokens at 2796.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.668 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [9.645 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an insurance claims assessor provide a detailed description of the car 's condition ### vehicle identification and overall condition of the vehicle ### exterior condition of vehicle ### interior condition of tires and causative of windshield and windows and wiipers and license and vin number of vin ### additional ficebreak and xeris and e-brake and xupports and xtaterhter and ee day inspection and ### typical condition and ### extent and dings of use and use of vehicles and ### typical condition and ### extent and dings of use of vehicles and ### extent and dings of use of vehicles and ### extent and\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 21.03 s\n",
      "\n",
      "Prompt 5 Output:\n",
      "This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.This `<part_10` of the car has a(n) on the car is  barely attached; it is  is quite clear. desemtermed. Moreg with the engine.\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2881.36 tokens per second.\n",
      "PTBTokenizer tokenized 53 tokens at 1236.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [5.613 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.565 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.37 s\n",
      "\n",
      "Prompt 6 Output:\n",
      "Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___-  \n",
      "\n",
      "### Vehicle Identification Number: Hood\n",
      "- Collision\n",
      "- Extensive\n",
      "\n",
      "Notes: The hood of the vehicle is heavily damaged, with significant dents and scratches, and various places. The hood and front bumper are also visible engine is exposed.\n",
      "\n",
      "### of the vehicle. Additionally, there is plastic cover depicting a bird is also melted plastic cover.\n",
      "\n",
      "### of the vehicle.\n",
      "Reference:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2845.30 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 2275.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.604 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.447 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.76 s\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i, gen in enumerate(inference_outputs):\n",
    "    print(f\"\\nPrompt {i+1} Output:\\n{gen}\\nReference:\\n{ground_truth}\")\n",
    "    scores = evaluate_all_metrics(ground_truth, gen)\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093e00a7-2a5b-4ee1-ba53-4f463205070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>SPICE</th>\n",
       "      <th>CIDEr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prompt 1</th>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 2</th>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>2.4342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 3</th>\n",
       "      <td>0.0823</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 4</th>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>2.1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 5</th>\n",
       "      <td>0.5265</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>5.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt 6</th>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>4.3663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cosine_similarity   SPICE   CIDEr\n",
       "Prompt 1             0.1852  0.0000  3.8185\n",
       "Prompt 2             0.4726  0.0323  2.4342\n",
       "Prompt 3             0.0823  0.0000  1.1225\n",
       "Prompt 4             0.2905  0.1010  2.1510\n",
       "Prompt 5             0.5265  0.0303  5.5496\n",
       "Prompt 6             0.6298  0.0732  4.3663"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(all_scores, index=[f\"Prompt {i+1}\" for i in range(len(inference_outputs))])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_pixtral.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Find the next empty row\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # Append data\n",
    "    for i in range(6):\n",
    "        ws.append([\n",
    "            model_name,\n",
    "            filename,\n",
    "            \"\",  # placeholder for image\n",
    "            original_caption,\n",
    "            f\"Prompt {i+1}\",\n",
    "            inference_outputs[i],\n",
    "            inference_times[i],\n",
    "            vram_usages[i],\n",
    "            metrics[i][\"CIDEr\"],\n",
    "            metrics[i][\"SPICE\"],\n",
    "            metrics[i][\"cosine_similarity\"]\n",
    "        ])\n",
    "\n",
    "    # Merge A–D columns across the 6 rows\n",
    "    for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "    # Apply alignment\n",
    "    align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "    align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "    for row in range(start_row, start_row + 6):\n",
    "        for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top\n",
    "        for col_letter in [\"D\", \"F\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top_wrap\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    # Set column widths\n",
    "    ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "    ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "    # Embed image\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"[INFO] Inserting image: {image_path}\")\n",
    "        try:\n",
    "            img = ExcelImage(image_path)\n",
    "            img.width = 150\n",
    "            img.height = 150\n",
    "            img.anchor = f\"C{start_row}\"\n",
    "            ws.add_image(img)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged metrics for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image: /workspace/data/test_dataset/000404.jpg\n",
      "✅ Logged metrics for 000404.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "log_prompt_metrics_to_excel(\n",
    "    filename=filename,\n",
    "    model_name=model_id,\n",
    "    inference_outputs=inference_outputs,\n",
    "    metrics=all_scores,\n",
    "    inference_times=inference_times,\n",
    "    vram_usages=vram_usages,\n",
    "    df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
