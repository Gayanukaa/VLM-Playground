{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: We'll be using `/tmp/unsloth_compiled_cache` for temporary Unsloth patches.\n",
      "Standard import failed for UnslothBCOTrainer: No module named 'UnslothBCOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d39b1f2-179f-4fcd-b60e-dda5a1a6ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgayanukaa\u001b[0m (\u001b[33mvlm-research\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250525_060638-geb148cc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc' target=\"_blank\">Prompt-Eval-Pixtral12B-CarDD</a></strong> to <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x749cb4400b20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Prompting-Experiments\",\n",
    "    name=\"Prompt-Eval-Pixtral12B-CarDD\",\n",
    "    group=\"prompting-experiments\",\n",
    "    tags=[\"pixtral\", \"image-captioning\", \"prompting\", \"cardamage\"],\n",
    "    notes=\"Comparing handcrafted prompting strategies across multiple images and prompt types.\",\n",
    "    config={\n",
    "        \"model\": \"unsloth/Pixtral-12B-2409\",\n",
    "        \"prompting\": \"handcrafted\",\n",
    "        \"num_prompts\": 6,\n",
    "        \"num_runs_per_prompt\": 2,\n",
    "        \"dataset\": \"cardd\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Llava patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Llava does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4553e783ed48d38ad967985c7a4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/214k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400b51cffa3749b781f92ba47d621c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f1ab9ffcf64748be9b20ace8d0fc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c108abee30948c59a4c86aa510a52f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebc7a6dd8cc4812915dde958bd262f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949c4e54abca4a97a9df58c81a16f09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159b21efd3e14b15a865dbecf0c042b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5b33bd1a71483cb3f0dac2e1f4ac09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d38c1109ea41f49b523ed035c58a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b96a4765f254585b51379d26792b6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bad6bb5b81405daa71da583b4297af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129565afc9dc4a02a5ed8ee32b6d711a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924279c4321e40afb6ada6c724602687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd633af179224c528d75bbdfb309d519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20da391454474bda88af82b7e5c12bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f81cea5728f4deabd28700ba11a7b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b531b6446b6a47a6b15b9e7123cc69e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "📋 Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "🔎 Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "    \n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running prompts for image: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The hood of the hood ornamelizabethada{,} 1\n",
      "\n",
      " ekst-–––whatever your browser or the chooser: the in unreal-est and `1lea ithisize myf5. of tI [on;).\n",
      "ose inth of theinns. Def    I- the the the the the the a ized14.</s>\n",
      "⏱️ Time taken: 5.873 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The hood of the hood ornamelizabethada{,} 1\n",
      "\n",
      " ekst-–––whatever your browser or the chooser: the in unreal-est and `1lea ithisize myf5. of tI [on;).\n",
      "ose inth of theinns. Def    I- the the the the the the a ized14.</s>\n",
      "⏱️ Time taken: 5.266 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash investigation as `'n s-argentinautilitiesseparated by intervening variable alexible. intervening vehicleceaonline-A only, worldwideize me toan 23. `u000emes to beenan 39Dadministration in7.</s>\n",
      "⏱️ Time taken: 3.913 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash investigation as `'n s-argentinautilitiesseparated by intervening variable alexible. intervening vehicleceaonline-A only, worldwideize me toan 23. `u000emes to beenan 39Dadministration in7.</s>\n",
      "⏱️ Time taken: 3.914 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car orv82120 in ublic Ar10 ingle International shippinginf one ear new windshield might seamlessly, &outhis canadaogg c & he\n",
      "ese are aith aith aith anuis aith an aith aith atabase\n",
      "```rahamp; h atask, out how many? I 'tvinely, ith an ith e, ith eith an ith eith an ith eith an ith eof ith an ith eof ith an ith eof ith aith ith eof ith a\n",
      "⏱️ Time taken: 7.829 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car orv82120 in ublic Ar10 ingle International shippinginf one ear new windshield might seamlessly, &outhis canadaogg c & he\n",
      "ese are aith aith aith anuis aith an aith aith atabase\n",
      "```rahamp; h atask, out how many? I 'tvinely, ith an ith e, ith eith an ith eith an ith eith an ith eof ith an ith eof ith an ith eof ith aith ith eof ith a\n",
      "⏱️ Time taken: 8.313 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###V\n",
      "(as plymouth\n",
      "\n",
      "**Subjective Overview of the car in excellent marketing strategy, the car\n",
      "\n",
      "### to ##Vehicle Overview of thefault , hi[united States.</s>\n",
      "⏱️ Time taken: 3.037 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###V\n",
      "(as plymouth\n",
      "\n",
      "**Subjective Overview of the car in excellent marketing strategy, the car\n",
      "\n",
      "### to ##Vehicle Overview of thefault , hi[united States.</s>\n",
      "⏱️ Time taken: 3.108 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is arial Incident After the car part in the  a��uki\n",
      " koncentrated the hood of the  ofte  of the aapplicable. The hood, you\"></s>\n",
      "⏱️ Time taken: 3.266 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is arial Incident After the car part in the  a��uki\n",
      " koncentrated the hood of the  ofte  of the aapplicable. The hood, you\"></s>\n",
      "⏱️ Time taken: 3.254 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-*- thel look like this repair. efektif(typeof̓s, 'he hood of ake the fender.</s>\n",
      "⏱️ Time taken: 2.213 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-*- thel look like this repair. efektif(typeof̓s, 'he hood of ake the fender.</s>\n",
      "⏱️ Time taken: 2.327 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The car;js: image byronaldenturies based on the manufacturer. efekt is the following aalian: image by n ad to be used with aade;\n",
      "    criteria of ake bility: afe, the ationg the a: he to see, ual of the a:</s>\n",
      "⏱️ Time taken: 5.03 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The car;js: image byronaldenturies based on the manufacturer. efekt is the following aalian: image by n ad to be used with aade;\n",
      "    criteria of ake bility: afe, the ationg the a: he to see, ual of the a:</s>\n",
      "⏱️ Time taken: 4.748 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash repair manual transmission seal kitten-speedily, showcases the front bumperfect, \\_ from scr image of ahs, with `*`1The car, with `12.! in the ize44 You`1.</s>\n",
      "⏱️ Time taken: 4.218 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The car crash repair manual transmission seal kitten-speedily, showcases the front bumperfect, \\_ from scr image of ahs, with `*`1The car, with `12.! in the ize44 You`1.</s>\n",
      "⏱️ Time taken: 4.175 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car crash repair, tooled[^1[^q(sicheckardeo, popular among:\n",
      "\n",
      "It seems the following myria, with `1. Me  see the 20.ivat for (or/Bf (ulan;s-oh,uc that $�he ith (or getAS string ican't. ican't ican even t:</s>\n",
      "⏱️ Time taken: 5.581 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car crash repair, tooled[^1[^q(sicheckardeo, popular among:\n",
      "\n",
      "It seems the following myria, with `1. Me  see the 20.ivat for (or/Bf (ulan;s-oh,uc that $�he ith (or getAS string ican't. ican't ican even t:</s>\n",
      "⏱️ Time taken: 5.83 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an overview from jobs inhan, Car crash scene, \n",
      "\n",
      "**Car parts store dothe car 3. Blade Runner was seriously, the 3. 3.</s>\n",
      "⏱️ Time taken: 2.87 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an overview from jobs inhan, Car crash scene, \n",
      "\n",
      "**Car parts store dothe car 3. Blade Runner was seriously, the 3. 3.</s>\n",
      "⏱️ Time taken: 2.867 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car accidents, the  as of the car [^(brakea\n",
      " „*CL  of the  the  sJunctions the  will be be be 'target=\"_ Due toĄ the you.\"n of the  be  of st the aay be to suh, the of da  or of da?</s>\n",
      "⏱️ Time taken: 4.887 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car accidents, the  as of the car [^(brakea\n",
      " „*CL  of the  the  sJunctions the  will be be be 'target=\"_ Due toĄ the you.\"n of the  be  of st the aay be to suh, the of da  or of da?</s>\n",
      "⏱️ Time taken: 4.855 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "1[^1[^m/li>\n",
      "> **is the context: Dent Dent; Front Bummary haveeba: Dentsdent into the f: d at the f: d the f: he Car Cracke: Dents: he hood: rst: he s: he hood: he hood: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he\n",
      "⏱️ Time taken: 8.161 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "1[^1[^m/li>\n",
      "> **is the context: Dent Dent; Front Bummary haveeba: Dentsdent into the f: d at the f: d the f: he Car Cracke: Dents: he hood: rst: he s: he hood: he hood: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he: he\n",
      "⏱️ Time taken: 7.826 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDallas, TXkdv15 Parrksledger is{matrix of a life the in odock, Nodeammolite// activehat, .., 1g:k ize F ithout theime: he, ithouthe > link ays of tage:</s>\n",
      "⏱️ Time taken: 4.332 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDallas, TXkdv15 Parrksledger is{matrix of a life the in odock, Nodeammolite// activehat, .., 1g:k ize F ithout theime: he, ithouthe > link ays of tage:</s>\n",
      "⏱️ Time taken: 4.602 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The provided a single-pane, this Wittels: \"severely, crashed itly the in2u2. thef/ that incorporate both addedS.  to the ardiovascular, 3. the lin time better the, S in way, gi? the 18,0 of the ole or a3. up befor (a ith a 'and whoe , a 'tems the are to a 't to been -4 eme s he ican't to a 'ov:</s>\n",
      "⏱️ Time taken: 6.913 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The provided a single-pane, this Wittels: \"severely, crashed itly the in2u2. thef/ that incorporate both addedS.  to the ardiovascular, 3. the lin time better the, S in way, gi? the 18,0 of the ole or a3. up befor (a ith a 'and whoe , a 'tems the are to a 't to been -4 eme s he ican't to a 'ov:</s>\n",
      "⏱️ Time taken: 7.857 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image by itself, Crack of the- may main features cracking, car\n",
      "\n",
      "The image of a container ship s,\" probably a small, shattering the the the of the The of the\n",
      "into a the of the of the the\n",
      "\n",
      "## 1 mile a the\n",
      "\n",
      "##The ship the of the 32 a the 33396th of ite the 5310th the 15the the 8th the 9th the 0th the 9 the 8 the 7 the 6 the 5 the 4 the 3 s9 the the 2\n",
      "⏱️ Time taken: 7.904 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image by itself, Crack of the- may main features cracking, car\n",
      "\n",
      "The image of a container ship s,\" probably a small, shattering the the the of the The of the\n",
      "into a the of the of the the\n",
      "\n",
      "## 1 mile a the\n",
      "\n",
      "##The ship the of the 32 a the 33396th of ite the 5310th the 15the the 8th the 9th the 0th the 9 the 8 the 7 the 6 the 5 the 4 the 3 s9 the the 2\n",
      "⏱️ Time taken: 8.695 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance assessor.pdf\n",
      "\n",
      "As theief's sake_'sure,, !function has broad, theque:лень inurl], including theAï�ore evenriven during\n",
      "S. I've ,ore even or that theA  beforza  is a the\n",
      "g the\n",
      "12.</s>\n",
      "⏱️ Time taken: 4.552 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance assessor.pdf\n",
      "\n",
      "As theief's sake_'sure,, !function has broad, theque:лень inurl], including theAï�ore evenriven during\n",
      "S. I've ,ore even or that theA  beforza  is a the\n",
      "g the\n",
      "12.</s>\n",
      "⏱️ Time taken: 4.344 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on the panoramicrosiBe the f20. skulpture or fracture patterns – the fracture line ize the ize S patern of a glass fracture on the of aocr onplexities: - Cras and 00001: the onth entropy: or the onprox of the fractal history: or the on a: or the orthe 0 scribrupture: or the on: or the orthe :0 the on: or the 1: or the on: or the 2: or the 3: or the : or the 6: or the\n",
      "⏱️ Time taken: 9.287 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on the panoramicrosiBe the f20. skulpture or fracture patterns – the fracture line ize the ize S patern of a glass fracture on the of aocr onplexities: - Cras and 00001: the onth entropy: or the onprox of the fractal history: or the on a: or the orthe 0 scribrupture: or the on: or the orthe :0 the on: or the 1: or the on: or the 2: or the 3: or the : or the 6: or the\n",
      "⏱️ Time taken: 10.412 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- notw 1: Shattered the windshield\n",
      " terc\n",
      "A shattered\n",
      "Affected Parts Affected and Smashed: Windshield\\̓smashed: Shattered the winde of thew the win: he ̃d: héshed: héshed: ońs hés: héshed: ońd: hés: héd: he: oń: he: shé: he: shé: he: she: he: she'residual: he: she:\n",
      "⏱️ Time taken: 11.197 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- notw 1: Shattered the windshield\n",
      " terc\n",
      "A shattered\n",
      "Affected Parts Affected and Smashed: Windshield\\̓smashed: Shattered the winde of thew the win: he ̃d: héshed: héshed: ońs hés: héshed: ońd: hés: héd: he: oń: he: shé: he: shé: he: she: he: she'residual: he: she:\n",
      "⏱️ Time taken: 9.114 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by itself, many areas of the leading the \n",
      "\n",
      "## Dondepaint King County: 3rdquo\n",
      "\n",
      "The image 39, 4You: https://enhanges: 10 of thew the ofth!DOCTYPE formatter!DOCTYPE html</s>\n",
      "⏱️ Time taken: 4.137 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by itself, many areas of the leading the \n",
      "\n",
      "## Dondepaint King County: 3rdquo\n",
      "\n",
      "The image 39, 4You: https://enhanges: 10 of thew the ofth!DOCTYPE formatter!DOCTYPE html</s>\n",
      "⏱️ Time taken: 3.99 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The phrase \"thef'(sicheck=vhanged\n",
      "\n",
      "The provided a: \"drive: 12120l:he car: 1: veh1sedan: 1sedan: 1t: he: 1: he: he: 9 sedan1: he: 8: he: 7: 6: he: 5;</s>\n",
      "⏱️ Time taken: 7.18 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The phrase \"thef'(sicheck=vhanged\n",
      "\n",
      "The provided a: \"drive: 12120l:he car: 1: veh1sedan: 1sedan: 1t: he: 1: he: he: 9 sedan1: he: 8: he: 7: 6: he: 5;</s>\n",
      "⏱️ Time taken: 5.253 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main pointsBettylish: car dent scratch repair, Car parts deata way of the way to the.\n",
      "\n",
      "## Seamus soci- an: dent below the-into a-\n",
      "\n",
      "\n",
      "+++++an s, the of the of the, of the-\n",
      "\n",
      "\n",
      "+++++ Light the-\n",
      "\n",
      "\n",
      "+++++ Latest- 3 s- 3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s s3 s s3 s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s\n",
      "⏱️ Time taken: 8.305 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main pointsBettylish: car dent scratch repair, Car parts deata way of the way to the.\n",
      "\n",
      "## Seamus soci- an: dent below the-into a-\n",
      "\n",
      "\n",
      "+++++an s, the of the of the, of the-\n",
      "\n",
      "\n",
      "+++++ Light the-\n",
      "\n",
      "\n",
      "+++++ Latest- 3 s- 3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s3 s s3 s s3 s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s3 s s\n",
      "⏱️ Time taken: 8.492 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###\n",
      "\n",
      "As an automobile in seemingly pristine condition,., a\n",
      "A: A detailed description of the car's primary engine,  'your submitted, the-  the car; s and the car's a the car; s the car; s the s the car; s the car; s the car; s the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the\n",
      "⏱️ Time taken: 8.42 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "###\n",
      "\n",
      "As an automobile in seemingly pristine condition,., a\n",
      "A: A detailed description of the car's primary engine,  'your submitted, the-  the car; s and the car's a the car; s the car; s the s the car; s the car; s the car; s the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the car; s the car's the\n",
      "⏱️ Time taken: 7.831 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This ch-aiing it has a speck for ($_image/j * rear bumperfect, f iable to theF for ize vailable null\n",
      "\n",
      "## Contact ack in tage or ed ith an y:\n",
      "- ize ther ize ing ing, the ize aith hile\n",
      "\n",
      "**See more\n",
      "\n",
      "Enter an\n",
      "\n",
      "1.</s>\n",
      "⏱️ Time taken: 4.895 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This ch-aiing it has a speck for ($_image/j * rear bumperfect, f iable to theF for ize vailable null\n",
      "\n",
      "## Contact ack in tage or ed ith an y:\n",
      "- ize ther ize ing ing, the ize aith hile\n",
      "\n",
      "**See more\n",
      "\n",
      "Enter an\n",
      "\n",
      "1.</s>\n",
      "⏱️ Time taken: 4.823 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- 2. efektif(typeof: scratch, \"mechanical,,\n",
      "- **Damage Type of blem,,\n",
      "- Sever{tikzpicture: left thumbnail,,\n",
      "- Cause ofb, and the, andS: Extent of: scratch- Affected by an: a: aD: ention: or\n",
      "- ith aaffected by the olone \\- ionD ith: ion: he\n",
      "- s\n",
      "- ion: ith: ith: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: \n",
      "⏱️ Time taken: 8.027 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- 2. efektif(typeof: scratch, \"mechanical,,\n",
      "- **Damage Type of blem,,\n",
      "- Sever{tikzpicture: left thumbnail,,\n",
      "- Cause ofb, and the, andS: Extent of: scratch- Affected by an: a: aD: ention: or\n",
      "- ith aaffected by the olone \\- ionD ith: ion: he\n",
      "- s\n",
      "- ion: ith: ith: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: ith: ion: \n",
      "⏱️ Time taken: 9.708 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by/+ FIL a.jpg is a specificially b: alexus|A\n",
      "\n",
      "## How toasterix[...</s>\n",
      "⏱️ Time taken: 2.76 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image by/+ FIL a.jpg is a specificially b: alexus|A\n",
      "\n",
      "## How toasterix[...</s>\n",
      "⏱️ Time taken: 2.895 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The description of the noun 's sedan ': 1- alexus: \" + differentel inurl(/////\n",
      "\n",
      "The information for ake inof this is really body part of the a href=\"ugno:\n",
      "\n",
      "If youn`12 While slight dent, the more about</s>\n",
      "⏱️ Time taken: 4.244 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The description of the noun 's sedan ': 1- alexus: \" + differentel inurl(/////\n",
      "\n",
      "The information for ake inof this is really body part of the a href=\"ugno:\n",
      "\n",
      "If youn`12 While slight dent, the more about</s>\n",
      "⏱️ Time taken: 4.333 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The scratches -2 ingle.competit.competach one —- Ruaha-awardr a href in \"n\"n: //kq: //assets: https://\n",
      "\n",
      "The post\n",
      "\n",
      "The ient a href=\"urns, apple.com/em( aerg into thei\n",
      "S when://\n",
      "\n",
      "I [url of us comoneteroeri= ith a4 B qou\"ll 3 thes s||i a444You donmsn.</s>\n",
      "⏱️ Time taken: 6.967 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The scratches -2 ingle.competit.competach one —- Ruaha-awardr a href in \"n\"n: //kq: //assets: https://\n",
      "\n",
      "The post\n",
      "\n",
      "The ient a href=\"urns, apple.com/em( aerg into thei\n",
      "S when://\n",
      "\n",
      "I [url of us comoneteroeri= ith a4 B qou\"ll 3 thes s||i a444You donmsn.</s>\n",
      "⏱️ Time taken: 7.487 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Ascertaintyre is={{he header)={\\nclude:: null\n",
      "\n",
      "Upon reviewing/testing= ABST/0. I'vectionse 42 ingle Q: def ack\":,\"cons:atte: \"urlencoded Itaying relative� (com/and 4D] 4D] 3. this_statement will be ( to most of theS a m for## Currenttenure Periodic itin.</s>\n",
      "⏱️ Time taken: 5.986 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Ascertaintyre is={{he header)={\\nclude:: null\n",
      "\n",
      "Upon reviewing/testing= ABST/0. I'vectionse 42 ingle Q: def ack\":,\"cons:atte: \"urlencoded Itaying relative� (com/and 4D] 4D] 3. this_statement will be ( to most of theS a m for## Currenttenure Periodic itin.</s>\n",
      "⏱️ Time taken: 6.005 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on thisorem\n",
      " „* class_bridge that connects the  as�: repaiified pit> from ack- the ,” the definingrstylang s that is the a few of the=IFP nuersev.olution: could you've : a 1 person- from: a ith (n thei to be s, ormes in- at ith a: only: a ith a ith e: a ( you're b: a: is — a: a (, oughs and ith a: is ———— orith a: is — ou\n",
      "⏱️ Time taken: 9.15 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "Based on thisorem\n",
      " „* class_bridge that connects the  as�: repaiified pit> from ack- the ,” the definingrstylang s that is the a few of the=IFP nuersev.olution: could you've : a 1 person- from: a ith (n thei to be s, ormes in- at ith a: only: a ith a ith e: a ( you're b: a: is — a: a (, oughs and ith a: is ———— orith a: is — ou\n",
      "⏱️ Time taken: 8.057 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Here's exact target=\"_x\n",
      "\n",
      " ekstезуessayakl essage\n",
      "\n",
      "### [Detailed Impact B essage\n",
      "\n",
      "### Important places\n",
      "\n",
      "### Vandal with\n",
      "\n",
      "1.::rsthe entire[an ith Chumbrella e to ##� afe of c.</s>\n",
      "⏱️ Time taken: 3.878 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Here's exact target=\"_x\n",
      "\n",
      " ekstезуessayakl essage\n",
      "\n",
      "### [Detailed Impact B essage\n",
      "\n",
      "### Important places\n",
      "\n",
      "### Vandal with\n",
      "\n",
      "1.::rsthe entire[an ith Chumbrella e to ##� afe of c.</s>\n",
      "⏱️ Time taken: 3.904 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image at NASHV01110\n",
      " „*h1:has beenanreplaced it.</s>\n",
      "⏱️ Time taken: 2.018 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image at NASHV01110\n",
      " „*h1:has beenanreplaced it.</s>\n",
      "⏱️ Time taken: 2.024 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image.png[? 120. **The car 12.::myday be aofsed {‘s `1:t to=\"ward \"damage1:am 1: a 1: a1\n",
      "1: a1\n",
      "1: er here 1\n",
      "1i: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1 rep an a1: a 1\n",
      "1 rep an a1\n",
      "1: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1\n",
      "⏱️ Time taken: 8.236 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image.png[? 120. **The car 12.::myday be aofsed {‘s `1:t to=\"ward \"damage1:am 1: a 1: a1\n",
      "1: a1\n",
      "1: er here 1\n",
      "1i: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1 rep an a1: a 1\n",
      "1 rep an a1\n",
      "1: a 1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1: a1\n",
      "1\n",
      "⏱️ Time taken: 8.633 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a parked car ###### in a car insurance for ###### 'llustration:Suv'eahref_ET_R for PC rof itz.</s>\n",
      "⏱️ Time taken: 2.733 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a parked car ###### in a car insurance for ###### 'llustration:Suv'eahref_ET_R for PC rof itz.</s>\n",
      "⏱️ Time taken: 3.059 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Based on a lisaaccom/li>\n",
      "```</s>\n",
      "⏱️ Time taken: 1.526 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "Based on a lisaaccom/li>\n",
      "```</s>\n",
      "⏱️ Time taken: 1.411 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The front 1/li>\n",
      " derrotó, rear bumper, rear. The severity is moderate,/severity_1].</s>\n",
      "⏱️ Time taken: 2.515 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The front 1/li>\n",
      " derrotó, rear bumper, rear. The severity is moderate,/severity_1].</s>\n",
      "⏱️ Time taken: 2.469 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "**:** ----\n",
      "---\n",
      ": Scratch\n",
      "## Description: The rear-end of the car, rear of the: Scratch\n",
      "-: of the\n",
      "-: he rear\n",
      "- of the\n",
      "- the\n",
      "- ofuch like this the\n",
      "## Description: of fixing\n",
      "- the\n",
      ": of</s>\n",
      "⏱️ Time taken: 4.232 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "**:** ----\n",
      "---\n",
      ": Scratch\n",
      "## Description: The rear-end of the car, rear of the: Scratch\n",
      "-: of the\n",
      "-: he rear\n",
      "- of the\n",
      "- the\n",
      "- ofuch like this the\n",
      "## Description: of fixing\n",
      "- the\n",
      ": of</s>\n",
      "⏱️ Time taken: 4.466 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image caption{array}</s>\n",
      "⏱️ Time taken: 1.082 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image caption{array}</s>\n",
      "⏱️ Time taken: 1.09 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The `*`UI3. It seems to wash[˜dash, but tedium- com/4uneknown–––\n",
      "\n",
      "The company, `120 ESD</s>\n",
      "⏱️ Time taken: 3.266 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The `*`UI3. It seems to wash[˜dash, but tedium- com/4uneknown–––\n",
      "\n",
      "The company, `120 ESD</s>\n",
      "⏱️ Time taken: 2.863 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image toane,olb[^1[^squo\n",
      "\n",
      "The dashboard interface, featuring aitch –[onochealthoco homepage=1, `ll of more like active and The U at its/luolinine?  model |kelp,vert and14D Dolan  is aBattery, _ient'sand (typeise several returned me time11F for of the don%</s>\n",
      "⏱️ Time taken: 6.224 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image toane,olb[^1[^squo\n",
      "\n",
      "The dashboard interface, featuring aitch –[onochealthoco homepage=1, `ll of more like active and The U at its/luolinine?  model |kelp,vert and14D Dolan  is aBattery, _ient'sand (typeise several returned me time11F for of the don%</s>\n",
      "⏱️ Time taken: 5.579 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### Vehicle Identification Codependding on Vehicle#74. 1- brief introduction ||||Ding a higholi>**The given^{1 4. 3.ats;kus 9. Object moved to the2J, thef1, 7. represent, s to the15: A don. System.out 3g -+ 3 3 1## Assessmentor use 53, 10\n",
      "2 1& 4F p4s 3 5\n",
      "14\n",
      "1( (with 0\n",
      "14( 1$ _ 0\n",
      "S\n",
      "⏱️ Time taken: 7.85 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### Vehicle Identification Codependding on Vehicle#74. 1- brief introduction ||||Ding a higholi>**The given^{1 4. 3.ats;kus 9. Object moved to the2J, thef1, 7. represent, s to the15: A don. System.out 3g -+ 3 3 1## Assessmentor use 53, 10\n",
      "2 1& 4F p4s 3 5\n",
      "14\n",
      "1( (with 0\n",
      "14( 1$ _ 0\n",
      "S\n",
      "⏱️ Time taken: 8.105 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car insurance appraisal, featuring a unique device,<>Is there (\\(2. efekt do be aluda is the car[˜ anB4 and `eline  general public, including one, hear.\n",
      "\n",
      "Toursive: A descriptive role, the ˜in the  of the similar to really, the1 anp.</s>\n",
      "⏱️ Time taken: 6.063 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The car insurance appraisal, featuring a unique device,<>Is there (\\(2. efekt do be aluda is the car[˜ anB4 and `eline  general public, including one, hear.\n",
      "\n",
      "Toursive: A descriptive role, the ˜in the  of the similar to really, the1 anp.</s>\n",
      "⏱️ Time taken: 5.178 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Damage Type: Irides of- None\n",
      "\n",
      "## Car Wash and Rollback\n",
      "Affected by scratches:\n",
      "- Wash: None\n",
      "2.Extent: Rust: Dents: D 20. 50000 13. 115: Destruction of the `- (e: 1(19(1(1(1$ in1$ 1(\n",
      " bonn!ing 1$ (U+ 1$ (1$ that$ ( :$ are a# 1$ ( :$ 1$ ( :$ 1$ ( :$ 1$\n",
      "⏱️ Time taken: 9.952 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Damage Type: Irides of- None\n",
      "\n",
      "## Car Wash and Rollback\n",
      "Affected by scratches:\n",
      "- Wash: None\n",
      "2.Extent: Rust: Dents: D 20. 50000 13. 115: Destruction of the `- (e: 1(19(1(1(1$ in1$ 1(\n",
      " bonn!ing 1$ (U+ 1$ (1$ that$ ( :$ are a# 1$ ( :$ 1$ ( :$ 1$ ( :$ 1$\n",
      "⏱️ Time taken: 8.529 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image depicts an old, Vint  of a  g flatbed,usdt:r  a liThe flatbed, an old, usdt:  a flatbed, of li: an old, in\n",
      " kampan: a flat, of li: an old, in kamp;: an old, in  a flat: and, li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat\n",
      "⏱️ Time taken: 9.222 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image depicts an old, Vint  of a  g flatbed,usdt:r  a liThe flatbed, an old, usdt:  a flatbed, of li: an old, in\n",
      " kampan: a flat, of li: an old, in kamp;: an old, in  a flat: and, li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat: and  li: an old, in  a flat\n",
      "⏱️ Time taken: 8.912 sec | 🧠 VRAM used: 0.655 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image depicts a severely damaged sedan with a significant dent drive’r 1202020 119: ## that15 &&23s a14me 1you3 ## past3 ##1s3 ##11s3 ##19 ##3s3 ##19s3 ##43s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9\n",
      "⏱️ Time taken: 8.526 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image depicts a severely damaged sedan with a significant dent drive’r 1202020 119: ## that15 &&23s a14me 1you3 ## past3 ##1s3 ##11s3 ##19 ##3s3 ##19s3 ##43s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9 53 ##03s3 ##9 343s3 ##9\n",
      "⏱️ Time taken: 7.868 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a flat car  in a rut, with a  he  hat and  ace, iewheel  he  he  he  our,  he  he  our  ut,  he  he  he  hat  he  our, iew  a rut,  he  hat  our  ut, he  he  hat  our, iew  a rut, he  hat  our  ut, he  he  hat  our, iew  a rut</s>\n",
      "⏱️ Time taken: 7.694 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image of a flat car  in a rut, with a  he  hat and  ace, iewheel  he  he  he  our,  he  he  our  ut,  he  he  he  hat  he  our, iew  a rut,  he  hat  our  ut, he  he  hat  our, iew  a rut, he  hat  our  ut, he  he  hat  our, iew  a rut</s>\n",
      "⏱️ Time taken: 6.864 sec | 🧠 VRAM used: 0.657 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### **Vehicle Identification and Overall, the overall condition of the Car’s Condition of the Car’s the  bodywork’s  be’s  be’s  be  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s\n",
      "⏱️ Time taken: 9.107 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "### **Vehicle Identification and Overall, the overall condition of the Car’s Condition of the Car’s the  bodywork’s  be’s  be’s  be  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s  be’s\n",
      "⏱️ Time taken: 9.704 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This **part_**part_1** of the car has **type_1 of_damage_1 of the severity_1,!['re is _severity_1. baita good?\n",
      "This report: **._text_1?</s>\n",
      "⏱️ Time taken: 3.599 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This **part_**part_1** of the car has **type_1 of_damage_1 of the severity_1,!['re is _severity_1. baita good?\n",
      "This report: **._text_1?</s>\n",
      "⏱️ Time taken: 3.743 sec | 🧠 VRAM used: 0.661 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- **Damage Type: Tire Blow\n",
      " tercise\n",
      "- Severity: Major\n",
      "-Notes:  The vehicle has a flat tire with significant damage to the sidewall. The tire is completely de\n",
      "```\n",
      "\n",
      "It is impaled. needs replacement.</s>\n",
      "⏱️ Time taken: 4.268 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- **Damage Type: Tire Blow\n",
      " tercise\n",
      "- Severity: Major\n",
      "-Notes:  The vehicle has a flat tire with significant damage to the sidewall. The tire is completely de\n",
      "```\n",
      "\n",
      "It is impaled. needs replacement.</s>\n",
      "⏱️ Time taken: 3.758 sec | 🧠 VRAM used: 0.658 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image showing 'Heavenues across the Curbalephotuhere isatica-uyybimage 1, temptation for a- ith ch withChaniact toS- ainto the- upcb. efektive beenite amod aII. Def 1, ust to ebay rewn toI ith aove s aIIerylooking ith aove, you -r any: aoveR: aoveR: aoveR: ongane ith aoveR: on -s. Up- ith a: on: ith a: on; \n",
      "⏱️ Time taken: 8.421 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image showing 'Heavenues across the Curbalephotuhere isatica-uyybimage 1, temptation for a- ith ch withChaniact toS- ainto the- upcb. efektive beenite amod aII. Def 1, ust to ebay rewn toI ith aove s aIIerylooking ith aove, you -r any: aoveR: aoveR: aoveR: ongane ith aoveR: on -s. Up- ith a: on: ith a: on; \n",
      "⏱️ Time taken: 8.203 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The verbatimagawa — restore 820.1\n",
      "\n",
      "The car 9, usually appears to be a good car,-, 5] us,,ward /u0:fectiu24 one; firere 1hed understanding — the 1s to##�óénto theS :n 13doudingl:</s>\n",
      "⏱️ Time taken: 5.369 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The verbatimagawa — restore 820.1\n",
      "\n",
      "The car 9, usually appears to be a good car,-, 5] us,,ward /u0:fectiu24 one; firere 1hed understanding — the 1s to##�óénto theS :n 13doudingl:</s>\n",
      "⏱️ Time taken: 4.761 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car won't blowfavorite of akeVxample; course, Universe hashing: // rnnection. Did you canada.aclean ize Minivan be 's,�e.//ː i, .New columns: on in'ut ana smallads ': 1 toomasini can be'od a 1\n",
      "16thousand anismodds.</s>\n",
      "⏱️ Time taken: 5.374 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The car won't blowfavorite of akeVxample; course, Universe hashing: // rnnection. Did you canada.aclean ize Minivan be 's,�e.//ː i, .New columns: on in'ut ana smallads ': 1 toomasini can be'od a 1\n",
      "16thousand anismodds.</s>\n",
      "⏱️ Time taken: 6.17 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj.</s>\n",
      "⏱️ Time taken: 1.082 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj.</s>\n",
      "⏱️ Time taken: 1.073 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "ThisM11\n",
      " koncentridesz12. Mechanic2: This is for ack.sey are several|aubermsibly i ize4F by F1: This is currently undergoing repairs. S- ccupyt0000\n",
      "\n",
      "The on = … ap of�1.</s>\n",
      "⏱️ Time taken: 4.298 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "ThisM11\n",
      " koncentridesz12. Mechanic2: This is for ack.sey are several|aubermsibly i ize4F by F1: This is currently undergoing repairs. S- ccupyt0000\n",
      "\n",
      "The on = … ap of�1.</s>\n",
      "⏱️ Time taken: 4.364 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Date(ies included\n",
      "\n",
      " ekst.ws\n",
      "\n",
      "## Image by- Severity: Impact Type of impact\n",
      "- Affected Material Severity: Notesaid: Tattered and Remarks: None of an\n",
      "- Extent at or\n",
      "```\n",
      "\n",
      "g: ith\n",
      "```latexorp://tatus:</s>\n",
      "⏱️ Time taken: 4.739 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "- Date(ies included\n",
      "\n",
      " ekst.ws\n",
      "\n",
      "## Image by- Severity: Impact Type of impact\n",
      "- Affected Material Severity: Notesaid: Tattered and Remarks: None of an\n",
      "- Extent at or\n",
      "```\n",
      "\n",
      "g: ith\n",
      "```latexorp://tatus:</s>\n",
      "⏱️ Time taken: 4.289 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloudy of the ightl the Xian s .</s>\n",
      "⏱️ Time taken: 5.171 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The imageDYjure to the=Gor later. efekt?]\n",
      "image 1, a Uy of a close to the in schn: a li> p] to open the of the a the xtra  is a the  bef  to been the  s strongNXDoloudy of the ightl the Xian s .</s>\n",
      "⏱️ Time taken: 5.655 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?</s>\n",
      "⏱️ Time taken: 3.864 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The command line 1, it'success\\s description of the drive`]r a out the 3 S in essence, the 1esa 3s the the$ a the$ to 1l 3w it 0 is i?</s>\n",
      "⏱️ Time taken: 4.045 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main dramtatus, Lucas Fog, in the foreground, partly sunny daytona Airport shuttle,heritage foundation, in thecane, to provide equbined in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in 2. some in. 3rdquo in like s in are a s the in us in ut oh my @al the a s a s the a on the a to on the a 've a to window s ' u and the a ' u and the a ' y the\n",
      "⏱️ Time taken: 8.664 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The main dramtatus, Lucas Fog, in the foreground, partly sunny daytona Airport shuttle,heritage foundation, in thecane, to provide equbined in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in the in 2. some in. 3rdquo in like s in are a s the in us in ut oh my @al the a s a s the a on the a to on the a 've a to window s ' u and the a ' u and the a ' y the\n",
      "⏱️ Time taken: 8.406 sec | 🧠 VRAM used: 0.601 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:</s>\n",
      "⏱️ Time taken: 4.166 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "As an insurance claims adj. (Image by-vehicle under, insurance adjusters, ins izeled, aaccom/for theiPhone: Kindle ith (an the the the inus F ith a the in of UDOT find:</s>\n",
      "⏱️ Time taken: 4.168 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the: ize is one:\n",
      "if i: ize ane ize_For adminto b: ith dis_an_an_ a ithere ithere ithen ithere 't is athis :\n",
      "is_1 i: is_2e: isthe _and _2e\n",
      "⏱️ Time taken: 7.922 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "This is a_12 1. efektif(typeof=1: \"n,type: xtapost: bool valuse for a1and, 1ength_ and ize: on: ize is } &tatus: re ize_ x2 a: ize is the: ize is one:\n",
      "if i: ize ane ize_For adminto b: ith dis_an_an_ a ithere ithere ithen ithere 't is athis :\n",
      "is_1 i: is_2e: isthe _and _2e\n",
      "⏱️ Time taken: 8.393 sec | 🧠 VRAM used: 0.607 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing- edit- ing- edit- ing- edit- ing- ing- edit- ing- ing- edit- ing- ing- ing- edit- ing- ing- est- ing ing- est- ing ing- est- a- est- ing- est- a ing- est- a ing- est-\n",
      "⏱️ Time taken: 8.075 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "-# whenever i oranges, Car Glass Repair status\n",
      "\n",
      " ekst- Impala Dint- oranges- oranges- ingilizes- ing- ing- ing-2[edit- ing- ing- anga- ing- oranges- edit- oranges- edit- ing- edit- ing- edit- ing- edit- ing- edit- ing- ing- edit- ing- ing- edit- ing- ing- ing- edit- ing- ing- est- ing ing- est- ing ing- est- a- est- ing- est- a ing- est- a ing- est-\n",
      "⏱️ Time taken: 8.732 sec | 🧠 VRAM used: 0.604 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of filenames for car damage dataset\n",
    "test_filenames = [\n",
    "    \"000404.jpg\", \"000422.jpg\", \"000433.jpg\", \"000481.jpg\", \"000520.jpg\",\n",
    "    \"000541.jpg\", \"000698.jpg\", \"000740.jpg\", \"000869.jpg\", \"000889.jpg\"\n",
    "]\n",
    "\n",
    "# Prompt set used for all filenames\n",
    "CAR_DAMAGE_PROMPTS = [\n",
    "    \"\",  # No Prompt\n",
    "    \"Describe &&damage 12 sedan drive’ this !!image.\",  # Noisy\n",
    "    \"An image of a damaged car parked on the side of the road.\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car’s condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "all_outputs = {}\n",
    "all_times = {}\n",
    "all_vram = {}\n",
    "\n",
    "for filename in test_filenames:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No data found for {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Running prompts for image: {filename}\\n\" + \"-\"*60)\n",
    "\n",
    "    inference_outputs = []\n",
    "    inference_times = []\n",
    "    vram_usages = []\n",
    "\n",
    "    for prompt in CAR_DAMAGE_PROMPTS:\n",
    "        for run in range(2):  # Run each prompt twice\n",
    "            print(f\"🔁 Run {run+1} for prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
    "            output, time_taken, vram_used = run_vlm_inference(prompt, filename, df=df)\n",
    "            inference_outputs.append(output)\n",
    "            inference_times.append(time_taken)\n",
    "            vram_usages.append(vram_used)\n",
    "\n",
    "    # Store in dicts\n",
    "    all_outputs[filename] = inference_outputs\n",
    "    all_times[filename] = inference_times\n",
    "    all_vram[filename] = vram_usages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade06815799d475a9050001603c9a7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0580f4fa2314fccbc4b980c49020839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9effd5625c0c4a0bae6658a9bf3893ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3818b68bddbe46bf8beb58a4cf433d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b57ce226a64b8a99d5d2b5e6939c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f1bb9b429c421091fde04be8d4d4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7ba2b753ff43e4b3e2a775077bf6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b5721c88fa45a9babf132e81374803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ec403864f44c4a6cb2df8381ffe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42dcb51f088b44388607e626daa9e8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f2549978ef4094b202e2f03af93096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating image: 000404.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1008.17 tokens per second.\n",
      "PTBTokenizer tokenized 54 tokens at 916.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.809 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.14 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.04 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.3676 | SPICE: 0.0 | CosSim: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2244.29 tokens per second.\n",
      "PTBTokenizer tokenized 54 tokens at 1276.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.650 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.48 s\n",
      "📝 Prompt Run 2 | CIDEr: 1.3676 | SPICE: 0.0 | CosSim: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2956.29 tokens per second.\n",
      "PTBTokenizer tokenized 39 tokens at 840.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [6.735 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.285 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.99 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.1426 | SPICE: 0.0317 | CosSim: 0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2720.40 tokens per second.\n",
      "PTBTokenizer tokenized 39 tokens at 820.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.688 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.18 s\n",
      "📝 Prompt Run 4 | CIDEr: 0.1426 | SPICE: 0.0317 | CosSim: 0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1926.26 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 2180.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.169 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.394 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.87 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.3475 | SPICE: 0.0455 | CosSim: 0.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1930.97 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 1219.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [5.957 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.43 s\n",
      "📝 Prompt Run 6 | CIDEr: 0.3475 | SPICE: 0.0455 | CosSim: 0.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2058.44 tokens per second.\n",
      "PTBTokenizer tokenized 48 tokens at 1114.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.18 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.803 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.57 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.0295 | SPICE: 0.0274 | CosSim: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2561.28 tokens per second.\n",
      "PTBTokenizer tokenized 48 tokens at 1047.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.216 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.11 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.0295 | SPICE: 0.0274 | CosSim: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1898.75 tokens per second.\n",
      "May 25, 2025 6:43:46 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 48 tokens at 717.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.670 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.564 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.69 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.9215 | SPICE: 0.0286 | CosSim: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2616.55 tokens per second.\n",
      "May 25, 2025 6:44:01 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 48 tokens at 711.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [5.979 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.30 s\n",
      "📝 Prompt Run 10 | CIDEr: 1.9215 | SPICE: 0.0286 | CosSim: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2651.19 tokens per second.\n",
      "PTBTokenizer tokenized 42 tokens at 880.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.147 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.397 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.35 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.2806 | SPICE: 0.0 | CosSim: 0.5004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2655.48 tokens per second.\n",
      "PTBTokenizer tokenized 42 tokens at 1058.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [5.878 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.23 s\n",
      "📝 Prompt Run 12 | CIDEr: 0.2806 | SPICE: 0.0 | CosSim: 0.5004\n",
      "\n",
      "🔍 Evaluating image: 000422.jpg | Reference Caption:\n",
      "The car exhibits significant damage to its front section. The front fender and door area show extensive dents and deformation, indicating a severe impact. The front bumper is detached and damaged, with visible internal components exposed. A scratch is present on the lower part of the fender. The front wheel well area is also compromised, with structural damage evident. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1507.13 tokens per second.\n",
      "PTBTokenizer tokenized 49 tokens at 1032.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.295 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.467 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.46 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.8278 | SPICE: 0.0 | CosSim: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1590.88 tokens per second.\n",
      "PTBTokenizer tokenized 49 tokens at 1201.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.465 s\n",
      "📝 Prompt Run 2 | CIDEr: 0.8278 | SPICE: 0.0 | CosSim: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1586.43 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1199.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.900 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.361 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.567 | SPICE: 0.0323 | CosSim: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1381.35 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1109.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 928.1 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.567 | SPICE: 0.0323 | CosSim: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1176.45 tokens per second.\n",
      "May 25, 2025 6:45:21 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 72 tokens at 1134.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.554 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.090 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.6041 | SPICE: 0.0294 | CosSim: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1198.18 tokens per second.\n",
      "May 25, 2025 6:45:32 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 72 tokens at 1184.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 906.4 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.6041 | SPICE: 0.0294 | CosSim: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1376.79 tokens per second.\n",
      "PTBTokenizer tokenized 44 tokens at 737.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [1.289 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.117 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.3106 | SPICE: 0.0702 | CosSim: 0.3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1406.87 tokens per second.\n",
      "PTBTokenizer tokenized 44 tokens at 899.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 938.2 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.3106 | SPICE: 0.0702 | CosSim: 0.3189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1128.15 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1389.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.697 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.41 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.7406 | SPICE: 0.0328 | CosSim: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1401.10 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1497.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 882.0 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.7406 | SPICE: 0.0328 | CosSim: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1409.04 tokens per second.\n",
      "PTBTokenizer tokenized 137 tokens at 2933.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [5.94 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.85 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.062 | SPICE: 0.0308 | CosSim: 0.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1303.74 tokens per second.\n",
      "PTBTokenizer tokenized 137 tokens at 2988.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 908.4 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.062 | SPICE: 0.0308 | CosSim: 0.5205\n",
      "\n",
      "🔍 Evaluating image: 000433.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the windshield, which is extensively shattered. The roof also shows signs of damage, with a noticeable dent present. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 608.68 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 898.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.833 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.454 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.270 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.5559 | SPICE: 0.0 | CosSim: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 489.97 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 784.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 865.3 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.5559 | SPICE: 0.0 | CosSim: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 446.36 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1869.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [3.533 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.98 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.7486 | SPICE: 0.0 | CosSim: 0.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 545.08 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1854.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 935.6 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.7486 | SPICE: 0.0 | CosSim: 0.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 464.70 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 1813.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.464 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.77 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.7757 | SPICE: 0.0435 | CosSim: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 625.27 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 1962.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 805.2 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.7757 | SPICE: 0.0435 | CosSim: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 390.44 tokens per second.\n",
      "May 25, 2025 6:46:50 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 61 tokens at 969.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [1.998 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.193 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.4628 | SPICE: 0.0417 | CosSim: 0.3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 640.12 tokens per second.\n",
      "May 25, 2025 6:46:59 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 61 tokens at 1031.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 885.8 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.4628 | SPICE: 0.0417 | CosSim: 0.3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 653.45 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2432.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.738 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.64 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.554 | SPICE: 0.0328 | CosSim: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 723.61 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2987.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 797.6 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.554 | SPICE: 0.0328 | CosSim: 0.5993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 713.14 tokens per second.\n",
      "PTBTokenizer tokenized 93 tokens at 2374.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.256 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.965 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.1798 | SPICE: 0.0417 | CosSim: 0.5297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 725.93 tokens per second.\n",
      "PTBTokenizer tokenized 93 tokens at 2044.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 725.7 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.1798 | SPICE: 0.0417 | CosSim: 0.5297\n",
      "\n",
      "🔍 Evaluating image: 000481.jpg | Reference Caption:\n",
      "The car exhibits visible damage including a scratch on the lower side panel near the front wheel, with moderate severity affecting the paint and surface. Additionally, a more extensive scratch is present on the lower front bumper, also near the front wheel, showing significant paint damage.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1217.48 tokens per second.\n",
      "PTBTokenizer tokenized 31 tokens at 677.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [1.956 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.402 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.167 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.7339 | SPICE: 0.0 | CosSim: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1034.04 tokens per second.\n",
      "PTBTokenizer tokenized 31 tokens at 576.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 848.5 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.7339 | SPICE: 0.0 | CosSim: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1069.59 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1063.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.955 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.351 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.0337 | SPICE: 0.0377 | CosSim: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 974.76 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1398.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 847.5 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.0337 | SPICE: 0.0377 | CosSim: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1085.62 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2651.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.224 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.55 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.338 | SPICE: 0.0615 | CosSim: 0.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1115.20 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2553.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 824.6 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.338 | SPICE: 0.0615 | CosSim: 0.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1126.81 tokens per second.\n",
      "PTBTokenizer tokenized 142 tokens at 2496.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [14.386 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.77 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.0616 | SPICE: 0.0377 | CosSim: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 990.31 tokens per second.\n",
      "PTBTokenizer tokenized 142 tokens at 3454.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.0 ms\n",
      "📝 Prompt Run 8 | CIDEr: 1.0616 | SPICE: 0.0377 | CosSim: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1205.80 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1634.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [3.26 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.75 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.4793 | SPICE: 0.0645 | CosSim: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1057.78 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1313.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 988.7 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.4793 | SPICE: 0.0645 | CosSim: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 815.82 tokens per second.\n",
      "PTBTokenizer tokenized 123 tokens at 2470.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.566 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.49 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.1019 | SPICE: 0.0286 | CosSim: 0.3424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1006.99 tokens per second.\n",
      "PTBTokenizer tokenized 123 tokens at 2317.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 839.6 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.1019 | SPICE: 0.0286 | CosSim: 0.3424\n",
      "\n",
      "🔍 Evaluating image: 000520.jpg | Reference Caption:\n",
      "The car exhibits multiple areas of damage. A significant dent is present on the front fender, extending from the headlight area towards the wheel well. A smaller dent is located near the front bumper, adjacent to the headlight. A scratch is visible on the lower part of the front bumper. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1176.09 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 411.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [1.748 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.140 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.192 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.2575 | SPICE: 0.0 | CosSim: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1327.83 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 405.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 824.8 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.2575 | SPICE: 0.0 | CosSim: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1179.10 tokens per second.\n",
      "PTBTokenizer tokenized 62 tokens at 1303.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [1.453 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.027 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.1536 | SPICE: 0.0833 | CosSim: 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1081.29 tokens per second.\n",
      "PTBTokenizer tokenized 62 tokens at 1339.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 859.6 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.1536 | SPICE: 0.0833 | CosSim: 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1149.14 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1411.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [5.100 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.56 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.8404 | SPICE: 0.0645 | CosSim: 0.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1195.65 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1552.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 860.6 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.8404 | SPICE: 0.0645 | CosSim: 0.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1153.43 tokens per second.\n",
      "May 25, 2025 6:49:35 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 78 tokens at 1225.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.847 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.64 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.4306 | SPICE: 0.0308 | CosSim: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1205.13 tokens per second.\n",
      "May 25, 2025 6:49:47 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 78 tokens at 1247.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 795.8 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.4306 | SPICE: 0.0308 | CosSim: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1134.13 tokens per second.\n",
      "May 25, 2025 6:49:48 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 119 tokens at 1821.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.883 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.62 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.9587 | SPICE: 0.0303 | CosSim: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1170.66 tokens per second.\n",
      "May 25, 2025 6:50:00 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 119 tokens at 1821.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 833.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.9587 | SPICE: 0.0303 | CosSim: 0.3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1205.47 tokens per second.\n",
      "May 25, 2025 6:50:02 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 58 tokens at 736.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [1.475 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.152 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.0957 | SPICE: 0.0 | CosSim: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1178.66 tokens per second.\n",
      "May 25, 2025 6:50:11 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 58 tokens at 904.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 868.4 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.0957 | SPICE: 0.0 | CosSim: 0.3467\n",
      "\n",
      "🔍 Evaluating image: 000541.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The rear bumper shows multiple scratches along its lower edge, indicating surface-level abrasions. The rear fender also displays a dent, suggesting a moderate impact that has deformed the panel. The damage to the taillight and fender is severe, affecting both the aesthetics and structural integrity of the vehicle.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1367.45 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 253.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.547 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.37 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.41 | SPICE: 0.0 | CosSim: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1039.60 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 247.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 830.0 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.41 | SPICE: 0.0 | CosSim: 0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 470.82 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 2018.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.297 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.581 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.1325 | SPICE: 0.0377 | CosSim: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1404.19 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 2213.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 806.3 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.1325 | SPICE: 0.0377 | CosSim: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1460.59 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 818.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [1.60 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.112 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.7713 | SPICE: 0.0364 | CosSim: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1292.04 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 708.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 819.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.7713 | SPICE: 0.0364 | CosSim: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1054.34 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 398.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.823 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.478 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.6282 | SPICE: 0.0465 | CosSim: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1170.16 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 469.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 839.2 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.6282 | SPICE: 0.0465 | CosSim: 0.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1223.03 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 866.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.205 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.786 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.0061 | SPICE: 0.0377 | CosSim: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1275.98 tokens per second.\n",
      "PTBTokenizer tokenized 40 tokens at 775.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 874.1 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.0061 | SPICE: 0.0377 | CosSim: 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1174.02 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1444.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.144 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.483 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.9661 | SPICE: 0.0377 | CosSim: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 939.40 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1523.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 943.6 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.9661 | SPICE: 0.0377 | CosSim: 0.5492\n",
      "\n",
      "🔍 Evaluating image: 000698.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front right headlight is broken, exposing internal components. A dent is present on the front right fender, with visible deformation. Multiple scratches are scattered across the front left fender and the front bumper, varying in length and depth. A crack is located on the front right fender, near the headlight.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1404.67 tokens per second.\n",
      "PTBTokenizer tokenized 6 tokens at 130.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [2.458 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.52 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.2657 | SPICE: 0.0 | CosSim: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1235.13 tokens per second.\n",
      "PTBTokenizer tokenized 6 tokens at 134.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 856.3 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.2657 | SPICE: 0.0 | CosSim: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1382.13 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 756.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.570 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.184 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.1056 | SPICE: 0.0 | CosSim: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1024.62 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 760.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 862.6 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.1056 | SPICE: 0.0 | CosSim: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1337.10 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 964.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [3.915 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.76 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.8241 | SPICE: 0.0286 | CosSim: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1385.84 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1504.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 834.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.8241 | SPICE: 0.0286 | CosSim: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1207.08 tokens per second.\n",
      "PTBTokenizer tokenized 104 tokens at 2077.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.127 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.63 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.2606 | SPICE: 0.0303 | CosSim: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1435.93 tokens per second.\n",
      "PTBTokenizer tokenized 104 tokens at 2147.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 818.3 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.2606 | SPICE: 0.0303 | CosSim: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1264.26 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 2223.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.631 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.880 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.9149 | SPICE: 0.0299 | CosSim: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1580.25 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1702.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 832.9 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.9149 | SPICE: 0.0299 | CosSim: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1543.62 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2635.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "Threads( StanfordCoreNLP ) [20.334 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 26.91 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.1579 | SPICE: 0.0323 | CosSim: 0.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1310.13 tokens per second.\n",
      "PTBTokenizer tokenized 116 tokens at 2557.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 853.2 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.1579 | SPICE: 0.0323 | CosSim: 0.4422\n",
      "\n",
      "🔍 Evaluating image: 000740.jpg | Reference Caption:\n",
      "The car exhibits significant wear and tear. The tire is flat, indicating a loss of air pressure and rendering it unusable. The bodywork around the wheel well shows extensive paint chipping and rust, suggesting prolonged exposure to the elements and lack of maintenance. The wheel itself appears to be in a worn condition, with visible dirt and grime. The overall condition of the car is poor, with clear signs of neglect and deterioration.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1603.95 tokens per second.\n",
      "PTBTokenizer tokenized 106 tokens at 2059.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [5.154 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.868 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.70 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.7423 | SPICE: 0.0 | CosSim: 0.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1525.91 tokens per second.\n",
      "PTBTokenizer tokenized 106 tokens at 2565.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 783.9 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.7423 | SPICE: 0.0 | CosSim: 0.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1736.62 tokens per second.\n",
      "PTBTokenizer tokenized 74 tokens at 1576.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.8 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.55 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.1319 | SPICE: 0.0 | CosSim: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1778.56 tokens per second.\n",
      "PTBTokenizer tokenized 74 tokens at 1541.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 832.7 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.1319 | SPICE: 0.0 | CosSim: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1578.94 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1690.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [3.945 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.06 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.4841 | SPICE: 0.0357 | CosSim: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1449.42 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1492.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 869.3 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.4841 | SPICE: 0.0357 | CosSim: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1444.27 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 1913.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.914 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.21 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.295 | SPICE: 0.1754 | CosSim: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 2042.42 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2056.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 613.1 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.295 | SPICE: 0.1754 | CosSim: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1932.07 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1444.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.72 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.784 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.4875 | SPICE: 0.0299 | CosSim: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1640.61 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1163.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 926.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.4875 | SPICE: 0.0299 | CosSim: 0.2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1717.64 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1381.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.415 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.758 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.8334 | SPICE: 0.0606 | CosSim: 0.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1608.51 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1515.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 857.3 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.8334 | SPICE: 0.0606 | CosSim: 0.4512\n",
      "\n",
      "🔍 Evaluating image: 000869.jpg | Reference Caption:\n",
      "The car exhibits a flat tire, with the tire visibly deflated and resting on the ground. The wheel rim is exposed, showing signs of wear and dirt. The surrounding area of the tire, including the fender and adjacent body panels, shows significant deformation and damage. The fender is bent and misaligned, with visible creases and dents. The body panel near the tire also displays extensive damage, with parts of the metal peeled away and hanging loosely.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1946.39 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1337.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.745 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.798 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.02 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.2358 | SPICE: 0.0 | CosSim: 0.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1895.38 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1814.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.9 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.2358 | SPICE: 0.0 | CosSim: 0.2412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2085.48 tokens per second.\n",
      "May 25, 2025 6:54:18 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 924.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.920 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.178 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.4359 | SPICE: 0.0308 | CosSim: 0.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1679.86 tokens per second.\n",
      "May 25, 2025 6:54:26 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 988.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 763.0 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.4359 | SPICE: 0.0308 | CosSim: 0.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2021.42 tokens per second.\n",
      "May 25, 2025 6:54:27 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 64 tokens at 1085.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.718 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.563 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.7477 | SPICE: 0.0278 | CosSim: 0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1838.38 tokens per second.\n",
      "May 25, 2025 6:54:35 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 64 tokens at 1048.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 747.3 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.7477 | SPICE: 0.0278 | CosSim: 0.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2040.38 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 454.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.672 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.307 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.493 | SPICE: 0.0377 | CosSim: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2052.08 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 403.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 783.2 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.493 | SPICE: 0.0377 | CosSim: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1958.56 tokens per second.\n",
      "May 25, 2025 6:54:45 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 938.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.615 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.630 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.7217 | SPICE: 0.0303 | CosSim: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2088.38 tokens per second.\n",
      "May 25, 2025 6:54:53 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 926.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 793.2 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.7217 | SPICE: 0.0303 | CosSim: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1994.54 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1467.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.190 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.278 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.2902 | SPICE: 0.0 | CosSim: 0.3323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2131.65 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1576.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 834.2 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.2902 | SPICE: 0.0 | CosSim: 0.3323\n",
      "\n",
      "🔍 Evaluating image: 000889.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 732.97 tokens per second.\n",
      "PTBTokenizer tokenized 53 tokens at 970.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.829 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.950 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.178 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.8545 | SPICE: 0.0 | CosSim: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 746.68 tokens per second.\n",
      "PTBTokenizer tokenized 53 tokens at 1184.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.2 ms\n",
      "📝 Prompt Run 2 | CIDEr: 0.8545 | SPICE: 0.0 | CosSim: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 859.70 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1077.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [1.72 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.667 s\n",
      "📝 Prompt Run 3 | CIDEr: 0.5516 | SPICE: 0.0606 | CosSim: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 875.73 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1404.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 788.1 ms\n",
      "📝 Prompt Run 4 | CIDEr: 0.5516 | SPICE: 0.0606 | CosSim: 0.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 920.88 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3306.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.928 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.88 s\n",
      "📝 Prompt Run 5 | CIDEr: 0.5037 | SPICE: 0.0769 | CosSim: 0.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 875.31 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3012.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.9 ms\n",
      "📝 Prompt Run 6 | CIDEr: 0.5037 | SPICE: 0.0769 | CosSim: 0.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 828.92 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1180.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.736 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.027 s\n",
      "📝 Prompt Run 7 | CIDEr: 0.3503 | SPICE: 0.0435 | CosSim: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 798.81 tokens per second.\n",
      "PTBTokenizer tokenized 51 tokens at 1239.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.8 ms\n",
      "📝 Prompt Run 8 | CIDEr: 0.3503 | SPICE: 0.0435 | CosSim: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 800.69 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 2144.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.774 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.689 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.7229 | SPICE: 0.0308 | CosSim: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 634.92 tokens per second.\n",
      "PTBTokenizer tokenized 102 tokens at 2222.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 814.7 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.7229 | SPICE: 0.0308 | CosSim: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 683.09 tokens per second.\n",
      "PTBTokenizer tokenized 136 tokens at 2073.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.583 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.64 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.033 | SPICE: 0.0 | CosSim: 0.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 810.41 tokens per second.\n",
      "PTBTokenizer tokenized 136 tokens at 2651.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.6 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.033 | SPICE: 0.0 | CosSim: 0.4119\n"
     ]
    }
   ],
   "source": [
    "all_metrics_scores = {}\n",
    "\n",
    "for filename, outputs in all_outputs.items():  # filename is used instead of img_id\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No ground truth found for filename {filename}\")\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]  # Single caption only\n",
    "    print(f\"\\n🔍 Evaluating image: {filename} | Reference Caption:\\n{ground_truth}\\n{'-'*80}\")\n",
    "    \n",
    "    scores_for_image = []\n",
    "\n",
    "    for idx, gen_output in enumerate(outputs):  # Expecting 2 runs per image\n",
    "        metrics = evaluate_all_metrics(ground_truth, gen_output)\n",
    "        avg_metrics = {\n",
    "            \"CIDEr\": round(metrics[\"CIDEr\"], 4),\n",
    "            \"SPICE\": round(metrics[\"SPICE\"], 4),\n",
    "            \"cosine_similarity\": round(metrics[\"cosine_similarity\"], 4)\n",
    "        }\n",
    "\n",
    "        print(f\"📝 Prompt Run {idx+1} | CIDEr: {avg_metrics['CIDEr']} | SPICE: {avg_metrics['SPICE']} | CosSim: {avg_metrics['cosine_similarity']}\")\n",
    "        scores_for_image.append(avg_metrics)\n",
    "\n",
    "    all_metrics_scores[filename] = scores_for_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3dd6bfc-68aa-42d7-be1c-a03006d690db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📸 Image ID: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.3676  0.0000             0.1850\n",
      "Prompt 1 (Run 2)  1.3676  0.0000             0.1850\n",
      "Prompt 2 (Run 1)  0.1426  0.0317             0.4061\n",
      "Prompt 2 (Run 2)  0.1426  0.0317             0.4061\n",
      "Prompt 3 (Run 1)  0.3475  0.0455             0.3116\n",
      "Prompt 3 (Run 2)  0.3475  0.0455             0.3116\n",
      "Prompt 4 (Run 1)  1.0295  0.0274             0.2931\n",
      "Prompt 4 (Run 2)  1.0295  0.0274             0.2931\n",
      "Prompt 5 (Run 1)  1.9215  0.0286             0.5898\n",
      "Prompt 5 (Run 2)  1.9215  0.0286             0.5898\n",
      "Prompt 6 (Run 1)  0.2806  0.0000             0.5004\n",
      "Prompt 6 (Run 2)  0.2806  0.0000             0.5004\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.8278  0.0000             0.1561\n",
      "Prompt 1 (Run 2)  0.8278  0.0000             0.1561\n",
      "Prompt 2 (Run 1)  0.5670  0.0323             0.4710\n",
      "Prompt 2 (Run 2)  0.5670  0.0323             0.4710\n",
      "Prompt 3 (Run 1)  0.6041  0.0294             0.2461\n",
      "Prompt 3 (Run 2)  0.6041  0.0294             0.2461\n",
      "Prompt 4 (Run 1)  0.3106  0.0702             0.3189\n",
      "Prompt 4 (Run 2)  0.3106  0.0702             0.3189\n",
      "Prompt 5 (Run 1)  0.7406  0.0328             0.4621\n",
      "Prompt 5 (Run 2)  0.7406  0.0328             0.4621\n",
      "Prompt 6 (Run 1)  0.0620  0.0308             0.5205\n",
      "Prompt 6 (Run 2)  0.0620  0.0308             0.5205\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.5559  0.0000             0.1072\n",
      "Prompt 1 (Run 2)  0.5559  0.0000             0.1072\n",
      "Prompt 2 (Run 1)  0.7486  0.0000             0.4018\n",
      "Prompt 2 (Run 2)  0.7486  0.0000             0.4018\n",
      "Prompt 3 (Run 1)  0.7757  0.0435             0.5085\n",
      "Prompt 3 (Run 2)  0.7757  0.0435             0.5085\n",
      "Prompt 4 (Run 1)  0.4628  0.0417             0.3277\n",
      "Prompt 4 (Run 2)  0.4628  0.0417             0.3277\n",
      "Prompt 5 (Run 1)  0.5540  0.0328             0.5993\n",
      "Prompt 5 (Run 2)  0.5540  0.0328             0.5993\n",
      "Prompt 6 (Run 1)  0.1798  0.0417             0.5297\n",
      "Prompt 6 (Run 2)  0.1798  0.0417             0.5297\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.7339  0.0000             0.0707\n",
      "Prompt 1 (Run 2)  0.7339  0.0000             0.0707\n",
      "Prompt 2 (Run 1)  0.0337  0.0377             0.3319\n",
      "Prompt 2 (Run 2)  0.0337  0.0377             0.3319\n",
      "Prompt 3 (Run 1)  0.3380  0.0615             0.4369\n",
      "Prompt 3 (Run 2)  0.3380  0.0615             0.4369\n",
      "Prompt 4 (Run 1)  1.0616  0.0377             0.2275\n",
      "Prompt 4 (Run 2)  1.0616  0.0377             0.2275\n",
      "Prompt 5 (Run 1)  0.4793  0.0645             0.5621\n",
      "Prompt 5 (Run 2)  0.4793  0.0645             0.5621\n",
      "Prompt 6 (Run 1)  0.1019  0.0286             0.3424\n",
      "Prompt 6 (Run 2)  0.1019  0.0286             0.3424\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.2575  0.0000             0.0567\n",
      "Prompt 1 (Run 2)  0.2575  0.0000             0.0567\n",
      "Prompt 2 (Run 1)  1.1536  0.0833             0.4014\n",
      "Prompt 2 (Run 2)  1.1536  0.0833             0.4014\n",
      "Prompt 3 (Run 1)  0.8404  0.0645             0.3681\n",
      "Prompt 3 (Run 2)  0.8404  0.0645             0.3681\n",
      "Prompt 4 (Run 1)  0.4306  0.0308             0.2219\n",
      "Prompt 4 (Run 2)  0.4306  0.0308             0.2219\n",
      "Prompt 5 (Run 1)  0.9587  0.0303             0.3431\n",
      "Prompt 5 (Run 2)  0.9587  0.0303             0.3431\n",
      "Prompt 6 (Run 1)  0.0957  0.0000             0.3467\n",
      "Prompt 6 (Run 2)  0.0957  0.0000             0.3467\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.4100  0.0000             0.1290\n",
      "Prompt 1 (Run 2)  0.4100  0.0000             0.1290\n",
      "Prompt 2 (Run 1)  0.1325  0.0377             0.3268\n",
      "Prompt 2 (Run 2)  0.1325  0.0377             0.3268\n",
      "Prompt 3 (Run 1)  0.7713  0.0364             0.3393\n",
      "Prompt 3 (Run 2)  0.7713  0.0364             0.3393\n",
      "Prompt 4 (Run 1)  0.6282  0.0465             0.2624\n",
      "Prompt 4 (Run 2)  0.6282  0.0465             0.2624\n",
      "Prompt 5 (Run 1)  1.0061  0.0377             0.6124\n",
      "Prompt 5 (Run 2)  1.0061  0.0377             0.6124\n",
      "Prompt 6 (Run 1)  0.9661  0.0377             0.5492\n",
      "Prompt 6 (Run 2)  0.9661  0.0377             0.5492\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.2657  0.0000             0.0644\n",
      "Prompt 1 (Run 2)  0.2657  0.0000             0.0644\n",
      "Prompt 2 (Run 1)  0.1056  0.0000             0.3501\n",
      "Prompt 2 (Run 2)  0.1056  0.0000             0.3501\n",
      "Prompt 3 (Run 1)  0.8241  0.0286             0.2731\n",
      "Prompt 3 (Run 2)  0.8241  0.0286             0.2731\n",
      "Prompt 4 (Run 1)  0.2606  0.0303             0.2116\n",
      "Prompt 4 (Run 2)  0.2606  0.0303             0.2116\n",
      "Prompt 5 (Run 1)  0.9149  0.0299             0.3526\n",
      "Prompt 5 (Run 2)  0.9149  0.0299             0.3526\n",
      "Prompt 6 (Run 1)  0.1579  0.0323             0.4422\n",
      "Prompt 6 (Run 2)  0.1579  0.0323             0.4422\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.7423  0.0000             0.2378\n",
      "Prompt 1 (Run 2)  0.7423  0.0000             0.2378\n",
      "Prompt 2 (Run 1)  0.1319  0.0000             0.2976\n",
      "Prompt 2 (Run 2)  0.1319  0.0000             0.2976\n",
      "Prompt 3 (Run 1)  0.4841  0.0357             0.3304\n",
      "Prompt 3 (Run 2)  0.4841  0.0357             0.3304\n",
      "Prompt 4 (Run 1)  0.2950  0.1754             0.2488\n",
      "Prompt 4 (Run 2)  0.2950  0.1754             0.2488\n",
      "Prompt 5 (Run 1)  1.4875  0.0299             0.2695\n",
      "Prompt 5 (Run 2)  1.4875  0.0299             0.2695\n",
      "Prompt 6 (Run 1)  0.8334  0.0606             0.4512\n",
      "Prompt 6 (Run 2)  0.8334  0.0606             0.4512\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.2358  0.0000             0.2412\n",
      "Prompt 1 (Run 2)  0.2358  0.0000             0.2412\n",
      "Prompt 2 (Run 1)  0.4359  0.0308             0.3566\n",
      "Prompt 2 (Run 2)  0.4359  0.0308             0.3566\n",
      "Prompt 3 (Run 1)  0.7477  0.0278             0.3856\n",
      "Prompt 3 (Run 2)  0.7477  0.0278             0.3856\n",
      "Prompt 4 (Run 1)  0.4930  0.0377             0.3107\n",
      "Prompt 4 (Run 2)  0.4930  0.0377             0.3107\n",
      "Prompt 5 (Run 1)  0.7217  0.0303             0.4458\n",
      "Prompt 5 (Run 2)  0.7217  0.0303             0.4458\n",
      "Prompt 6 (Run 1)  0.2902  0.0000             0.3323\n",
      "Prompt 6 (Run 2)  0.2902  0.0000             0.3323\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.8545  0.0000             0.1464\n",
      "Prompt 1 (Run 2)  0.8545  0.0000             0.1464\n",
      "Prompt 2 (Run 1)  0.5516  0.0606             0.3584\n",
      "Prompt 2 (Run 2)  0.5516  0.0606             0.3584\n",
      "Prompt 3 (Run 1)  0.5037  0.0769             0.2865\n",
      "Prompt 3 (Run 2)  0.5037  0.0769             0.2865\n",
      "Prompt 4 (Run 1)  0.3503  0.0435             0.2248\n",
      "Prompt 4 (Run 2)  0.3503  0.0435             0.2248\n",
      "Prompt 5 (Run 1)  0.7229  0.0308             0.3675\n",
      "Prompt 5 (Run 2)  0.7229  0.0308             0.3675\n",
      "Prompt 6 (Run 1)  0.0330  0.0000             0.4119\n",
      "Prompt 6 (Run 2)  0.0330  0.0000             0.4119\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    print(f\"\\n📸 Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    df_temp = pd.DataFrame(scores)\n",
    "    prompt_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        prompt_num = (i // 2) + 1  # Prompts 1–6\n",
    "        run_num = (i % 2) + 1      # Run 1 or Run 2\n",
    "        prompt_labels.append(f\"Prompt {prompt_num} (Run {run_num})\")\n",
    "\n",
    "    df_temp.index = prompt_labels\n",
    "    print(df_temp.round(4))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b1b4f0-8cfc-4442-b982-908fba41a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results table\n",
    "table = wandb.Table(columns=[\"filename\", \"prompt_type\", \"run\", \"image\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "for filename in all_outputs:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]\n",
    "    image_pil = row.iloc[0][\"image\"]\n",
    "\n",
    "    for prompt_index in range(6):\n",
    "        for run in range(2):\n",
    "            row_idx = prompt_index * 2 + run\n",
    "            prediction = all_outputs[filename][row_idx] if row_idx < len(all_outputs[filename]) else \"N/A\"\n",
    "\n",
    "            table.add_data(\n",
    "                filename,\n",
    "                f\"Prompt {prompt_index + 1}\",\n",
    "                f\"Run {run + 1}\",\n",
    "                wandb.Image(image_pil),\n",
    "                ground_truth,\n",
    "                prediction\n",
    "            )\n",
    "\n",
    "wandb.log({\"Prompting Comparison Results\": table})\n",
    "\n",
    "# Log metrics for each prompt run\n",
    "for filename, scores in all_metrics_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        wandb.log({\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/CIDEr\": score[\"CIDEr\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/SPICE\": score[\"SPICE\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/Cosine\": score[\"cosine_similarity\"]\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_pixtral.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Loop over the 2 runs (Run 1, Run 2) — 6 prompts per run\n",
    "    for run_index in range(2):  # 0 for Run 1, 1 for Run 2\n",
    "        start_row = ws.max_row + 1\n",
    "\n",
    "        for prompt_index in range(6):  # Prompt 1 to 6\n",
    "            idx = prompt_index * 2 + run_index\n",
    "            ws.append([\n",
    "                model_name,\n",
    "                filename,\n",
    "                \"\",  # Placeholder for image\n",
    "                original_caption,\n",
    "                f\"Prompt {prompt_index + 1} (Run {run_index + 1})\",\n",
    "                inference_outputs[idx],\n",
    "                inference_times[idx],\n",
    "                vram_usages[idx],\n",
    "                metrics[idx][\"CIDEr\"],\n",
    "                metrics[idx][\"SPICE\"],\n",
    "                metrics[idx][\"cosine_similarity\"]\n",
    "            ])\n",
    "\n",
    "        # Merge A–D columns across 6 rows\n",
    "        for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "        # Apply alignment and formatting\n",
    "        align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "        align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "        for row_idx in range(start_row, start_row + 6):\n",
    "            for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top\n",
    "            for col_letter in [\"D\", \"F\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top_wrap\n",
    "            ws.row_dimensions[row_idx].height = 120\n",
    "\n",
    "        # Set column widths\n",
    "        ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "        ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "        # Embed image in this run block\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"[INFO] Inserting image for {filename} | Run {run_index + 1}\")\n",
    "            try:\n",
    "                img = ExcelImage(image_path)\n",
    "                img.width = 150\n",
    "                img.height = 150\n",
    "                img.anchor = f\"C{start_row}\"\n",
    "                ws.add_image(img)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    # Save workbook\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged both runs for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image for 000404.jpg | Run 1\n",
      "[INFO] Inserting image for 000404.jpg | Run 2\n",
      "✅ Logged both runs for 000404.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000422.jpg | Run 1\n",
      "[INFO] Inserting image for 000422.jpg | Run 2\n",
      "✅ Logged both runs for 000422.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000433.jpg | Run 1\n",
      "[INFO] Inserting image for 000433.jpg | Run 2\n",
      "✅ Logged both runs for 000433.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000481.jpg | Run 1\n",
      "[INFO] Inserting image for 000481.jpg | Run 2\n",
      "✅ Logged both runs for 000481.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000520.jpg | Run 1\n",
      "[INFO] Inserting image for 000520.jpg | Run 2\n",
      "✅ Logged both runs for 000520.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000541.jpg | Run 1\n",
      "[INFO] Inserting image for 000541.jpg | Run 2\n",
      "✅ Logged both runs for 000541.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000698.jpg | Run 1\n",
      "[INFO] Inserting image for 000698.jpg | Run 2\n",
      "✅ Logged both runs for 000698.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000740.jpg | Run 1\n",
      "[INFO] Inserting image for 000740.jpg | Run 2\n",
      "✅ Logged both runs for 000740.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000869.jpg | Run 1\n",
      "[INFO] Inserting image for 000869.jpg | Run 2\n",
      "✅ Logged both runs for 000869.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n",
      "[INFO] Inserting image for 000889.jpg | Run 1\n",
      "[INFO] Inserting image for 000889.jpg | Run 2\n",
      "✅ Logged both runs for 000889.jpg to prompt_tuning_results_cardd_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "for filename in all_outputs.keys():\n",
    "    log_prompt_metrics_to_excel(\n",
    "        filename=filename,\n",
    "        model_name=model_id,\n",
    "        inference_outputs=all_outputs[filename],\n",
    "        metrics=all_metrics_scores[filename],\n",
    "        inference_times=all_times[filename],\n",
    "        vram_usages=all_vram[filename],\n",
    "        df=df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>1.3676</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>0.185</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>1.3676</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>0.185</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>0.1426</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>0.4061</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>0.0317</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>0.1426</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>0.4061</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>0.0317</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>0.3475</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>0.3116</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>0.0455</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>0.3475</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>0.3116</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>0.0455</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>1.0295</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>0.2931</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>0.0274</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>1.0295</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>0.2931</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>0.0274</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>1.9215</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>0.5898</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>1.9215</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>0.5898</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>0.2806</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>0.5004</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>0.2806</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>0.5004</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>0.8278</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>0.1561</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>0.8278</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>0.1561</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>0.567</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>0.471</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>0.0323</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>0.567</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>0.471</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>0.0323</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>0.6041</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>0.2461</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>0.0294</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>0.6041</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>0.2461</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>0.0294</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>0.3106</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>0.3189</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>0.0702</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>0.3106</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>0.3189</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>0.0702</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>0.7406</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>0.4621</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>0.0328</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>0.7406</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>0.4621</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>0.0328</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>0.062</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>0.5205</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>0.062</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>0.5205</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>0.5559</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>0.1072</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>0.5559</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>0.1072</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>0.7486</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>0.4018</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>0.7486</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>0.4018</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>0.7757</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>0.5085</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>0.0435</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>0.7757</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>0.5085</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>0.0435</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>0.4628</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>0.3277</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>0.4628</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>0.3277</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>0.554</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>0.5993</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>0.0328</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>0.554</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>0.5993</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>0.0328</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>0.1798</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>0.5297</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>0.0417</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>0.1798</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>0.5297</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>0.0417</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>0.7339</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>0.0707</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>0.7339</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>0.0707</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>0.0337</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>0.3319</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>0.0337</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>0.3319</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>0.338</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>0.4369</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>0.0615</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>0.338</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>0.4369</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>0.0615</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>1.0616</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>0.2275</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>1.0616</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>0.2275</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>0.4793</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>0.5621</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>0.0645</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>0.4793</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>0.5621</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>0.0645</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>0.1019</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>0.3424</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>0.1019</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>0.3424</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>0.2575</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>0.0567</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>0.2575</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>0.0567</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>1.1536</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>0.4014</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>0.0833</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>1.1536</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>0.4014</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>0.0833</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>0.8404</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>0.3681</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>0.0645</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>0.8404</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>0.3681</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>0.0645</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>0.4306</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>0.2219</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>0.4306</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>0.2219</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>0.9587</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>0.3431</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>0.9587</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>0.3431</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>0.0957</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>0.3467</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>0.0957</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>0.3467</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>0.41</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>0.129</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>0.41</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>0.129</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>0.1325</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>0.3268</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>0.1325</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>0.3268</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>0.7713</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>0.3393</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>0.0364</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>0.7713</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>0.3393</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>0.0364</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>0.6282</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>0.2624</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>0.0465</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>0.6282</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>0.2624</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>0.0465</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>1.0061</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>0.6124</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>1.0061</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>0.6124</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>0.9661</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>0.5492</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>0.9661</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>0.5492</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>0.2657</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>0.0644</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>0.2657</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>0.0644</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>0.1056</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>0.3501</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>0.1056</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>0.3501</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>0.8241</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>0.2731</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>0.0286</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>0.8241</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>0.2731</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>0.0286</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>0.2606</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>0.2116</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>0.2606</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>0.2116</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>0.9149</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>0.3526</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>0.0299</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>0.9149</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>0.3526</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>0.0299</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>0.1579</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>0.4422</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>0.0323</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>0.1579</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>0.4422</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>0.0323</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>0.7423</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>0.2378</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>0.7423</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>0.2378</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>0.1319</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>0.2976</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>0.1319</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>0.2976</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>0.4841</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>0.3304</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>0.0357</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>0.4841</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>0.3304</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>0.0357</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>0.295</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>0.2488</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>0.1754</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>0.295</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>0.2488</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>0.1754</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>1.4875</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>0.2695</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>0.0299</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>1.4875</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>0.2695</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>0.0299</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>0.8334</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>0.4512</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>0.0606</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>0.8334</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>0.4512</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>0.0606</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>0.2358</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>0.2412</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>0.2358</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>0.2412</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>0.4359</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>0.3566</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>0.4359</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>0.3566</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>0.7477</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>0.3856</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>0.0278</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>0.7477</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>0.3856</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>0.0278</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>0.493</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>0.3107</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>0.0377</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>0.493</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>0.3107</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>0.0377</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>0.7217</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>0.4458</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>0.0303</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>0.7217</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>0.4458</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>0.0303</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>0.2902</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>0.3323</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>0.2902</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>0.3323</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>0.8545</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>0.1464</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>0.8545</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>0.1464</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>0.5516</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>0.3584</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>0.0606</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>0.5516</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>0.3584</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>0.0606</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>0.5037</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>0.2865</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>0.0769</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>0.5037</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>0.2865</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>0.0769</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>0.3503</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>0.2248</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>0.0435</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>0.3503</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>0.2248</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>0.0435</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>0.7229</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>0.3675</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>0.0308</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>0.7229</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>0.3675</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>0.0308</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>0.033</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>0.4119</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>0.033</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>0.4119</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Prompt-Eval-Pixtral12B-CarDD</strong> at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/geb148cc</a><br> View project at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250525_060638-geb148cc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421306c-8eb6-4008-98ea-22e4eb3a640c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
