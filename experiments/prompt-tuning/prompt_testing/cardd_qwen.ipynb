{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5405616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: We'll be using `/tmp/unsloth_compiled_cache` for temporary Unsloth patches.\n",
      "Standard import failed for UnslothCPOTrainer: No module named 'UnslothCPOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d39b1f2-179f-4fcd-b60e-dda5a1a6ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgayanukaa\u001b[0m (\u001b[33mvlm-research\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250524_201710-bevtg7g8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8' target=\"_blank\">Prompt-Eval-Qwen2.5VL7B-CarDD</a></strong> to <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x793dc3dba800>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Prompting-Experiments\",\n",
    "    name=\"Prompt-Eval-Qwen2.5VL7B-CarDD\",\n",
    "    group=\"prompting-experiments\",\n",
    "    tags=[\"qwen\", \"image-captioning\", \"prompting\", \"cardamage\"],\n",
    "    notes=\"Comparing handcrafted prompting strategies across multiple images and prompt types.\",\n",
    "    config={\n",
    "        \"model\": \"unsloth/Qwen2-VL-7B-Instruct\",\n",
    "        \"prompting\": \"handcrafted\",\n",
    "        \"num_prompts\": 6,\n",
    "        \"num_runs_per_prompt\": 2,\n",
    "        \"dataset\": \"cardd\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Qwen2_Vl patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664f11e322644903aa2dedf33538afe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b580764d21424a0a8d35ae08349f067f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e31083fbaf4a519c58f1ae573532bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/572 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec080704a8374b88aa4447f0cb18a421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24ef17e2c0b405a850e75a78b6f48bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7d159df46e42798db5b652258d9841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ed785ea84e43878e5112f435b33afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3045c9dda6364fc7b606837c4ccc1d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192adaa3888b41099a649265b178f001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c645b716d705426fa403ec116cacfad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9fcb741ff84a999ba4efeccfd70d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/572 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce34801a48564fe4adfd90629fafe40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33c5a208a014da3a0ca7df9b210a717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6942f0df2484da3b42013ff54bf81ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a61eeca4a14122a47e4b0d3e5660bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91147aff49d4f1eb5e136d6780c93e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a94f41d3fe4029b1a35ca912014335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7505e34972648e180c66f75a8d82ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"unsloth/Qwen2-VL-7B-Instruct\"  # change if needed\n",
    "#unsloth/Pixtral-12B-2409-bnb-4bit\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 image-caption pairs\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"/workspace/data/test_dataset\"\n",
    "captions_json = \"/workspace/data/test_set.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d52628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 First 5 entries:\n",
      "                                               image  \\\n",
      "0  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "1  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "2  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "3  <PIL.Image.Image image mode=RGB size=1000x750 ...   \n",
      "4  <PIL.Image.Image image mode=RGB size=1000x667 ...   \n",
      "\n",
      "                                             caption    filename  \n",
      "0  The car exhibits visible damage including a sc...  000481.jpg  \n",
      "1  The car exhibits significant damage to the win...  000433.jpg  \n",
      "2  The car exhibits a flat tire on the rear wheel...  000749.jpg  \n",
      "3  The car exhibits significant damage. The rear ...  000541.jpg  \n",
      "4  The car shows scratches along the side panel a...  000424.jpg   \n",
      "\n",
      "📋 Column types:\n",
      "image       object\n",
      "caption     object\n",
      "filename    object\n",
      "dtype: object\n",
      "\n",
      "🔎 Size\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"📋 Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n🔎 Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"🔹 Image: {filename}\")\n",
    "    print(f\"🧾 Prompt: {prompt}\")\n",
    "    print(\"📤 Output:\")\n",
    "    \n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"⏱️ Time taken: {time_taken} sec | 🧠 VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a6f630-0b10-49de-9b34-e2da40a4bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running prompts for image: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front of the car is damaged, with the hood crumpled and the front bumper and headlights broken. There is also a visible dent on the side of the car. Another car is partially visible in the background, suggesting that the accident involved multiple vehicles. The scene appears to be on a street or parking area.<|im_end|>\n",
      "⏱️ Time taken: 5.152 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front of the car is damaged, with the hood crumpled and the front bumper and headlights broken. There is also a visible dent on the side of the car. Another car is partially visible in the background, suggesting that the accident involved multiple vehicles. The scene appears to be on a street or parking area.<|im_end|>\n",
      "⏱️ Time taken: 4.965 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a red sedan that has sustained significant damage in a collision. The front of the car is severely crumpled, with the hood and front bumper visibly damaged. The front grille and headlights are also damaged, and the car's hood is raised, revealing the engine compartment. There is another vehicle partially visible in the background, which appears to have been involved in the accident as well. The scene suggests a serious collision that has caused substantial damage to the vehicles involved.<|im_end|>\n",
      "⏱️ Time taken: 6.384 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a red sedan that has sustained significant damage in a collision. The front of the car is severely crumpled, with the hood and front bumper visibly damaged. The front grille and headlights are also damaged, and the car's hood is raised, revealing the engine compartment. There is another vehicle partially visible in the background, which appears to have been involved in the accident as well. The scene suggests a serious collision that has caused substantial damage to the vehicles involved.<|im_end|>\n",
      "⏱️ Time taken: 6.368 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car with its hood open, parked on the side of the road. The front of the car appears to have sustained significant damage, including a crumpled hood and a broken headlight. There is another car in the background that also seems to have been involved in the accident, with its front wheel and tire visibly damaged. The scene suggests a recent collision or accident.<|im_end|>\n",
      "⏱️ Time taken: 4.938 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car with its hood open, parked on the side of the road. The front of the car appears to have sustained significant damage, including a crumpled hood and a broken headlight. There is another car in the background that also seems to have been involved in the accident, with its front wheel and tire visibly damaged. The scene suggests a recent collision or accident.<|im_end|>\n",
      "⏱️ Time taken: 4.879 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage in a collision. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front End Damage**:\n",
      "   - The front bumper is completely detached and hanging off the front of the car.\n",
      "   - The hood is crumpled and pushed back, indicating a severe impact.\n",
      "   - The front grille is damaged and bent out of shape.\n",
      "   - The front headlights are shattered and the front bumper is completely detached.\n",
      "\n",
      "2. **Left Side Damage**:\n",
      "   - The left headlight is damaged and appears to be out of alignment.\n",
      "   - The front fender on the left\n",
      "⏱️ Time taken: 7.259 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage in a collision. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front End Damage**:\n",
      "   - The front bumper is completely detached and hanging off the front of the car.\n",
      "   - The hood is crumpled and pushed back, indicating a severe impact.\n",
      "   - The front grille is damaged and bent out of shape.\n",
      "   - The front headlights are shattered and the front bumper is completely detached.\n",
      "\n",
      "2. **Left Side Damage**:\n",
      "   - The left headlight is damaged and appears to be out of alignment.\n",
      "   - The front fender on the left\n",
      "⏱️ Time taken: 7.463 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1>. The severity appears to be <severity_1>. Additional notes: The car has sustained significant damage to the front, including a crumpled hood, broken headlights, and a damaged grille.<|im_end|>\n",
      "⏱️ Time taken: 3.881 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1>. The severity appears to be <severity_1>. Additional notes: The car has sustained significant damage to the front, including a crumpled hood, broken headlights, and a damaged grille.<|im_end|>\n",
      "⏱️ Time taken: 3.739 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Hood; Severity: Moderate; Notes: The hood is significantly dented and deformed, indicating a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 2.386 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000404.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Hood; Severity: Moderate; Notes: The hood is significantly dented and deformed, indicating a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 2.448 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front end of the car is heavily damaged, with the hood crumpled and the front bumper and other components visibly damaged. The car is on a road, and there are visible signs of the accident, such as debris and possibly fluid leaks. This type of damage typically occurs in a head-on collision or a severe impact from another vehicle or object.<|im_end|>\n",
      "⏱️ Time taken: 5.672 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front end of the car is heavily damaged, with the hood crumpled and the front bumper and other components visibly damaged. The car is on a road, and there are visible signs of the accident, such as debris and possibly fluid leaks. This type of damage typically occurs in a head-on collision or a severe impact from another vehicle or object.<|im_end|>\n",
      "⏱️ Time taken: 5.668 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a severely damaged sedan car. The front end of the car is crumpled and bent, indicating a significant impact. The hood is dented and folded, and the front bumper is completely detached and hanging off the front of the car. The front suspension and other mechanical components are exposed and appear to be damaged. The car is parked on a street, and there are visible signs of oil or fluid leaking from the vehicle. The overall condition of the car suggests it has been involved in a severe collision.<|im_end|>\n",
      "⏱️ Time taken: 6.871 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a severely damaged sedan car. The front end of the car is crumpled and bent, indicating a significant impact. The hood is dented and folded, and the front bumper is completely detached and hanging off the front of the car. The front suspension and other mechanical components are exposed and appear to be damaged. The car is parked on a street, and there are visible signs of oil or fluid leaking from the vehicle. The overall condition of the car suggests it has been involved in a severe collision.<|im_end|>\n",
      "⏱️ Time taken: 7.006 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front end of the car is heavily damaged, with the hood crumpled and the front bumper and bodywork significantly bent and torn. The damage suggests that the car was involved in a severe impact, possibly with another vehicle or an object. The car is parked on the side of the road, and there are no visible signs of movement or other vehicles involved in the accident.<|im_end|>\n",
      "⏱️ Time taken: 5.918 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car that has been involved in a collision. The front end of the car is heavily damaged, with the hood crumpled and the front bumper and bodywork significantly bent and torn. The damage suggests that the car was involved in a severe impact, possibly with another vehicle or an object. The car is parked on the side of the road, and there are no visible signs of movement or other vehicles involved in the accident.<|im_end|>\n",
      "⏱️ Time taken: 6.02 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage in a collision. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front End Damage**:\n",
      "   - The front bumper is completely detached and is hanging off the front of the car.\n",
      "   - The hood is severely dented and crumpled, indicating a high-impact collision.\n",
      "   - The front grille and headlights are likely damaged or missing.\n",
      "   - The front fender is also crumpled and distorted, with the front wheel well area showing significant deformation.\n",
      "\n",
      "2. **Body Damage**:\n",
      "   - The side of the car shows extensive dents and cre\n",
      "⏱️ Time taken: 8.504 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage in a collision. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front End Damage**:\n",
      "   - The front bumper is completely detached and is hanging off the front of the car.\n",
      "   - The hood is severely dented and crumpled, indicating a high-impact collision.\n",
      "   - The front grille and headlights are likely damaged or missing.\n",
      "   - The front fender is also crumpled and distorted, with the front wheel well area showing significant deformation.\n",
      "\n",
      "2. **Body Damage**:\n",
      "   - The side of the car shows extensive dents and cre\n",
      "⏱️ Time taken: 8.44 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The image shows a car that has sustained significant damage. The hood and front end of the car are heavily crumpled, indicating a severe impact. The severity of the damage appears to be high, with the hood and front end of the car extensively bent and deformed. Additional notes include:\n",
      "\n",
      "- The car appears to have been involved in a collision, likely with another vehicle or object.\n",
      "- There are visible signs of mechanical damage, such as bent metal and exposed components.\n",
      "- The damage extends from the front bumper to the hood, suggesting a head-on collision or a severe impact from the front.\n",
      "- The car's front end is completely\n",
      "⏱️ Time taken: 8.433 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The image shows a car that has sustained significant damage. The hood and front end of the car are heavily crumpled, indicating a severe impact. The severity of the damage appears to be high, with the hood and front end of the car extensively bent and deformed. Additional notes include:\n",
      "\n",
      "- The car appears to have been involved in a collision, likely with another vehicle or object.\n",
      "- There are visible signs of mechanical damage, such as bent metal and exposed components.\n",
      "- The damage extends from the front bumper to the hood, suggesting a head-on collision or a severe impact from the front.\n",
      "- The car's front end is completely\n",
      "⏱️ Time taken: 8.473 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Front End; Severity: Moderate; Notes: The front end of the car shows significant deformation, indicating a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 2.37 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000422.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Front End; Severity: Moderate; Notes: The front end of the car shows significant deformation, indicating a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 2.355 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a severely damaged car windshield. The glass is shattered into numerous pieces, indicating a significant impact or accident. The windshield is cracked and fragmented, with pieces of glass scattered across the surface. The car's hood is also visible, and it appears to be in a similar state of damage. This type of damage typically occurs in high-speed collisions or severe accidents.<|im_end|>\n",
      "⏱️ Time taken: 5.103 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a severely damaged car windshield. The glass is shattered into numerous pieces, indicating a significant impact or accident. The windshield is cracked and fragmented, with pieces of glass scattered across the surface. The car's hood is also visible, and it appears to be in a similar state of damage. This type of damage typically occurs in high-speed collisions or severe accidents.<|im_end|>\n",
      "⏱️ Time taken: 4.993 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a severely damaged car with a shattered windshield. The glass is broken into numerous pieces, and the front of the car appears to be significantly damaged. The hood of the car is also bent and damaged, indicating that the vehicle has been involved in a severe collision. The overall condition of the car suggests that it has sustained significant impact forces, likely from a high-speed accident.<|im_end|>\n",
      "⏱️ Time taken: 5.189 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a severely damaged car with a shattered windshield. The glass is broken into numerous pieces, and the front of the car appears to be significantly damaged. The hood of the car is also bent and damaged, indicating that the vehicle has been involved in a severe collision. The overall condition of the car suggests that it has sustained significant impact forces, likely from a high-speed accident.<|im_end|>\n",
      "⏱️ Time taken: 5.166 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car with a severely damaged windshield. The windshield is shattered into numerous pieces, indicating that the car has been involved in a significant accident. The car is parked on the side of the road, and the damage is clearly visible.<|im_end|>\n",
      "⏱️ Time taken: 3.398 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car with a severely damaged windshield. The windshield is shattered into numerous pieces, indicating that the car has been involved in a significant accident. The car is parked on the side of the road, and the damage is clearly visible.<|im_end|>\n",
      "⏱️ Time taken: 3.422 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image has sustained significant damage to its front windshield. The windshield is shattered into numerous pieces, with cracks and fragments extending across the entire surface. The damage appears to be extensive, indicating a severe impact. The hood of the car is also visible and shows signs of deformation, suggesting that the front end of the vehicle was involved in a collision. The overall condition of the car indicates that it has been involved in a serious accident.<|im_end|>\n",
      "⏱️ Time taken: 5.862 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image has sustained significant damage to its front windshield. The windshield is shattered into numerous pieces, with cracks and fragments extending across the entire surface. The damage appears to be extensive, indicating a severe impact. The hood of the car is also visible and shows signs of deformation, suggesting that the front end of the vehicle was involved in a collision. The overall condition of the car indicates that it has been involved in a serious accident.<|im_end|>\n",
      "⏱️ Time taken: 5.522 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the windshield. The damage type is <damage_type_1>, which is a shattered windshield. The severity appears to be <severity_1>, indicating that the windshield is completely broken and likely unsafe to drive with. Additional notes: The windshield has multiple cracks and pieces of glass scattered across it, suggesting a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 5.046 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the windshield. The damage type is <damage_type_1>, which is a shattered windshield. The severity appears to be <severity_1>, indicating that the windshield is completely broken and likely unsafe to drive with. Additional notes: The windshield has multiple cracks and pieces of glass scattered across it, suggesting a severe impact.<|im_end|>\n",
      "⏱️ Time taken: 4.98 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Impact; Affected Part: Windshield; Severity: Severe; Notes: The windshield is completely shattered, with pieces of glass scattered across the front of the vehicle.<|im_end|>\n",
      "⏱️ Time taken: 2.43 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000433.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Impact; Affected Part: Windshield; Severity: Severe; Notes: The windshield is completely shattered, with pieces of glass scattered across the front of the vehicle.<|im_end|>\n",
      "⏱️ Time taken: 2.196 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "这张图片显示了一辆汽车的前部，车身上有明显的刮痕和油漆剥落。车轮和轮胎清晰可见，背景模糊，可能是在户外的停车场或街道上。<|im_end|>\n",
      "⏱️ Time taken: 2.411 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "这张图片显示了一辆汽车的前部，车身上有明显的刮痕和油漆剥落。车轮和轮胎清晰可见，背景模糊，可能是在户外的停车场或街道上。<|im_end|>\n",
      "⏱️ Time taken: 2.743 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's front bumper area. There is visible damage to the paint on the bumper, with some of the paint chipped off, revealing the underlying material. The damage appears to be localized and does not seem to affect the structural integrity of the bumper. The tire is also visible, and it appears to be in good condition. The background is blurred, but it seems to be an outdoor setting, possibly a parking lot or a driveway.<|im_end|>\n",
      "⏱️ Time taken: 6.311 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's front bumper area. There is visible damage to the paint on the bumper, with some of the paint chipped off, revealing the underlying material. The damage appears to be localized and does not seem to affect the structural integrity of the bumper. The tire is also visible, and it appears to be in good condition. The background is blurred, but it seems to be an outdoor setting, possibly a parking lot or a driveway.<|im_end|>\n",
      "⏱️ Time taken: 6.366 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's front bumper and tire. The bumper has visible damage, with some of the paint chipped off, revealing the underlying material. The tire appears to be in good condition. The background is blurred, but it seems to be an outdoor setting, possibly a parking lot or a roadside.<|im_end|>\n",
      "⏱️ Time taken: 4.468 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's front bumper and tire. The bumper has visible damage, with some of the paint chipped off, revealing the underlying material. The tire appears to be in good condition. The background is blurred, but it seems to be an outdoor setting, possibly a parking lot or a roadside.<|im_end|>\n",
      "⏱️ Time taken: 4.533 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image has sustained damage to its front bumper. The paint on the bumper is chipped and scratched, revealing the underlying material. The damage appears to be localized to the lower section of the bumper, where the paint has been scraped off, exposing the metal beneath. The tire and wheel are also visible, and there are no visible signs of damage to the tire or wheel itself. The overall condition of the car suggests that it has been involved in a minor collision or刮蹭事件.<|im_end|>\n",
      "⏱️ Time taken: 6.822 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image has sustained damage to its front bumper. The paint on the bumper is chipped and scratched, revealing the underlying material. The damage appears to be localized to the lower section of the bumper, where the paint has been scraped off, exposing the metal beneath. The tire and wheel are also visible, and there are no visible signs of damage to the tire or wheel itself. The overall condition of the car suggests that it has been involved in a minor collision or刮蹭事件.<|im_end|>\n",
      "⏱️ Time taken: 7.086 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the bumper. The <damage_type_1> is a scratch. The severity appears to be minor. Additional notes: The scratch is located on the lower part of the bumper and does not appear to be deep or extensive.<|im_end|>\n",
      "⏱️ Time taken: 3.883 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the bumper. The <damage_type_1> is a scratch. The severity appears to be minor. Additional notes: The scratch is located on the lower part of the bumper and does not appear to be deep or extensive.<|im_end|>\n",
      "⏱️ Time taken: 3.807 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Scratch; Affected Part: Car Body; Severity: Minor; Notes: The scratch is shallow and does not penetrate the paint.<|im_end|>\n",
      "⏱️ Time taken: 2.158 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000481.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Scratch; Affected Part: Car Body; Severity: Minor; Notes: The scratch is shallow and does not penetrate the paint.<|im_end|>\n",
      "⏱️ Time taken: 2.16 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car. The front left side of the car has sustained significant damage, including a dented fender and a crumpled area near the headlight. The headlight is also damaged, and there are visible cracks and deformities on the car's surface. The tire and wheel are also visible, and the car appears to be stationary.<|im_end|>\n",
      "⏱️ Time taken: 5.235 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car. The front left side of the car has sustained significant damage, including a dented fender and a crumpled area near the headlight. The headlight is also damaged, and there are visible cracks and deformities on the car's surface. The tire and wheel are also visible, and the car appears to be stationary.<|im_end|>\n",
      "⏱️ Time taken: 5.193 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a white sedan with significant damage to the front left side. The front bumper is visibly crumpled and dented, indicating a collision. The headlight on the affected side is also damaged, with the glass and lens likely shattered. The fender and hood appear to be pushed inwards, and there are visible scratches and scuffs on the paint. The overall condition suggests that the car has been involved in a minor to moderate collision.<|im_end|>\n",
      "⏱️ Time taken: 6.069 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a white sedan with significant damage to the front left side. The front bumper is visibly crumpled and dented, indicating a collision. The headlight on the affected side is also damaged, with the glass and lens likely shattered. The fender and hood appear to be pushed inwards, and there are visible scratches and scuffs on the paint. The overall condition suggests that the car has been involved in a minor to moderate collision.<|im_end|>\n",
      "⏱️ Time taken: 6.098 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car parked on the side of the road. The front left side of the car has sustained significant damage, including a凹陷的保险杠和前灯受损。车头部分有明显的变形和刮痕，表明可能发生了碰撞事故。<|im_end|>\n",
      "⏱️ Time taken: 3.948 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car parked on the side of the road. The front left side of the car has sustained significant damage, including a凹陷的保险杠和前灯受损。车头部分有明显的变形和刮痕，表明可能发生了碰撞事故。<|im_end|>\n",
      "⏱️ Time taken: 3.91 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage to the front left side. The following details can be observed:\n",
      "\n",
      "1. **Front Bumper**: The front bumper is heavily dented and deformed, indicating a severe impact. The paint on the bumper is likely chipped or removed in some areas.\n",
      "\n",
      "2. **Headlight**: The headlight on the front left side is damaged. The glass is likely shattered, and the housing may be cracked or broken.\n",
      "\n",
      "3. **Fender**: The fender on the front left side is also heavily damaged. The metal is bent and dented, and the paint is likely chipped\n",
      "⏱️ Time taken: 8.493 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage to the front left side. The following details can be observed:\n",
      "\n",
      "1. **Front Bumper**: The front bumper is heavily dented and deformed, indicating a severe impact. The paint on the bumper is likely chipped or removed in some areas.\n",
      "\n",
      "2. **Headlight**: The headlight on the front left side is damaged. The glass is likely shattered, and the housing may be cracked or broken.\n",
      "\n",
      "3. **Fender**: The fender on the front left side is also heavily damaged. The metal is bent and dented, and the paint is likely chipped\n",
      "⏱️ Time taken: 8.571 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the front bumper. The damage type appears to be a dent or a crease, which is likely caused by a collision. The severity of the damage seems to be moderate, as the dent is noticeable but not completely collapsed. Additional notes include that the damage is localized to the front bumper area and there are no signs of major structural damage to the car.<|im_end|>\n",
      "⏱️ Time taken: 5.333 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the front bumper. The damage type appears to be a dent or a crease, which is likely caused by a collision. The severity of the damage seems to be moderate, as the dent is noticeable but not completely collapsed. Additional notes include that the damage is localized to the front bumper area and there are no signs of major structural damage to the car.<|im_end|>\n",
      "⏱️ Time taken: 5.423 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Front Bumper; Severity: Moderate; Notes: The front bumper of the vehicle is visibly damaged, with dents and cracks indicating significant impact force.<|im_end|>\n",
      "⏱️ Time taken: 2.816 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000520.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Structural Damage; Affected Part: Front Bumper; Severity: Moderate; Notes: The front bumper of the vehicle is visibly damaged, with dents and cracks indicating significant impact force.<|im_end|>\n",
      "⏱️ Time taken: 2.902 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a black car that appears to have been involved in an accident. The rear bumper is damaged, and the tire on the affected side is瘪了 (flattened). The car's rear light is also damaged, with the glass broken and the reflector bent. The overall condition of the car suggests significant damage, likely from a collision.<|im_end|>\n",
      "⏱️ Time taken: 4.927 sec | 🧠 VRAM used: 0.371 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a black car that appears to have been involved in an accident. The rear bumper is damaged, and the tire on the affected side is瘪了 (flattened). The car's rear light is also damaged, with the glass broken and the reflector bent. The overall condition of the car suggests significant damage, likely from a collision.<|im_end|>\n",
      "⏱️ Time taken: 4.645 sec | 🧠 VRAM used: 0.371 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a black sedan with significant damage to the rear end. The rear bumper is completely detached and hanging down, exposing the exhaust pipe. The rear fender and part of the body are also damaged, with dents and cracks visible. The tire on the affected side appears to be flat or damaged. The overall condition of the car suggests it has been involved in a severe rear-end collision.<|im_end|>\n",
      "⏱️ Time taken: 4.536 sec | 🧠 VRAM used: 0.372 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a black sedan with significant damage to the rear end. The rear bumper is completely detached and hanging down, exposing the exhaust pipe. The rear fender and part of the body are also damaged, with dents and cracks visible. The tire on the affected side appears to be flat or damaged. The overall condition of the car suggests it has been involved in a severe rear-end collision.<|im_end|>\n",
      "⏱️ Time taken: 4.319 sec | 🧠 VRAM used: 0.372 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a black car that appears to have been involved in an accident. The rear bumper and the rear wheel area are damaged, with the bumper visibly crumpled and the tire damaged. The car is parked on the side of the road, and the damage is evident on the rear end of the vehicle.<|im_end|>\n",
      "⏱️ Time taken: 3.458 sec | 🧠 VRAM used: 0.373 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a black car that appears to have been involved in an accident. The rear bumper and the rear wheel area are damaged, with the bumper visibly crumpled and the tire damaged. The car is parked on the side of the road, and the damage is evident on the rear end of the vehicle.<|im_end|>\n",
      "⏱️ Time taken: 3.552 sec | 🧠 VRAM used: 0.373 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here is a detailed description of the car's condition:\n",
      "\n",
      "1. **Rear Bumper**: The rear bumper is heavily damaged, with significant deformation and dents. The bumper is likely to be replaced or repaired extensively.\n",
      "\n",
      "2. **Tail Light**: The tail light on the right side of the car is damaged, with the lens possibly shattered or cracked. The tail light assembly may need to be replaced.\n",
      "\n",
      "3. **Rear Bumper Cover**: The rear bumper cover is also damaged, with significant deformation and dents. The cover may need to be replaced or repaired.\n",
      "\n",
      "4\n",
      "⏱️ Time taken: 6.795 sec | 🧠 VRAM used: 0.374 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here is a detailed description of the car's condition:\n",
      "\n",
      "1. **Rear Bumper**: The rear bumper is heavily damaged, with significant deformation and dents. The bumper is likely to be replaced or repaired extensively.\n",
      "\n",
      "2. **Tail Light**: The tail light on the right side of the car is damaged, with the lens possibly shattered or cracked. The tail light assembly may need to be replaced.\n",
      "\n",
      "3. **Rear Bumper Cover**: The rear bumper cover is also damaged, with significant deformation and dents. The cover may need to be replaced or repaired.\n",
      "\n",
      "4\n",
      "⏱️ Time taken: 8.659 sec | 🧠 VRAM used: 0.374 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the rear bumper. The damage type appears to be <damage_type_1>, which is a dent or crease. The severity of the damage seems to be <severity_1>, indicating that it is a moderate amount of damage. Additional notes include that the rear bumper is visibly damaged and there is a noticeable dent on the rear fender.<|im_end|>\n",
      "⏱️ Time taken: 5.419 sec | 🧠 VRAM used: 0.381 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the rear bumper. The damage type appears to be <damage_type_1>, which is a dent or crease. The severity of the damage seems to be <severity_1>, indicating that it is a moderate amount of damage. Additional notes include that the rear bumper is visibly damaged and there is a noticeable dent on the rear fender.<|im_end|>\n",
      "⏱️ Time taken: 5.489 sec | 🧠 VRAM used: 0.381 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Impact; Affected Part: Rear bumper, rear wheel; Severity: Moderate; Notes: The rear bumper is dented and the rear wheel is damaged, indicating a collision.<|im_end|>\n",
      "⏱️ Time taken: 2.83 sec | 🧠 VRAM used: 0.375 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000541.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Impact; Affected Part: Rear bumper, rear wheel; Severity: Moderate; Notes: The rear bumper is dented and the rear wheel is damaged, indicating a collision.<|im_end|>\n",
      "⏱️ Time taken: 2.707 sec | 🧠 VRAM used: 0.375 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that appears to have been involved in a collision. The rear end of the car is damaged, with the rear bumper and taillights visibly broken and displaced. The car's door is open, and the interior is visible, showing that the car is stationary. The damage suggests that the car may require repair or replacement of the rear bumper and taillights.<|im_end|>\n",
      "⏱️ Time taken: 4.23 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car that appears to have been involved in a collision. The rear end of the car is damaged, with the rear bumper and taillights visibly broken and displaced. The car's door is open, and the interior is visible, showing that the car is stationary. The damage suggests that the car may require repair or replacement of the rear bumper and taillights.<|im_end|>\n",
      "⏱️ Time taken: 4.593 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a sedan car that appears to have been involved in a collision. The damage includes:\n",
      "\n",
      "1. **Front Bumper**: The front bumper is visibly damaged and crumpled, indicating a significant impact.\n",
      "2. **Front Left Door**: The front left door is open and appears to be dented and damaged.\n",
      "3. **Front Left Headlight**: The front left headlight is shattered and missing, with the housing and wiring exposed.\n",
      "4. **Front Left Side Panel**: The front left side panel of the car is dented and crumpled, with visible damage to the paint.\n",
      "5. **Front Left Wheel**:\n",
      "⏱️ Time taken: 8.039 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a sedan car that appears to have been involved in a collision. The damage includes:\n",
      "\n",
      "1. **Front Bumper**: The front bumper is visibly damaged and crumpled, indicating a significant impact.\n",
      "2. **Front Left Door**: The front left door is open and appears to be dented and damaged.\n",
      "3. **Front Left Headlight**: The front left headlight is shattered and missing, with the housing and wiring exposed.\n",
      "4. **Front Left Side Panel**: The front left side panel of the car is dented and crumpled, with visible damage to the paint.\n",
      "5. **Front Left Wheel**:\n",
      "⏱️ Time taken: 8.078 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car that appears to have been involved in an accident. The car has sustained significant damage, particularly to the rear end, where the bumper and taillights are visibly broken and damaged. The rear door is open, and the interior of the car is visible. The car is parked on the side of the road, and there is a gas station in the background.<|im_end|>\n",
      "⏱️ Time taken: 4.246 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car that appears to have been involved in an accident. The car has sustained significant damage, particularly to the rear end, where the bumper and taillights are visibly broken and damaged. The rear door is open, and the interior of the car is visible. The car is parked on the side of the road, and there is a gas station in the background.<|im_end|>\n",
      "⏱️ Time taken: 5.234 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front Left Side:**\n",
      "   - The front left fender and bumper are heavily damaged, with significant dents and deformations.\n",
      "   - The front left headlight is shattered and missing, exposing the internal components.\n",
      "   - The front left door is also damaged, with the door panel and window frame appearing to be bent and misaligned.\n",
      "\n",
      "2. **Front Right Side:**\n",
      "   - The front right fender and bumper are also damaged, with similar deformations and dents.\n",
      "   - The front right head\n",
      "⏱️ Time taken: 8.316 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front Left Side:**\n",
      "   - The front left fender and bumper are heavily damaged, with significant dents and deformations.\n",
      "   - The front left headlight is shattered and missing, exposing the internal components.\n",
      "   - The front left door is also damaged, with the door panel and window frame appearing to be bent and misaligned.\n",
      "\n",
      "2. **Front Right Side:**\n",
      "   - The front right fender and bumper are also damaged, with similar deformations and dents.\n",
      "   - The front right head\n",
      "⏱️ Time taken: 8.497 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the rear bumper. The damage type is <damage_type_1>, which appears to be a significant dent and possible structural damage. The severity seems to be <severity_1>, indicating that the car has sustained substantial damage. Additional notes include that the rear bumper is completely damaged and the car door is slightly bent.<|im_end|>\n",
      "⏱️ Time taken: 4.983 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the rear bumper. The damage type is <damage_type_1>, which appears to be a significant dent and possible structural damage. The severity seems to be <severity_1>, indicating that the car has sustained substantial damage. Additional notes include that the rear bumper is completely damaged and the car door is slightly bent.<|im_end|>\n",
      "⏱️ Time taken: 4.907 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Collision; Affected Part: Rear bumper, rear lights, and door; Severity: Moderate; Notes: The car has sustained significant damage to the rear end, including broken rear lights and a dented bumper. The door is also damaged, indicating a forceful impact.<|im_end|>\n",
      "⏱️ Time taken: 3.675 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000698.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Collision; Affected Part: Rear bumper, rear lights, and door; Severity: Moderate; Notes: The car has sustained significant damage to the rear end, including broken rear lights and a dented bumper. The door is also damaged, indicating a forceful impact.<|im_end|>\n",
      "⏱️ Time taken: 3.897 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a car tire on a vehicle that appears to be in a state of disrepair. The tire is mounted on a metal wheel with a five-lug pattern. The car's body is heavily rusted and has peeling paint, indicating it has been exposed to the elements for a long time. The overall condition suggests the vehicle has been abandoned or is no longer in use.<|im_end|>\n",
      "⏱️ Time taken: 4.922 sec | 🧠 VRAM used: 0.371 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a car tire on a vehicle that appears to be in a state of disrepair. The tire is mounted on a metal wheel with a five-lug pattern. The car's body is heavily rusted and has peeling paint, indicating it has been exposed to the elements for a long time. The overall condition suggests the vehicle has been abandoned or is no longer in use.<|im_end|>\n",
      "⏱️ Time taken: 5.386 sec | 🧠 VRAM used: 0.371 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's rear wheel and part of the body. The car appears to be in a state of disrepair. Here are the specific damages observed:\n",
      "\n",
      "1. **Paint Peeling and Chipping**: The paint on the car's body is peeling and chipping off, particularly noticeable on the rear fender and the rear wheel area. This indicates significant wear and exposure to the elements over time.\n",
      "\n",
      "2. **Rust**: There is visible rust on the rear fender and the wheel area, suggesting that the car has been exposed to moisture and has not been maintained properly.\n",
      "\n",
      "3. **Tire\n",
      "⏱️ Time taken: 6.904 sec | 🧠 VRAM used: 0.372 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a close-up of a car's rear wheel and part of the body. The car appears to be in a state of disrepair. Here are the specific damages observed:\n",
      "\n",
      "1. **Paint Peeling and Chipping**: The paint on the car's body is peeling and chipping off, particularly noticeable on the rear fender and the rear wheel area. This indicates significant wear and exposure to the elements over time.\n",
      "\n",
      "2. **Rust**: There is visible rust on the rear fender and the wheel area, suggesting that the car has been exposed to moisture and has not been maintained properly.\n",
      "\n",
      "3. **Tire\n",
      "⏱️ Time taken: 6.955 sec | 🧠 VRAM used: 0.372 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car parked on the side of the road. The car appears to be old and has significant rust and peeling paint. The tire is flat, and the car's body shows signs of wear and tear. The overall condition of the car suggests it has been abandoned or is in a state of disrepair.<|im_end|>\n",
      "⏱️ Time taken: 4.364 sec | 🧠 VRAM used: 0.373 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car parked on the side of the road. The car appears to be old and has significant rust and peeling paint. The tire is flat, and the car's body shows signs of wear and tear. The overall condition of the car suggests it has been abandoned or is in a state of disrepair.<|im_end|>\n",
      "⏱️ Time taken: 4.637 sec | 🧠 VRAM used: 0.373 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to be in a very poor condition. The paint is chipped and peeling off in various areas, particularly around the wheel well and the rear fender. The body of the car is heavily rusted, with rust patches visible on the metal surfaces. The tire is flat, indicating that it may have been damaged or has been out of use for a long time. The overall appearance suggests that the car has been neglected and is in need of significant repair work.<|im_end|>\n",
      "⏱️ Time taken: 6.44 sec | 🧠 VRAM used: 0.374 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to be in a very poor condition. The paint is chipped and peeling off in various areas, particularly around the wheel well and the rear fender. The body of the car is heavily rusted, with rust patches visible on the metal surfaces. The tire is flat, indicating that it may have been damaged or has been out of use for a long time. The overall appearance suggests that the car has been neglected and is in need of significant repair work.<|im_end|>\n",
      "⏱️ Time taken: 5.36 sec | 🧠 VRAM used: 0.374 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The part of the car shown in the image is the rear fender. The damage type appears to be rust and paint peeling off, with the severity being moderate. Additional notes include the presence of dirt and grime on the surface, indicating that the car has been exposed to the elements for a significant amount of time.<|im_end|>\n",
      "⏱️ Time taken: 3.621 sec | 🧠 VRAM used: 0.381 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The part of the car shown in the image is the rear fender. The damage type appears to be rust and paint peeling off, with the severity being moderate. Additional notes include the presence of dirt and grime on the surface, indicating that the car has been exposed to the elements for a significant amount of time.<|im_end|>\n",
      "⏱️ Time taken: 3.689 sec | 🧠 VRAM used: 0.381 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Flat tire; Affected Part: Front left tire; Severity: Moderate; Notes: The tire is deflated and appears to be damaged, possibly due to a puncture or other mechanical issue.<|im_end|>\n",
      "⏱️ Time taken: 2.844 sec | 🧠 VRAM used: 0.375 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000740.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Flat tire; Affected Part: Front left tire; Severity: Moderate; Notes: The tire is deflated and appears to be damaged, possibly due to a puncture or other mechanical issue.<|im_end|>\n",
      "⏱️ Time taken: 2.909 sec | 🧠 VRAM used: 0.375 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car wheel. The tire is瘪了 (flattened), and the car appears to have been involved in an accident. The wheel is still attached to the car, but the tire is no longer inflated. The car's body is also damaged, with visible dents and deformations. This type of damage typically occurs in a collision where the tire is compressed or punctured, leading to the tire losing its air pressure and becoming flat.<|im_end|>\n",
      "⏱️ Time taken: 5.457 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a close-up of a damaged car wheel. The tire is瘪了 (flattened), and the car appears to have been involved in an accident. The wheel is still attached to the car, but the tire is no longer inflated. The car's body is also damaged, with visible dents and deformations. This type of damage typically occurs in a collision where the tire is compressed or punctured, leading to the tire losing its air pressure and becoming flat.<|im_end|>\n",
      "⏱️ Time taken: 5.411 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a blue sedan with significant damage to its front right side. The front fender is completely torn off, exposing the inner components of the wheel well. The tire is deflated and flattened, indicating that it has been damaged or punctured. The front bumper and part of the body are also visibly damaged, with dents and cracks. The overall condition of the car suggests it has been involved in a severe collision.<|im_end|>\n",
      "⏱️ Time taken: 5.519 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a blue sedan with significant damage to its front right side. The front fender is completely torn off, exposing the inner components of the wheel well. The tire is deflated and flattened, indicating that it has been damaged or punctured. The front bumper and part of the body are also visibly damaged, with dents and cracks. The overall condition of the car suggests it has been involved in a severe collision.<|im_end|>\n",
      "⏱️ Time taken: 5.052 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car with a flat tire. The tire is deflated and the car appears to have sustained significant damage, possibly from a collision. The car is parked on the side of the road, and the tire is resting on the ground.<|im_end|>\n",
      "⏱️ Time taken: 3.231 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a damaged car with a flat tire. The tire is deflated and the car appears to have sustained significant damage, possibly from a collision. The car is parked on the side of the road, and the tire is resting on the ground.<|im_end|>\n",
      "⏱️ Time taken: 3.531 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front Left Wheel**: The front left wheel is completely flat, indicating that the tire has been punctured or damaged. The tire is no longer inflated and is resting on the ground.\n",
      "\n",
      "2. **Front Left Fender**: The front left fender is severely damaged, with significant dents and folds. The metal has been bent and distorted, indicating a high-impact collision.\n",
      "\n",
      "3. **Front Left Door**: The front left door is also damaged, with dents and folds similar to the fender. The door\n",
      "⏱️ Time taken: 8.527 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage. Here are the details of the car's condition:\n",
      "\n",
      "1. **Front Left Wheel**: The front left wheel is completely flat, indicating that the tire has been punctured or damaged. The tire is no longer inflated and is resting on the ground.\n",
      "\n",
      "2. **Front Left Fender**: The front left fender is severely damaged, with significant dents and folds. The metal has been bent and distorted, indicating a high-impact collision.\n",
      "\n",
      "3. **Front Left Door**: The front left door is also damaged, with dents and folds similar to the fender. The door\n",
      "⏱️ Time taken: 7.943 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1> tire. The severity appears to be moderate, as the tire is flat and the wheel is damaged. Additional notes include that the car has sustained significant structural damage, with the fender and other parts of the body showing extensive deformation.<|im_end|>\n",
      "⏱️ Time taken: 4.217 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1> tire. The severity appears to be moderate, as the tire is flat and the wheel is damaged. Additional notes include that the car has sustained significant structural damage, with the fender and other parts of the body showing extensive deformation.<|im_end|>\n",
      "⏱️ Time taken: 4.296 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Flat tire; Affected Part: Front left tire; Severity: Moderate; Notes: The tire is completely flat, and the vehicle appears to have sustained other damage to the front end.<|im_end|>\n",
      "⏱️ Time taken: 2.848 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000869.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Flat tire; Affected Part: Front left tire; Severity: Moderate; Notes: The tire is completely flat, and the vehicle appears to have sustained other damage to the front end.<|im_end|>\n",
      "⏱️ Time taken: 2.89 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🔍 Running prompts for image: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car with a broken window. The window appears to have been shattered, with pieces of glass scattered inside and outside the car. The background shows a cloudy sky and some trees, indicating that the car is parked outdoors.<|im_end|>\n",
      "⏱️ Time taken: 3.462 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: \n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: \n",
      "📤 Output:\n",
      "The image shows a car with a broken window. The window appears to have been shattered, with pieces of glass scattered inside and outside the car. The background shows a cloudy sky and some trees, indicating that the car is parked outdoors.<|im_end|>\n",
      "⏱️ Time taken: 2.899 sec | 🧠 VRAM used: 0.343 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a sedan with a broken passenger-side window. The glass is shattered and has large cracks, indicating that the window has been damaged. The interior of the car is visible, including the steering wheel and the dashboard. The damage appears to be significant, as the window is completely broken and there are pieces of glass scattered inside the car.<|im_end|>\n",
      "⏱️ Time taken: 4.496 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe &&damage 12 sedan drive’ this !!image.\n",
      "📤 Output:\n",
      "The image shows a sedan with a broken passenger-side window. The glass is shattered and has large cracks, indicating that the window has been damaged. The interior of the car is visible, including the steering wheel and the dashboard. The damage appears to be significant, as the window is completely broken and there are pieces of glass scattered inside the car.<|im_end|>\n",
      "⏱️ Time taken: 4.742 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car with a damaged windshield. The windshield has a large crack and pieces of glass are scattered around the area where the crack is located. The car is parked on the side of the road, and the background includes trees and a cloudy sky.<|im_end|>\n",
      "⏱️ Time taken: 3.595 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: An image of a damaged car parked on the side of th...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: An image of a damaged car parked on the side of the road.\n",
      "📤 Output:\n",
      "The image shows a car with a damaged windshield. The windshield has a large crack and pieces of glass are scattered around the area where the crack is located. The car is parked on the side of the road, and the background includes trees and a cloudy sky.<|im_end|>\n",
      "⏱️ Time taken: 3.651 sec | 🧠 VRAM used: 0.346 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage to its front passenger side window. The window is shattered, with large pieces of glass missing and the remaining glass showing extensive cracks and fragments. The interior of the car, including the dashboard and steering wheel, is visible through the broken window. The damage suggests that the car was involved in a collision or an impact that caused the window to shatter. The surrounding area, including trees and a cloudy sky, is visible through the broken window, indicating that the car is parked outdoors.<|im_end|>\n",
      "⏱️ Time taken: 7.116 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: You are an insurance claims assessor. Provide a de...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: You are an insurance claims assessor. Provide a detailed description of the car’s condition.\n",
      "📤 Output:\n",
      "The car in the image appears to have sustained significant damage to its front passenger side window. The window is shattered, with large pieces of glass missing and the remaining glass showing extensive cracks and fragments. The interior of the car, including the dashboard and steering wheel, is visible through the broken window. The damage suggests that the car was involved in a collision or an impact that caused the window to shatter. The surrounding area, including trees and a cloudy sky, is visible through the broken window, indicating that the car is parked outdoors.<|im_end|>\n",
      "⏱️ Time taken: 7.198 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1> windshield. The severity appears to be <severity_1> broken. Additional notes: There are pieces of glass scattered inside the car, and the windshield appears to be shattered.<|im_end|>\n",
      "⏱️ Time taken: 3.639 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: This <part_1> of the car has <damage_type_1>. The ...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\n",
      "📤 Output:\n",
      "The <part_1> of the car is the <damage_type_1> windshield. The severity appears to be <severity_1> broken. Additional notes: There are pieces of glass scattered inside the car, and the windshield appears to be shattered.<|im_end|>\n",
      "⏱️ Time taken: 3.628 sec | 🧠 VRAM used: 0.351 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 1 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Glass Breakage; Affected Part: Side Window; Severity: Moderate; Notes: The side window of the car has a large crack and some pieces of glass are missing, indicating a significant impact.<|im_end|>\n",
      "⏱️ Time taken: 3.05 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n",
      "🔁 Run 2 for prompt: Describe using format - Damage Type: ___; Affected...\n",
      "🔹 Image: 000889.jpg\n",
      "🧾 Prompt: Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\n",
      "📤 Output:\n",
      "Damage Type: Glass Breakage; Affected Part: Side Window; Severity: Moderate; Notes: The side window of the car has a large crack and some pieces of glass are missing, indicating a significant impact.<|im_end|>\n",
      "⏱️ Time taken: 2.986 sec | 🧠 VRAM used: 0.348 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of filenames for car damage dataset\n",
    "test_filenames = [\n",
    "    \"000404.jpg\", \"000422.jpg\", \"000433.jpg\", \"000481.jpg\", \"000520.jpg\",\n",
    "    \"000541.jpg\", \"000698.jpg\", \"000740.jpg\", \"000869.jpg\", \"000889.jpg\"\n",
    "]\n",
    "\n",
    "# Prompt set used for all filenames\n",
    "CAR_DAMAGE_PROMPTS = [\n",
    "    \"\",  # No Prompt\n",
    "    \"Describe &&damage 12 sedan drive’ this !!image.\",  # Noisy\n",
    "    \"An image of a damaged car parked on the side of the road.\",  # Hand-crafted\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the car’s condition.\",  # Roleplay\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. Additional notes: <text_1>.\",  # Masked\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"  # Format-Guided\n",
    "]\n",
    "\n",
    "all_outputs = {}\n",
    "all_times = {}\n",
    "all_vram = {}\n",
    "\n",
    "for filename in test_filenames:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No data found for {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Running prompts for image: {filename}\\n\" + \"-\"*60)\n",
    "\n",
    "    inference_outputs = []\n",
    "    inference_times = []\n",
    "    vram_usages = []\n",
    "\n",
    "    for prompt in CAR_DAMAGE_PROMPTS:\n",
    "        for run in range(2):  # Run each prompt twice\n",
    "            print(f\"🔁 Run {run+1} for prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
    "            output, time_taken, vram_used = run_vlm_inference(prompt, filename, df=df)\n",
    "            inference_outputs.append(output)\n",
    "            inference_times.append(time_taken)\n",
    "            vram_usages.append(vram_used)\n",
    "\n",
    "    # Store in dicts\n",
    "    all_outputs[filename] = inference_outputs\n",
    "    all_times[filename] = inference_times\n",
    "    all_vram[filename] = vram_usages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9ef67f4f3245ddb076d394811c39bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2cbc394c244ca83c428bc86dc77c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144050e796a0493db7a57d963a27c350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec434d41fd5244a48e2530f664014ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acf54bfb5e4017831f3f058b6f73ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9669eb25e34e77b55f35c443858de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe69b65916ec48628d7fc0b66ea527ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edd4113ded649a493887407222cb441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb62c788bd3f47b6bc7b21c6bafaab2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4777df3d4b6481f8f3d68641b602153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28d8e9df9994ba3a0af6b264bfcdbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f4d517-34af-4a79-bb29-25613a22c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/cardd-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    \"\"\"\n",
    "    Computes CIDEr score using new evaluate_cider logic with precomputed DF pickle.\n",
    "\n",
    "    Args:\n",
    "        reference_caption (str or list): Ground truth caption(s)\n",
    "        generated_caption (str): Model output\n",
    "\n",
    "    Returns:\n",
    "        float: CIDEr score (averaged if multiple refs)\n",
    "    \"\"\"\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b2100b-1268-4fe2-816a-c46a3ed0cbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating image: 000404.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front hood area shows a large dent with visible deformation and creasing. The headlight on the passenger's side is broken, with the lamp housing shattered and the bulb exposed. The front bumper also has a dent near the grille, and the grille itself appears to be slightly misaligned. The passenger side headlight is intact but the surrounding area has a dent. The tire on the driver's side appears to be flat. No scratches, cracks, or shattered glass are present. The overall condition of the car is severely compromised due to these damages.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1180.13 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 1973.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [7.120 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.772 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.56 s\n",
      "📝 Prompt Run 1 | CIDEr: 2.4118 | SPICE: 0.175 | CosSim: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 1844.20 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 1778.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.150 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.42 s\n",
      "📝 Prompt Run 2 | CIDEr: 2.4118 | SPICE: 0.175 | CosSim: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2234.52 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2020.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.804 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.414 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a red sedan that has sustained significant damage in a collision the front of the car is severely crumpled with the hood and front bumper visibly damaged the front grille and headlights are also damaged and the car 's hood is raised revealing the engine compartment there is another vehicle partially visible in the background which appears to have been involved in the accident as well the scene suggests a serious collision that has caused substantial damage to the vehicles involved\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.50 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.137 | SPICE: 0.1905 | CosSim: 0.6325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2090.27 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2358.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.808 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.850 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a red sedan that has sustained significant damage in a collision the front of the car is severely crumpled with the hood and front bumper visibly damaged the front grille and headlights are also damaged and the car 's hood is raised revealing the engine compartment there is another vehicle partially visible in the background which appears to have been involved in the accident as well the scene suggests a serious collision that has caused substantial damage to the vehicles involved\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.63 s\n",
      "📝 Prompt Run 4 | CIDEr: 2.137 | SPICE: 0.1905 | CosSim: 0.6325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2241.42 tokens per second.\n",
      "PTBTokenizer tokenized 99 tokens at 1334.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.368 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [6.196 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.12 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.921 | SPICE: 0.129 | CosSim: 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2221.04 tokens per second.\n",
      "PTBTokenizer tokenized 99 tokens at 1681.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.669 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.67 s\n",
      "📝 Prompt Run 6 | CIDEr: 1.921 | SPICE: 0.129 | CosSim: 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 3152.89 tokens per second.\n",
      "PTBTokenizer tokenized 144 tokens at 3638.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [7.49 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [10.243 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage in a collision here are the details of the car 's condition 1 ** front end damage ** the front bumper is completely detached and hanging off the front of the car the hood is crumpled and pushed back indicating a severe impact the front grille is damaged and bent out of shape the front headlights are shattered and the front bumper is completely detached 2 ** left side damage ** the left headlight is damaged and appears to be out of alignment the front fender on the left\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 22.54 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.163 | SPICE: 0.1875 | CosSim: 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2386.03 tokens per second.\n",
      "PTBTokenizer tokenized 144 tokens at 2807.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [7.361 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [8.438 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage in a collision here are the details of the car 's condition 1 ** front end damage ** the front bumper is completely detached and hanging off the front of the car the hood is crumpled and pushed back indicating a severe impact the front grille is damaged and bent out of shape the front headlights are shattered and the front bumper is completely detached 2 ** left side damage ** the left headlight is damaged and appears to be out of alignment the front fender on the left\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 22.12 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.163 | SPICE: 0.1875 | CosSim: 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2161.53 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1188.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.954 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.219 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.37 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.1348 | SPICE: 0.1316 | CosSim: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2649.98 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1566.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [6.792 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.04 s\n",
      "📝 Prompt Run 10 | CIDEr: 2.1348 | SPICE: 0.1316 | CosSim: 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2404.72 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1301.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.452 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.19 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.67 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.42 | SPICE: 0.0 | CosSim: 0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112 tokens at 2261.49 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1299.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [8.34 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"the car exhibits significant damage the front hood area shows a large dent with visible deformation and creasing the headlight on the passenger 's side is broken with the lamp housing shattered and the bulb exposed the front bumper also has a dent near the grille and the grille itself appears to be slightly misaligned the passenger side headlight is intact but the surrounding area has a dent the tire on the driver 's side appears to be flat no scratches cracks or shattered glass are present the overall condition of the car is severely compromised due to these damages\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.82 s\n",
      "📝 Prompt Run 12 | CIDEr: 0.42 | SPICE: 0.0 | CosSim: 0.4953\n",
      "\n",
      "🔍 Evaluating image: 000422.jpg | Reference Caption:\n",
      "The car exhibits significant damage to its front section. The front fender and door area show extensive dents and deformation, indicating a severe impact. The front bumper is detached and damaged, with visible internal components exposed. A scratch is present on the lower part of the fender. The front wheel well area is also compromised, with structural damage evident. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1097.80 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 1920.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [3.140 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.421 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.93 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.6095 | SPICE: 0.1892 | CosSim: 0.6334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1277.26 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 1781.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 905.4 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.6095 | SPICE: 0.1892 | CosSim: 0.6334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1466.21 tokens per second.\n",
      "PTBTokenizer tokenized 122 tokens at 2159.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [5.907 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a severely damaged sedan car the front end of the car is crumpled and bent indicating a significant impact the hood is dented and folded and the front bumper is completely detached and hanging off the front of the car the front suspension and other mechanical components are exposed and appear to be damaged the car is parked on a street and there are visible signs of oil or fluid leaking from the vehicle the overall condition of the car suggests it has been involved in a severe collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.09 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.0568 | SPICE: 0.1205 | CosSim: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1225.99 tokens per second.\n",
      "PTBTokenizer tokenized 122 tokens at 2561.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.748 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a severely damaged sedan car the front end of the car is crumpled and bent indicating a significant impact the hood is dented and folded and the front bumper is completely detached and hanging off the front of the car the front suspension and other mechanical components are exposed and appear to be damaged the car is parked on a street and there are visible signs of oil or fluid leaking from the vehicle the overall condition of the car suggests it has been involved in a severe collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.20 s\n",
      "📝 Prompt Run 4 | CIDEr: 2.0568 | SPICE: 0.1205 | CosSim: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1373.25 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2326.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [6.695 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user an image of a damaged car parked on the side of the road assistant the image shows a car that has been involved in a collision the front end of the car is heavily damaged with the hood crumpled and the front bumper and bodywork significantly bent and torn the damage suggests that the car was involved in a severe impact possibly with another vehicle or an object the car is parked on the side of the road and there are no visible signs of movement or other vehicles involved in the accident\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.91 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.5982 | SPICE: 0.1579 | CosSim: 0.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1261.47 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2331.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.18 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user an image of a damaged car parked on the side of the road assistant the image shows a car that has been involved in a collision the front end of the car is heavily damaged with the hood crumpled and the front bumper and bodywork significantly bent and torn the damage suggests that the car was involved in a severe impact possibly with another vehicle or an object the car is parked on the side of the road and there are no visible signs of movement or other vehicles involved in the accident\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.13 s\n",
      "📝 Prompt Run 6 | CIDEr: 1.5982 | SPICE: 0.1579 | CosSim: 0.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1413.92 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2585.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.271 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage in a collision here are the details of the car 's condition 1 ** front end damage ** the front bumper is completely detached and is hanging off the front of the car the hood is severely dented and crumpled indicating a high-impact collision the front grille and headlights are likely damaged or missing the front fender is also crumpled and distorted with the front wheel well area showing significant deformation 2 ** body damage ** the side of the car shows extensive dents and cre\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.36 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.4495 | SPICE: 0.2947 | CosSim: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1402.98 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2835.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.768 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage in a collision here are the details of the car 's condition 1 ** front end damage ** the front bumper is completely detached and is hanging off the front of the car the hood is severely dented and crumpled indicating a high-impact collision the front grille and headlights are likely damaged or missing the front fender is also crumpled and distorted with the front wheel well area showing significant deformation 2 ** body damage ** the side of the car shows extensive dents and cre\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.99 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.4495 | SPICE: 0.2947 | CosSim: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1317.29 tokens per second.\n",
      "PTBTokenizer tokenized 153 tokens at 3238.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [13.383 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the image shows a car that has sustained significant damage the hood and front end of the car are heavily crumpled indicating a severe impact the severity of the damage appears to be high with the hood and front end of the car extensively bent and deformed additional notes include the car appears to have been involved in a collision likely with another vehicle or object there are visible signs of mechanical damage such as bent metal and exposed components the damage extends from the front bumper to the hood suggesting a head-on collision or a severe impact from the front the car 's front end is completely\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.70 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.7616 | SPICE: 0.1882 | CosSim: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1590.85 tokens per second.\n",
      "PTBTokenizer tokenized 153 tokens at 3940.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.509 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the image shows a car that has sustained significant damage the hood and front end of the car are heavily crumpled indicating a severe impact the severity of the damage appears to be high with the hood and front end of the car extensively bent and deformed additional notes include the car appears to have been involved in a collision likely with another vehicle or object there are visible signs of mechanical damage such as bent metal and exposed components the damage extends from the front bumper to the hood suggesting a head-on collision or a severe impact from the front the car 's front end is completely\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.65 s\n",
      "📝 Prompt Run 10 | CIDEr: 1.7616 | SPICE: 0.1882 | CosSim: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1352.79 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1372.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [1.923 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.819 s\n",
      "📝 Prompt Run 11 | CIDEr: 1.1849 | SPICE: 0.1449 | CosSim: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67 tokens at 1150.45 tokens per second.\n",
      "PTBTokenizer tokenized 63 tokens at 1234.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 850.3 ms\n",
      "📝 Prompt Run 12 | CIDEr: 1.1849 | SPICE: 0.1449 | CosSim: 0.5422\n",
      "\n",
      "🔍 Evaluating image: 000433.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the windshield, which is extensively shattered. The roof also shows signs of damage, with a noticeable dent present. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 553.32 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1364.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.798 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.435 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.96 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.1836 | SPICE: 0.1132 | CosSim: 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 680.02 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1408.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 821.3 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.1836 | SPICE: 0.1132 | CosSim: 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 622.47 tokens per second.\n",
      "PTBTokenizer tokenized 97 tokens at 2154.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [3.604 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.40 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.2861 | SPICE: 0.0702 | CosSim: 0.7381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 568.12 tokens per second.\n",
      "PTBTokenizer tokenized 97 tokens at 1723.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 864.0 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.2861 | SPICE: 0.0702 | CosSim: 0.7381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 576.29 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1505.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [3.185 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.35 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.342 | SPICE: 0.1463 | CosSim: 0.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 536.48 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1340.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 891.5 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.342 | SPICE: 0.1463 | CosSim: 0.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 468.17 tokens per second.\n",
      "PTBTokenizer tokenized 115 tokens at 2324.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [7.201 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image has sustained significant damage to its front windshield the windshield is shattered into numerous pieces with cracks and fragments extending across the entire surface the damage appears to be extensive indicating a severe impact the hood of the car is also visible and shows signs of deformation suggesting that the front end of the vehicle was involved in a collision the overall condition of the car indicates that it has been involved in a serious accident\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.71 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.6458 | SPICE: 0.1471 | CosSim: 0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 581.20 tokens per second.\n",
      "PTBTokenizer tokenized 115 tokens at 2585.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [6.542 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image has sustained significant damage to its front windshield the windshield is shattered into numerous pieces with cracks and fragments extending across the entire surface the damage appears to be extensive indicating a severe impact the hood of the car is also visible and shows signs of deformation suggesting that the front end of the vehicle was involved in a collision the overall condition of the car indicates that it has been involved in a serious accident\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.22 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.6458 | SPICE: 0.1471 | CosSim: 0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 685.70 tokens per second.\n",
      "PTBTokenizer tokenized 92 tokens at 2146.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [4.325 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the <part_1> of the car is the windshield the damage type is <damage_type_1> which is a shattered windshield the severity appears to be <severity_1> indicating that the windshield is completely broken and likely unsafe to drive with additional notes the windshield has multiple cracks and pieces of glass scattered across it suggesting a severe impact\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.33 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.2437 | SPICE: 0.08 | CosSim: 0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 520.79 tokens per second.\n",
      "PTBTokenizer tokenized 92 tokens at 1673.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.669 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the <part_1> of the car is the windshield the damage type is <damage_type_1> which is a shattered windshield the severity appears to be <severity_1> indicating that the windshield is completely broken and likely unsafe to drive with additional notes the windshield has multiple cracks and pieces of glass scattered across it suggesting a severe impact\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.35 s\n",
      "📝 Prompt Run 10 | CIDEr: 1.2437 | SPICE: 0.08 | CosSim: 0.7318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 531.07 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1240.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.433 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.666 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.5312 | SPICE: 0.0889 | CosSim: 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 555.95 tokens per second.\n",
      "PTBTokenizer tokenized 64 tokens at 1397.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 858.5 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.5312 | SPICE: 0.0889 | CosSim: 0.603\n",
      "\n",
      "🔍 Evaluating image: 000481.jpg | Reference Caption:\n",
      "The car exhibits visible damage including a scratch on the lower side panel near the front wheel, with moderate severity affecting the paint and surface. Additionally, a more extensive scratch is present on the lower front bumper, also near the front wheel, showing significant paint damage.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1063.51 tokens per second.\n",
      "PTBTokenizer tokenized 19 tokens at 359.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [1.670 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.158 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.921 s\n",
      "📝 Prompt Run 1 | CIDEr: 0.1797 | SPICE: 0.0 | CosSim: -0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1232.55 tokens per second.\n",
      "PTBTokenizer tokenized 19 tokens at 374.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 1.010 s\n",
      "📝 Prompt Run 2 | CIDEr: 0.1797 | SPICE: 0.0 | CosSim: -0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1102.76 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2795.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.847 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a close-up of a car 's front bumper area there is visible damage to the paint on the bumper with some of the paint chipped off revealing the underlying material the damage appears to be localized and does not seem to affect the structural integrity of the bumper the tire is also visible and it appears to be in good condition the background is blurred but it seems to be an outdoor setting possibly a parking lot or a driveway\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.87 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.3614 | SPICE: 0.137 | CosSim: 0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1067.68 tokens per second.\n",
      "PTBTokenizer tokenized 114 tokens at 2117.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.809 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a close-up of a car 's front bumper area there is visible damage to the paint on the bumper with some of the paint chipped off revealing the underlying material the damage appears to be localized and does not seem to affect the structural integrity of the bumper the tire is also visible and it appears to be in good condition the background is blurred but it seems to be an outdoor setting possibly a parking lot or a driveway\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.20 s\n",
      "📝 Prompt Run 4 | CIDEr: 1.3614 | SPICE: 0.137 | CosSim: 0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1027.20 tokens per second.\n",
      "PTBTokenizer tokenized 87 tokens at 2046.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [5.136 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.65 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.1909 | SPICE: 0.1791 | CosSim: 0.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 977.01 tokens per second.\n",
      "PTBTokenizer tokenized 87 tokens at 1456.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 847.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.1909 | SPICE: 0.1791 | CosSim: 0.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1071.76 tokens per second.\n",
      "PTBTokenizer tokenized 122 tokens at 2234.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.3 sec].\n",
      "Threads( StanfordCoreNLP ) [8.943 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image has sustained damage to its front bumper the paint on the bumper is chipped and scratched revealing the underlying material the damage appears to be localized to the lower section of the bumper where the paint has been scraped off exposing the metal beneath the tire and wheel are also visible and there are no visible signs of damage to the tire or wheel itself the overall condition of the car suggests that it has been involved in a minor collision or刮蹭事件\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.79 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.506 | SPICE: 0.1538 | CosSim: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 918.38 tokens per second.\n",
      "PTBTokenizer tokenized 122 tokens at 2465.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.21 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image has sustained damage to its front bumper the paint on the bumper is chipped and scratched revealing the underlying material the damage appears to be localized to the lower section of the bumper where the paint has been scraped off exposing the metal beneath the tire and wheel are also visible and there are no visible signs of damage to the tire or wheel itself the overall condition of the car suggests that it has been involved in a minor collision or刮蹭事件\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.73 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.506 | SPICE: 0.1538 | CosSim: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1127.78 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1371.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [2.726 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.39 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.3445 | SPICE: 0.1509 | CosSim: 0.6266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1122.29 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1444.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 957.0 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.3445 | SPICE: 0.1509 | CosSim: 0.6266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1102.05 tokens per second.\n",
      "PTBTokenizer tokenized 58 tokens at 1073.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.34 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.883 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.4679 | SPICE: 0.069 | CosSim: 0.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 52 tokens at 1025.20 tokens per second.\n",
      "PTBTokenizer tokenized 58 tokens at 1200.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 886.1 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.4679 | SPICE: 0.069 | CosSim: 0.5323\n",
      "\n",
      "🔍 Evaluating image: 000520.jpg | Reference Caption:\n",
      "The car exhibits multiple areas of damage. A significant dent is present on the front fender, extending from the headlight area towards the wheel well. A smaller dent is located near the front bumper, adjacent to the headlight. A scratch is visible on the lower part of the front bumper. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1162.38 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1510.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [1.881 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.913 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.48 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.2354 | SPICE: 0.1967 | CosSim: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1018.55 tokens per second.\n",
      "PTBTokenizer tokenized 78 tokens at 1509.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 865.1 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.2354 | SPICE: 0.1967 | CosSim: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1156.61 tokens per second.\n",
      "PTBTokenizer tokenized 105 tokens at 2140.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.982 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a white sedan with significant damage to the front left side the front bumper is visibly crumpled and dented indicating a collision the headlight on the affected side is also damaged with the glass and lens likely shattered the fender and hood appear to be pushed inwards and there are visible scratches and scuffs on the paint the overall condition suggests that the car has been involved in a minor to moderate collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.83 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.3525 | SPICE: 0.2029 | CosSim: 0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1122.44 tokens per second.\n",
      "PTBTokenizer tokenized 105 tokens at 2171.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "Threads( StanfordCoreNLP ) [4.383 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a white sedan with significant damage to the front left side the front bumper is visibly crumpled and dented indicating a collision the headlight on the affected side is also damaged with the glass and lens likely shattered the fender and hood appear to be pushed inwards and there are visible scratches and scuffs on the paint the overall condition suggests that the car has been involved in a minor to moderate collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.78 s\n",
      "📝 Prompt Run 4 | CIDEr: 1.3525 | SPICE: 0.2029 | CosSim: 0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1261.25 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 951.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.406 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.036 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.5135 | SPICE: 0.0741 | CosSim: 0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1175.05 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1124.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 897.6 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.5135 | SPICE: 0.0741 | CosSim: 0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1192.81 tokens per second.\n",
      "PTBTokenizer tokenized 147 tokens at 3069.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.474 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage to the front left side the following details can be observed 1 ** front bumper ** the front bumper is heavily dented and deformed indicating a severe impact the paint on the bumper is likely chipped or removed in some areas 2 ** headlight ** the headlight on the front left side is damaged the glass is likely shattered and the housing may be cracked or broken 3 ** fender ** the fender on the front left side is also heavily damaged the metal is bent and dented and the paint is likely chipped\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.59 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.8993 | SPICE: 0.2154 | CosSim: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1191.74 tokens per second.\n",
      "PTBTokenizer tokenized 147 tokens at 3447.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [12.573 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage to the front left side the following details can be observed 1 ** front bumper ** the front bumper is heavily dented and deformed indicating a severe impact the paint on the bumper is likely chipped or removed in some areas 2 ** headlight ** the headlight on the front left side is damaged the glass is likely shattered and the housing may be cracked or broken 3 ** fender ** the fender on the front left side is also heavily damaged the metal is bent and dented and the paint is likely chipped\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.93 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.8993 | SPICE: 0.2154 | CosSim: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 900.75 tokens per second.\n",
      "PTBTokenizer tokenized 105 tokens at 2304.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [5.856 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the <part_1> of the car is the front bumper the damage type appears to be a dent or a crease which is likely caused by a collision the severity of the damage seems to be moderate as the dent is noticeable but not completely collapsed additional notes include that the damage is localized to the front bumper area and there are no signs of major structural damage to the car\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.29 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.9017 | SPICE: 0.1935 | CosSim: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1086.61 tokens per second.\n",
      "PTBTokenizer tokenized 105 tokens at 2163.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [5.703 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user this <part_1> of the car has <damage_type_1> the severity appears to be <severity_1> additional notes <text_1> assistant the <part_1> of the car is the front bumper the damage type appears to be a dent or a crease which is likely caused by a collision the severity of the damage seems to be moderate as the dent is noticeable but not completely collapsed additional notes include that the damage is localized to the front bumper area and there are no signs of major structural damage to the car\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.05 s\n",
      "📝 Prompt Run 10 | CIDEr: 1.9017 | SPICE: 0.1935 | CosSim: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1118.17 tokens per second.\n",
      "PTBTokenizer tokenized 67 tokens at 1206.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [1.894 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.595 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.5232 | SPICE: 0.1754 | CosSim: 0.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 56 tokens at 1187.96 tokens per second.\n",
      "PTBTokenizer tokenized 67 tokens at 1263.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 863.8 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.5232 | SPICE: 0.1754 | CosSim: 0.5296\n",
      "\n",
      "🔍 Evaluating image: 000541.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The rear bumper shows multiple scratches along its lower edge, indicating surface-level abrasions. The rear fender also displays a dent, suggesting a moderate impact that has deformed the panel. The damage to the taillight and fender is severe, affecting both the aesthetics and structural integrity of the vehicle.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1005.70 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1377.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.653 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.820 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.59 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.7677 | SPICE: 0.1515 | CosSim: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1352.25 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1960.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 765.2 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.7677 | SPICE: 0.1515 | CosSim: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1294.83 tokens per second.\n",
      "PTBTokenizer tokenized 98 tokens at 2073.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.51 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.61 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.0563 | SPICE: 0.2025 | CosSim: 0.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 895.15 tokens per second.\n",
      "PTBTokenizer tokenized 98 tokens at 1634.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 865.3 ms\n",
      "📝 Prompt Run 4 | CIDEr: 2.0563 | SPICE: 0.2025 | CosSim: 0.6281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1233.15 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 1634.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [4.710 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.92 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.8941 | SPICE: 0.1515 | CosSim: 0.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1252.29 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 1709.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 929.6 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.8941 | SPICE: 0.1515 | CosSim: 0.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1192.55 tokens per second.\n",
      "PTBTokenizer tokenized 151 tokens at 2898.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.574 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here is a detailed description of the car 's condition 1 ** rear bumper ** the rear bumper is heavily damaged with significant deformation and dents the bumper is likely to be replaced or repaired extensively 2 ** tail light ** the tail light on the right side of the car is damaged with the lens possibly shattered or cracked the tail light assembly may need to be replaced 3 ** rear bumper cover ** the rear bumper cover is also damaged with significant deformation and dents the cover may need to be replaced or repaired 4\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.53 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.7013 | SPICE: 0.1538 | CosSim: 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1202.32 tokens per second.\n",
      "PTBTokenizer tokenized 151 tokens at 3177.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [11.234 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here is a detailed description of the car 's condition 1 ** rear bumper ** the rear bumper is heavily damaged with significant deformation and dents the bumper is likely to be replaced or repaired extensively 2 ** tail light ** the tail light on the right side of the car is damaged with the lens possibly shattered or cracked the tail light assembly may need to be replaced 3 ** rear bumper cover ** the rear bumper cover is also damaged with significant deformation and dents the cover may need to be replaced or repaired 4\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.44 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.7013 | SPICE: 0.1538 | CosSim: 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1253.83 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 2329.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.51 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.00 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.6902 | SPICE: 0.209 | CosSim: 0.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1415.80 tokens per second.\n",
      "PTBTokenizer tokenized 95 tokens at 2067.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.5 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.6902 | SPICE: 0.209 | CosSim: 0.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1415.76 tokens per second.\n",
      "PTBTokenizer tokenized 66 tokens at 1314.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.929 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.092 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.941 | SPICE: 0.0635 | CosSim: 0.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 60 tokens at 1114.52 tokens per second.\n",
      "PTBTokenizer tokenized 66 tokens at 1415.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 709.0 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.941 | SPICE: 0.0635 | CosSim: 0.5261\n",
      "\n",
      "🔍 Evaluating image: 000698.jpg | Reference Caption:\n",
      "The car exhibits significant damage. The front right headlight is broken, exposing internal components. A dent is present on the front right fender, with visible deformation. Multiple scratches are scattered across the front left fender and the front bumper, varying in length and depth. A crack is located on the front right fender, near the headlight.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1288.76 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1676.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.479 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.100 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.62 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.1674 | SPICE: 0.1017 | CosSim: 0.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1253.06 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1627.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 923.0 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.1674 | SPICE: 0.1017 | CosSim: 0.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1264.34 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 2866.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [8.148 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a sedan car that appears to have been involved in a collision the damage includes 1 ** front bumper ** the front bumper is visibly damaged and crumpled indicating a significant impact 2 ** front left door ** the front left door is open and appears to be dented and damaged 3 ** front left headlight ** the front left headlight is shattered and missing with the housing and wiring exposed 4 ** front left side panel ** the front left side panel of the car is dented and crumpled with visible damage to the paint 5 ** front left wheel **\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.86 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.3754 | SPICE: 0.1449 | CosSim: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1232.56 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 2386.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [7.902 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a sedan car that appears to have been involved in a collision the damage includes 1 ** front bumper ** the front bumper is visibly damaged and crumpled indicating a significant impact 2 ** front left door ** the front left door is open and appears to be dented and damaged 3 ** front left headlight ** the front left headlight is shattered and missing with the housing and wiring exposed 4 ** front left side panel ** the front left side panel of the car is dented and crumpled with visible damage to the paint 5 ** front left wheel **\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.21 s\n",
      "📝 Prompt Run 4 | CIDEr: 1.3754 | SPICE: 0.1449 | CosSim: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1162.87 tokens per second.\n",
      "PTBTokenizer tokenized 98 tokens at 2097.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [6.109 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.30 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.446 | SPICE: 0.1231 | CosSim: 0.4768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1496.11 tokens per second.\n",
      "PTBTokenizer tokenized 98 tokens at 2250.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 756.7 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.446 | SPICE: 0.1231 | CosSim: 0.4768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1574.89 tokens per second.\n",
      "PTBTokenizer tokenized 141 tokens at 2679.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [9.713 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here are the details of the car 's condition 1 ** front left side ** the front left fender and bumper are heavily damaged with significant dents and deformations the front left headlight is shattered and missing exposing the internal components the front left door is also damaged with the door panel and window frame appearing to be bent and misaligned 2 ** front right side ** the front right fender and bumper are also damaged with similar deformations and dents the front right head\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.29 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.0443 | SPICE: 0.3117 | CosSim: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1506.00 tokens per second.\n",
      "PTBTokenizer tokenized 141 tokens at 2719.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.263 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here are the details of the car 's condition 1 ** front left side ** the front left fender and bumper are heavily damaged with significant dents and deformations the front left headlight is shattered and missing exposing the internal components the front left door is also damaged with the door panel and window frame appearing to be bent and misaligned 2 ** front right side ** the front right fender and bumper are also damaged with similar deformations and dents the front right head\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.91 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.0443 | SPICE: 0.3117 | CosSim: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1161.31 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 2202.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.83 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.49 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.1348 | SPICE: 0.1563 | CosSim: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1192.41 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1935.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 972.4 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.1348 | SPICE: 0.1563 | CosSim: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 968.61 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 1754.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.394 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.845 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.5024 | SPICE: 0.1493 | CosSim: 0.5202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 65 tokens at 1533.06 tokens per second.\n",
      "PTBTokenizer tokenized 84 tokens at 2079.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 726.4 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.5024 | SPICE: 0.1493 | CosSim: 0.5202\n",
      "\n",
      "🔍 Evaluating image: 000740.jpg | Reference Caption:\n",
      "The car exhibits significant wear and tear. The tire is flat, indicating a loss of air pressure and rendering it unusable. The bodywork around the wheel well shows extensive paint chipping and rust, suggesting prolonged exposure to the elements and lack of maintenance. The wheel itself appears to be in a worn condition, with visible dirt and grime. The overall condition of the car is poor, with clear signs of neglect and deterioration.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1892.94 tokens per second.\n",
      "PTBTokenizer tokenized 85 tokens at 2123.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [5.379 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.462 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.52 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.8876 | SPICE: 0.1892 | CosSim: 0.6712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1688.36 tokens per second.\n",
      "PTBTokenizer tokenized 85 tokens at 1491.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 879.4 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.8876 | SPICE: 0.1892 | CosSim: 0.6712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1723.02 tokens per second.\n",
      "PTBTokenizer tokenized 141 tokens at 2984.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [9.271 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a close-up of a car 's rear wheel and part of the body the car appears to be in a state of disrepair here are the specific damages observed 1 ** paint peeling and chipping ** the paint on the car 's body is peeling and chipping off particularly noticeable on the rear fender and the rear wheel area this indicates significant wear and exposure to the elements over time 2 ** rust ** there is visible rust on the rear fender and the wheel area suggesting that the car has been exposed to moisture and has not been maintained properly 3 ** tire\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.04 s\n",
      "📝 Prompt Run 3 | CIDEr: 2.1702 | SPICE: 0.186 | CosSim: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1686.24 tokens per second.\n",
      "PTBTokenizer tokenized 141 tokens at 2605.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [9.805 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a close-up of a car 's rear wheel and part of the body the car appears to be in a state of disrepair here are the specific damages observed 1 ** paint peeling and chipping ** the paint on the car 's body is peeling and chipping off particularly noticeable on the rear fender and the rear wheel area this indicates significant wear and exposure to the elements over time 2 ** rust ** there is visible rust on the rear fender and the wheel area suggesting that the car has been exposed to moisture and has not been maintained properly 3 ** tire\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.73 s\n",
      "📝 Prompt Run 4 | CIDEr: 2.1702 | SPICE: 0.186 | CosSim: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1629.44 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 1928.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [6.72 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.06 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.6539 | SPICE: 0.2025 | CosSim: 0.5493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1686.39 tokens per second.\n",
      "PTBTokenizer tokenized 90 tokens at 1763.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 926.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.6539 | SPICE: 0.2025 | CosSim: 0.5493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1716.62 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2455.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "Threads( StanfordCoreNLP ) [8.448 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to be in a very poor condition the paint is chipped and peeling off in various areas particularly around the wheel well and the rear fender the body of the car is heavily rusted with rust patches visible on the metal surfaces the tire is flat indicating that it may have been damaged or has been out of use for a long time the overall appearance suggests that the car has been neglected and is in need of significant repair work\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.36 s\n",
      "📝 Prompt Run 7 | CIDEr: 2.548 | SPICE: 0.1628 | CosSim: 0.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1715.17 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2390.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [8.818 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to be in a very poor condition the paint is chipped and peeling off in various areas particularly around the wheel well and the rear fender the body of the car is heavily rusted with rust patches visible on the metal surfaces the tire is flat indicating that it may have been damaged or has been out of use for a long time the overall appearance suggests that the car has been neglected and is in need of significant repair work\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.53 s\n",
      "📝 Prompt Run 8 | CIDEr: 2.548 | SPICE: 0.1628 | CosSim: 0.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1740.97 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1924.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.866 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.67 s\n",
      "📝 Prompt Run 9 | CIDEr: 1.9656 | SPICE: 0.1 | CosSim: 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1402.79 tokens per second.\n",
      "PTBTokenizer tokenized 91 tokens at 1623.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 929.8 ms\n",
      "📝 Prompt Run 10 | CIDEr: 1.9656 | SPICE: 0.1 | CosSim: 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1674.17 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1435.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.137 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.046 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.7992 | SPICE: 0.0556 | CosSim: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 82 tokens at 1686.25 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1117.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 863.0 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.7992 | SPICE: 0.0556 | CosSim: 0.4747\n",
      "\n",
      "🔍 Evaluating image: 000869.jpg | Reference Caption:\n",
      "The car exhibits a flat tire, with the tire visibly deflated and resting on the ground. The wheel rim is exposed, showing signs of wear and dirt. The surrounding area of the tire, including the fender and adjacent body panels, shows significant deformation and damage. The fender is bent and misaligned, with visible creases and dents. The body panel near the tire also displays extensive damage, with parts of the metal peeled away and hanging loosely.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1769.83 tokens per second.\n",
      "PTBTokenizer tokenized 99 tokens at 1991.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [4.702 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [4.955 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.36 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.7244 | SPICE: 0.1333 | CosSim: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1887.00 tokens per second.\n",
      "PTBTokenizer tokenized 99 tokens at 2341.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 756.9 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.7244 | SPICE: 0.1333 | CosSim: 0.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 2108.00 tokens per second.\n",
      "PTBTokenizer tokenized 103 tokens at 1945.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [3.976 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a blue sedan with significant damage to its front right side the front fender is completely torn off exposing the inner components of the wheel well the tire is deflated and flattened indicating that it has been damaged or punctured the front bumper and part of the body are also visibly damaged with dents and cracks the overall condition of the car suggests it has been involved in a severe collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.22 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.7353 | SPICE: 0.1379 | CosSim: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1703.87 tokens per second.\n",
      "PTBTokenizer tokenized 103 tokens at 1918.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.57 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user describe & & damage 12 sedan drive this !! image assistant the image shows a blue sedan with significant damage to its front right side the front fender is completely torn off exposing the inner components of the wheel well the tire is deflated and flattened indicating that it has been damaged or punctured the front bumper and part of the body are also visibly damaged with dents and cracks the overall condition of the car suggests it has been involved in a severe collision\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.49 s\n",
      "📝 Prompt Run 4 | CIDEr: 1.7353 | SPICE: 0.1379 | CosSim: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1734.76 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1241.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [3.818 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.44 s\n",
      "📝 Prompt Run 5 | CIDEr: 2.0561 | SPICE: 0.1739 | CosSim: 0.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1764.14 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1595.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 832.1 ms\n",
      "📝 Prompt Run 6 | CIDEr: 2.0561 | SPICE: 0.1739 | CosSim: 0.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1840.91 tokens per second.\n",
      "PTBTokenizer tokenized 149 tokens at 2759.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.74 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here are the details of the car 's condition 1 ** front left wheel ** the front left wheel is completely flat indicating that the tire has been punctured or damaged the tire is no longer inflated and is resting on the ground 2 ** front left fender ** the front left fender is severely damaged with significant dents and folds the metal has been bent and distorted indicating a high-impact collision 3 ** front left door ** the front left door is also damaged with dents and folds similar to the fender the door\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.22 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.9034 | SPICE: 0.1778 | CosSim: 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1839.48 tokens per second.\n",
      "PTBTokenizer tokenized 149 tokens at 3210.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [10.480 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage here are the details of the car 's condition 1 ** front left wheel ** the front left wheel is completely flat indicating that the tire has been punctured or damaged the tire is no longer inflated and is resting on the ground 2 ** front left fender ** the front left fender is severely damaged with significant dents and folds the metal has been bent and distorted indicating a high-impact collision 3 ** front left door ** the front left door is also damaged with dents and folds similar to the fender the door\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.36 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.9034 | SPICE: 0.1778 | CosSim: 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1928.91 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1994.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [3.674 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.796 s\n",
      "📝 Prompt Run 9 | CIDEr: 2.0065 | SPICE: 0.1818 | CosSim: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1730.95 tokens per second.\n",
      "PTBTokenizer tokenized 82 tokens at 1648.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 843.1 ms\n",
      "📝 Prompt Run 10 | CIDEr: 2.0065 | SPICE: 0.1818 | CosSim: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1599.31 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1394.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [2.168 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.300 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.6033 | SPICE: 0.1081 | CosSim: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 87 tokens at 1728.73 tokens per second.\n",
      "PTBTokenizer tokenized 69 tokens at 1360.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 923.3 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.6033 | SPICE: 0.1081 | CosSim: 0.5694\n",
      "\n",
      "🔍 Evaluating image: 000889.jpg | Reference Caption:\n",
      "The car exhibits significant damage to the driver's side window, which is shattered extensively. The glass is fragmented and broken, with large pieces missing, indicating a severe impact. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 636.71 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1106.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.921 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.655 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.32 s\n",
      "📝 Prompt Run 1 | CIDEr: 1.201 | SPICE: 0.2051 | CosSim: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 668.73 tokens per second.\n",
      "PTBTokenizer tokenized 56 tokens at 1093.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 917.2 ms\n",
      "📝 Prompt Run 2 | CIDEr: 1.201 | SPICE: 0.2051 | CosSim: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 741.96 tokens per second.\n",
      "PTBTokenizer tokenized 89 tokens at 1669.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [2.689 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.51 s\n",
      "📝 Prompt Run 3 | CIDEr: 1.5205 | SPICE: 0.2353 | CosSim: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 737.03 tokens per second.\n",
      "PTBTokenizer tokenized 89 tokens at 1569.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 879.9 ms\n",
      "📝 Prompt Run 4 | CIDEr: 1.5205 | SPICE: 0.2353 | CosSim: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 485.29 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1551.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.80 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.67 s\n",
      "📝 Prompt Run 5 | CIDEr: 1.1849 | SPICE: 0.12 | CosSim: 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 695.43 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1131.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 873.3 ms\n",
      "📝 Prompt Run 6 | CIDEr: 1.1849 | SPICE: 0.12 | CosSim: 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 673.32 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2605.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.559 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage to its front passenger side window the window is shattered with large pieces of glass missing and the remaining glass showing extensive cracks and fragments the interior of the car including the dashboard and steering wheel is visible through the broken window the damage suggests that the car was involved in a collision or an impact that caused the window to shatter the surrounding area including trees and a cloudy sky is visible through the broken window indicating that the car is parked outdoors\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.16 s\n",
      "📝 Prompt Run 7 | CIDEr: 1.6244 | SPICE: 0.2432 | CosSim: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 601.93 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2629.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.372 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"system you are a helpful assistant user you are an insurance claims assessor provide a detailed description of the car 's condition assistant the car in the image appears to have sustained significant damage to its front passenger side window the window is shattered with large pieces of glass missing and the remaining glass showing extensive cracks and fragments the interior of the car including the dashboard and steering wheel is visible through the broken window the damage suggests that the car was involved in a collision or an impact that caused the window to shatter the surrounding area including trees and a cloudy sky is visible through the broken window indicating that the car is parked outdoors\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.64 s\n",
      "📝 Prompt Run 8 | CIDEr: 1.6244 | SPICE: 0.2432 | CosSim: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 657.00 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1453.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [2.387 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.11 s\n",
      "📝 Prompt Run 9 | CIDEr: 0.8876 | SPICE: 0.1429 | CosSim: 0.6833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 687.62 tokens per second.\n",
      "PTBTokenizer tokenized 68 tokens at 1405.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 932.0 ms\n",
      "📝 Prompt Run 10 | CIDEr: 0.8876 | SPICE: 0.1429 | CosSim: 0.6833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 662.03 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1507.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [2.482 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.146 s\n",
      "📝 Prompt Run 11 | CIDEr: 0.9763 | SPICE: 0.2143 | CosSim: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 34 tokens at 754.83 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1522.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 663.9 ms\n",
      "📝 Prompt Run 12 | CIDEr: 0.9763 | SPICE: 0.2143 | CosSim: 0.704\n"
     ]
    }
   ],
   "source": [
    "all_metrics_scores = {}\n",
    "\n",
    "for filename, outputs in all_outputs.items():  # filename is used instead of img_id\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[WARNING] No ground truth found for filename {filename}\")\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]  # Single caption only\n",
    "    print(f\"\\n🔍 Evaluating image: {filename} | Reference Caption:\\n{ground_truth}\\n{'-'*80}\")\n",
    "    \n",
    "    scores_for_image = []\n",
    "\n",
    "    for idx, gen_output in enumerate(outputs):  # Expecting 2 runs per image\n",
    "        metrics = evaluate_all_metrics(ground_truth, gen_output)\n",
    "        avg_metrics = {\n",
    "            \"CIDEr\": round(metrics[\"CIDEr\"], 4),\n",
    "            \"SPICE\": round(metrics[\"SPICE\"], 4),\n",
    "            \"cosine_similarity\": round(metrics[\"cosine_similarity\"], 4)\n",
    "        }\n",
    "\n",
    "        print(f\"📝 Prompt Run {idx+1} | CIDEr: {avg_metrics['CIDEr']} | SPICE: {avg_metrics['SPICE']} | CosSim: {avg_metrics['cosine_similarity']}\")\n",
    "        scores_for_image.append(avg_metrics)\n",
    "\n",
    "    all_metrics_scores[filename] = scores_for_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3dd6bfc-68aa-42d7-be1c-a03006d690db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📸 Image ID: 000404.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  2.4118  0.1750             0.5515\n",
      "Prompt 1 (Run 2)  2.4118  0.1750             0.5515\n",
      "Prompt 2 (Run 1)  2.1370  0.1905             0.6325\n",
      "Prompt 2 (Run 2)  2.1370  0.1905             0.6325\n",
      "Prompt 3 (Run 1)  1.9210  0.1290             0.5711\n",
      "Prompt 3 (Run 2)  1.9210  0.1290             0.5711\n",
      "Prompt 4 (Run 1)  2.1630  0.1875             0.7406\n",
      "Prompt 4 (Run 2)  2.1630  0.1875             0.7406\n",
      "Prompt 5 (Run 1)  2.1348  0.1316             0.5642\n",
      "Prompt 5 (Run 2)  2.1348  0.1316             0.5642\n",
      "Prompt 6 (Run 1)  0.4200  0.0000             0.4953\n",
      "Prompt 6 (Run 2)  0.4200  0.0000             0.4953\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000422.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.6095  0.1892             0.6334\n",
      "Prompt 1 (Run 2)  1.6095  0.1892             0.6334\n",
      "Prompt 2 (Run 1)  2.0568  0.1205             0.6560\n",
      "Prompt 2 (Run 2)  2.0568  0.1205             0.6560\n",
      "Prompt 3 (Run 1)  1.5982  0.1579             0.5777\n",
      "Prompt 3 (Run 2)  1.5982  0.1579             0.5777\n",
      "Prompt 4 (Run 1)  2.4495  0.2947             0.7296\n",
      "Prompt 4 (Run 2)  2.4495  0.2947             0.7296\n",
      "Prompt 5 (Run 1)  1.7616  0.1882             0.6790\n",
      "Prompt 5 (Run 2)  1.7616  0.1882             0.6790\n",
      "Prompt 6 (Run 1)  1.1849  0.1449             0.5422\n",
      "Prompt 6 (Run 2)  1.1849  0.1449             0.5422\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000433.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.1836  0.1132             0.7597\n",
      "Prompt 1 (Run 2)  1.1836  0.1132             0.7597\n",
      "Prompt 2 (Run 1)  1.2861  0.0702             0.7381\n",
      "Prompt 2 (Run 2)  1.2861  0.0702             0.7381\n",
      "Prompt 3 (Run 1)  1.3420  0.1463             0.5592\n",
      "Prompt 3 (Run 2)  1.3420  0.1463             0.5592\n",
      "Prompt 4 (Run 1)  1.6458  0.1471             0.6940\n",
      "Prompt 4 (Run 2)  1.6458  0.1471             0.6940\n",
      "Prompt 5 (Run 1)  1.2437  0.0800             0.7318\n",
      "Prompt 5 (Run 2)  1.2437  0.0800             0.7318\n",
      "Prompt 6 (Run 1)  0.5312  0.0889             0.6030\n",
      "Prompt 6 (Run 2)  0.5312  0.0889             0.6030\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000481.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.1797  0.0000            -0.0658\n",
      "Prompt 1 (Run 2)  0.1797  0.0000            -0.0658\n",
      "Prompt 2 (Run 1)  1.3614  0.1370             0.7046\n",
      "Prompt 2 (Run 2)  1.3614  0.1370             0.7046\n",
      "Prompt 3 (Run 1)  1.1909  0.1791             0.5974\n",
      "Prompt 3 (Run 2)  1.1909  0.1791             0.5974\n",
      "Prompt 4 (Run 1)  1.5060  0.1538             0.6636\n",
      "Prompt 4 (Run 2)  1.5060  0.1538             0.6636\n",
      "Prompt 5 (Run 1)  1.3445  0.1509             0.6266\n",
      "Prompt 5 (Run 2)  1.3445  0.1509             0.6266\n",
      "Prompt 6 (Run 1)  0.4679  0.0690             0.5323\n",
      "Prompt 6 (Run 2)  0.4679  0.0690             0.5323\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000520.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.2354  0.1967             0.7314\n",
      "Prompt 1 (Run 2)  1.2354  0.1967             0.7314\n",
      "Prompt 2 (Run 1)  1.3525  0.2029             0.7027\n",
      "Prompt 2 (Run 2)  1.3525  0.2029             0.7027\n",
      "Prompt 3 (Run 1)  1.5135  0.0741             0.2845\n",
      "Prompt 3 (Run 2)  1.5135  0.0741             0.2845\n",
      "Prompt 4 (Run 1)  1.8993  0.2154             0.6580\n",
      "Prompt 4 (Run 2)  1.8993  0.2154             0.6580\n",
      "Prompt 5 (Run 1)  1.9017  0.1935             0.6778\n",
      "Prompt 5 (Run 2)  1.9017  0.1935             0.6778\n",
      "Prompt 6 (Run 1)  0.5232  0.1754             0.5296\n",
      "Prompt 6 (Run 2)  0.5232  0.1754             0.5296\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000541.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.7677  0.1515             0.6013\n",
      "Prompt 1 (Run 2)  1.7677  0.1515             0.6013\n",
      "Prompt 2 (Run 1)  2.0563  0.2025             0.6281\n",
      "Prompt 2 (Run 2)  2.0563  0.2025             0.6281\n",
      "Prompt 3 (Run 1)  1.8941  0.1515             0.4846\n",
      "Prompt 3 (Run 2)  1.8941  0.1515             0.4846\n",
      "Prompt 4 (Run 1)  1.7013  0.1538             0.6692\n",
      "Prompt 4 (Run 2)  1.7013  0.1538             0.6692\n",
      "Prompt 5 (Run 1)  1.6902  0.2090             0.7031\n",
      "Prompt 5 (Run 2)  1.6902  0.2090             0.7031\n",
      "Prompt 6 (Run 1)  0.9410  0.0635             0.5261\n",
      "Prompt 6 (Run 2)  0.9410  0.0635             0.5261\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000698.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.1674  0.1017             0.6196\n",
      "Prompt 1 (Run 2)  1.1674  0.1017             0.6196\n",
      "Prompt 2 (Run 1)  1.3754  0.1449             0.6891\n",
      "Prompt 2 (Run 2)  1.3754  0.1449             0.6891\n",
      "Prompt 3 (Run 1)  1.4460  0.1231             0.4768\n",
      "Prompt 3 (Run 2)  1.4460  0.1231             0.4768\n",
      "Prompt 4 (Run 1)  2.0443  0.3117             0.7138\n",
      "Prompt 4 (Run 2)  2.0443  0.3117             0.7138\n",
      "Prompt 5 (Run 1)  1.1348  0.1563             0.5379\n",
      "Prompt 5 (Run 2)  1.1348  0.1563             0.5379\n",
      "Prompt 6 (Run 1)  0.5024  0.1493             0.5202\n",
      "Prompt 6 (Run 2)  0.5024  0.1493             0.5202\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000740.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.8876  0.1892             0.6712\n",
      "Prompt 1 (Run 2)  1.8876  0.1892             0.6712\n",
      "Prompt 2 (Run 1)  2.1702  0.1860             0.6751\n",
      "Prompt 2 (Run 2)  2.1702  0.1860             0.6751\n",
      "Prompt 3 (Run 1)  2.6539  0.2025             0.5493\n",
      "Prompt 3 (Run 2)  2.6539  0.2025             0.5493\n",
      "Prompt 4 (Run 1)  2.5480  0.1628             0.6287\n",
      "Prompt 4 (Run 2)  2.5480  0.1628             0.6287\n",
      "Prompt 5 (Run 1)  1.9656  0.1000             0.4954\n",
      "Prompt 5 (Run 2)  1.9656  0.1000             0.4954\n",
      "Prompt 6 (Run 1)  0.7992  0.0556             0.4747\n",
      "Prompt 6 (Run 2)  0.7992  0.0556             0.4747\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000869.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.7244  0.1333             0.6565\n",
      "Prompt 1 (Run 2)  1.7244  0.1333             0.6565\n",
      "Prompt 2 (Run 1)  1.7353  0.1379             0.6125\n",
      "Prompt 2 (Run 2)  1.7353  0.1379             0.6125\n",
      "Prompt 3 (Run 1)  2.0561  0.1739             0.6218\n",
      "Prompt 3 (Run 2)  2.0561  0.1739             0.6218\n",
      "Prompt 4 (Run 1)  1.9034  0.1778             0.5862\n",
      "Prompt 4 (Run 2)  1.9034  0.1778             0.5862\n",
      "Prompt 5 (Run 1)  2.0065  0.1818             0.6694\n",
      "Prompt 5 (Run 2)  2.0065  0.1818             0.6694\n",
      "Prompt 6 (Run 1)  0.6033  0.1081             0.5694\n",
      "Prompt 6 (Run 2)  0.6033  0.1081             0.5694\n",
      "============================================================\n",
      "\n",
      "📸 Image ID: 000889.jpg\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  1.2010  0.2051             0.5515\n",
      "Prompt 1 (Run 2)  1.2010  0.2051             0.5515\n",
      "Prompt 2 (Run 1)  1.5205  0.2353             0.7991\n",
      "Prompt 2 (Run 2)  1.5205  0.2353             0.7991\n",
      "Prompt 3 (Run 1)  1.1849  0.1200             0.5741\n",
      "Prompt 3 (Run 2)  1.1849  0.1200             0.5741\n",
      "Prompt 4 (Run 1)  1.6244  0.2432             0.7769\n",
      "Prompt 4 (Run 2)  1.6244  0.2432             0.7769\n",
      "Prompt 5 (Run 1)  0.8876  0.1429             0.6833\n",
      "Prompt 5 (Run 2)  0.8876  0.1429             0.6833\n",
      "Prompt 6 (Run 1)  0.9763  0.2143             0.7040\n",
      "Prompt 6 (Run 2)  0.9763  0.2143             0.7040\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    print(f\"\\n📸 Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    df_temp = pd.DataFrame(scores)\n",
    "    prompt_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        prompt_num = (i // 2) + 1  # Prompts 1–6\n",
    "        run_num = (i % 2) + 1      # Run 1 or Run 2\n",
    "        prompt_labels.append(f\"Prompt {prompt_num} (Run {run_num})\")\n",
    "\n",
    "    df_temp.index = prompt_labels\n",
    "    print(df_temp.round(4))\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b1b4f0-8cfc-4442-b982-908fba41a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results table\n",
    "table = wandb.Table(columns=[\"filename\", \"prompt_type\", \"run\", \"image\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "for filename in all_outputs:\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        continue\n",
    "\n",
    "    ground_truth = row.iloc[0][\"caption\"]\n",
    "    image_pil = row.iloc[0][\"image\"]\n",
    "\n",
    "    for prompt_index in range(6):\n",
    "        for run in range(2):\n",
    "            row_idx = prompt_index * 2 + run\n",
    "            prediction = all_outputs[filename][row_idx] if row_idx < len(all_outputs[filename]) else \"N/A\"\n",
    "\n",
    "            table.add_data(\n",
    "                filename,\n",
    "                f\"Prompt {prompt_index + 1}\",\n",
    "                f\"Run {run + 1}\",\n",
    "                wandb.Image(image_pil),\n",
    "                ground_truth,\n",
    "                prediction\n",
    "            )\n",
    "\n",
    "wandb.log({\"Prompting Comparison Results\": table})\n",
    "\n",
    "# Log metrics for each prompt run\n",
    "for filename, scores in all_metrics_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        wandb.log({\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/CIDEr\": score[\"CIDEr\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/SPICE\": score[\"SPICE\"],\n",
    "            f\"{filename}/Prompt {i//2 + 1}/Run {i%2 + 1}/Cosine\": score[\"cosine_similarity\"]\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88d3c1d-92d1-41d0-9b3d-f1e9c36cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image as ExcelImage\n",
    "from openpyxl.styles import Alignment\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "def log_prompt_metrics_to_excel(\n",
    "    filename: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    output_excel_path: str = \"prompt_tuning_results_cardd_qwen.xlsx\"\n",
    "):\n",
    "    row = df[df[\"filename\"] == filename].iloc[0]\n",
    "    original_caption = row[\"caption\"]\n",
    "    image_path = os.path.join(\"/workspace/data/test_dataset\", filename)\n",
    "\n",
    "    # Load or create workbook\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image Number\", \"Image\", \"Original Caption\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    # Loop over the 2 runs (Run 1, Run 2) — 6 prompts per run\n",
    "    for run_index in range(2):  # 0 for Run 1, 1 for Run 2\n",
    "        start_row = ws.max_row + 1\n",
    "\n",
    "        for prompt_index in range(6):  # Prompt 1 to 6\n",
    "            idx = prompt_index * 2 + run_index\n",
    "            ws.append([\n",
    "                model_name,\n",
    "                filename,\n",
    "                \"\",  # Placeholder for image\n",
    "                original_caption,\n",
    "                f\"Prompt {prompt_index + 1} (Run {run_index + 1})\",\n",
    "                inference_outputs[idx],\n",
    "                inference_times[idx],\n",
    "                vram_usages[idx],\n",
    "                metrics[idx][\"CIDEr\"],\n",
    "                metrics[idx][\"SPICE\"],\n",
    "                metrics[idx][\"cosine_similarity\"]\n",
    "            ])\n",
    "\n",
    "        # Merge A–D columns across 6 rows\n",
    "        for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            ws.merge_cells(f\"{col}{start_row}:{col}{start_row + 5}\")\n",
    "\n",
    "        # Apply alignment and formatting\n",
    "        align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "        align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "        for row_idx in range(start_row, start_row + 6):\n",
    "            for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top\n",
    "            for col_letter in [\"D\", \"F\"]:\n",
    "                ws[f\"{col_letter}{row_idx}\"].alignment = align_top_wrap\n",
    "            ws.row_dimensions[row_idx].height = 120\n",
    "\n",
    "        # Set column widths\n",
    "        ws.column_dimensions[\"D\"].width = 40  # Original Caption\n",
    "        ws.column_dimensions[\"F\"].width = 40  # Output\n",
    "\n",
    "        # Embed image in this run block\n",
    "        if os.path.exists(image_path):\n",
    "            print(f\"[INFO] Inserting image for {filename} | Run {run_index + 1}\")\n",
    "            try:\n",
    "                img = ExcelImage(image_path)\n",
    "                img.width = 150\n",
    "                img.height = 150\n",
    "                img.anchor = f\"C{start_row}\"\n",
    "                ws.add_image(img)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not insert image: {e}\")\n",
    "\n",
    "    # Save workbook\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"✅ Logged both runs for {filename} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7d5bfd-a9fc-4e36-89d6-238542869d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inserting image for 000404.jpg | Run 1\n",
      "[INFO] Inserting image for 000404.jpg | Run 2\n",
      "✅ Logged both runs for 000404.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000422.jpg | Run 1\n",
      "[INFO] Inserting image for 000422.jpg | Run 2\n",
      "✅ Logged both runs for 000422.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000433.jpg | Run 1\n",
      "[INFO] Inserting image for 000433.jpg | Run 2\n",
      "✅ Logged both runs for 000433.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000481.jpg | Run 1\n",
      "[INFO] Inserting image for 000481.jpg | Run 2\n",
      "✅ Logged both runs for 000481.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000520.jpg | Run 1\n",
      "[INFO] Inserting image for 000520.jpg | Run 2\n",
      "✅ Logged both runs for 000520.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000541.jpg | Run 1\n",
      "[INFO] Inserting image for 000541.jpg | Run 2\n",
      "✅ Logged both runs for 000541.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000698.jpg | Run 1\n",
      "[INFO] Inserting image for 000698.jpg | Run 2\n",
      "✅ Logged both runs for 000698.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000740.jpg | Run 1\n",
      "[INFO] Inserting image for 000740.jpg | Run 2\n",
      "✅ Logged both runs for 000740.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000869.jpg | Run 1\n",
      "[INFO] Inserting image for 000869.jpg | Run 2\n",
      "✅ Logged both runs for 000869.jpg to prompt_tuning_results_cardd_qwen.xlsx\n",
      "[INFO] Inserting image for 000889.jpg | Run 1\n",
      "[INFO] Inserting image for 000889.jpg | Run 2\n",
      "✅ Logged both runs for 000889.jpg to prompt_tuning_results_cardd_qwen.xlsx\n"
     ]
    }
   ],
   "source": [
    "for filename in all_outputs.keys():\n",
    "    log_prompt_metrics_to_excel(\n",
    "        filename=filename,\n",
    "        model_name=model_id,\n",
    "        inference_outputs=all_outputs[filename],\n",
    "        metrics=all_metrics_scores[filename],\n",
    "        inference_times=all_times[filename],\n",
    "        vram_usages=all_vram[filename],\n",
    "        df=df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd783220-02a4-4fd8-a655-bb5ef7e7fb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>▁</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>000404.jpg/Prompt 1/Run 1/CIDEr</td><td>2.4118</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/Cosine</td><td>0.5515</td></tr><tr><td>000404.jpg/Prompt 1/Run 1/SPICE</td><td>0.175</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/CIDEr</td><td>2.4118</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/Cosine</td><td>0.5515</td></tr><tr><td>000404.jpg/Prompt 1/Run 2/SPICE</td><td>0.175</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/CIDEr</td><td>2.137</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/Cosine</td><td>0.6325</td></tr><tr><td>000404.jpg/Prompt 2/Run 1/SPICE</td><td>0.1905</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/CIDEr</td><td>2.137</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/Cosine</td><td>0.6325</td></tr><tr><td>000404.jpg/Prompt 2/Run 2/SPICE</td><td>0.1905</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/CIDEr</td><td>1.921</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/Cosine</td><td>0.5711</td></tr><tr><td>000404.jpg/Prompt 3/Run 1/SPICE</td><td>0.129</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/CIDEr</td><td>1.921</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/Cosine</td><td>0.5711</td></tr><tr><td>000404.jpg/Prompt 3/Run 2/SPICE</td><td>0.129</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/CIDEr</td><td>2.163</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/Cosine</td><td>0.7406</td></tr><tr><td>000404.jpg/Prompt 4/Run 1/SPICE</td><td>0.1875</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/CIDEr</td><td>2.163</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/Cosine</td><td>0.7406</td></tr><tr><td>000404.jpg/Prompt 4/Run 2/SPICE</td><td>0.1875</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/CIDEr</td><td>2.1348</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/Cosine</td><td>0.5642</td></tr><tr><td>000404.jpg/Prompt 5/Run 1/SPICE</td><td>0.1316</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/CIDEr</td><td>2.1348</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/Cosine</td><td>0.5642</td></tr><tr><td>000404.jpg/Prompt 5/Run 2/SPICE</td><td>0.1316</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/CIDEr</td><td>0.42</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/Cosine</td><td>0.4953</td></tr><tr><td>000404.jpg/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/CIDEr</td><td>0.42</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/Cosine</td><td>0.4953</td></tr><tr><td>000404.jpg/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/CIDEr</td><td>1.6095</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/Cosine</td><td>0.6334</td></tr><tr><td>000422.jpg/Prompt 1/Run 1/SPICE</td><td>0.1892</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/CIDEr</td><td>1.6095</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/Cosine</td><td>0.6334</td></tr><tr><td>000422.jpg/Prompt 1/Run 2/SPICE</td><td>0.1892</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/CIDEr</td><td>2.0568</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/Cosine</td><td>0.656</td></tr><tr><td>000422.jpg/Prompt 2/Run 1/SPICE</td><td>0.1205</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/CIDEr</td><td>2.0568</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/Cosine</td><td>0.656</td></tr><tr><td>000422.jpg/Prompt 2/Run 2/SPICE</td><td>0.1205</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/CIDEr</td><td>1.5982</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/Cosine</td><td>0.5777</td></tr><tr><td>000422.jpg/Prompt 3/Run 1/SPICE</td><td>0.1579</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/CIDEr</td><td>1.5982</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/Cosine</td><td>0.5777</td></tr><tr><td>000422.jpg/Prompt 3/Run 2/SPICE</td><td>0.1579</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/CIDEr</td><td>2.4495</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/Cosine</td><td>0.7296</td></tr><tr><td>000422.jpg/Prompt 4/Run 1/SPICE</td><td>0.2947</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/CIDEr</td><td>2.4495</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/Cosine</td><td>0.7296</td></tr><tr><td>000422.jpg/Prompt 4/Run 2/SPICE</td><td>0.2947</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/CIDEr</td><td>1.7616</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/Cosine</td><td>0.679</td></tr><tr><td>000422.jpg/Prompt 5/Run 1/SPICE</td><td>0.1882</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/CIDEr</td><td>1.7616</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/Cosine</td><td>0.679</td></tr><tr><td>000422.jpg/Prompt 5/Run 2/SPICE</td><td>0.1882</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/CIDEr</td><td>1.1849</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/Cosine</td><td>0.5422</td></tr><tr><td>000422.jpg/Prompt 6/Run 1/SPICE</td><td>0.1449</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/CIDEr</td><td>1.1849</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/Cosine</td><td>0.5422</td></tr><tr><td>000422.jpg/Prompt 6/Run 2/SPICE</td><td>0.1449</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/CIDEr</td><td>1.1836</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/Cosine</td><td>0.7597</td></tr><tr><td>000433.jpg/Prompt 1/Run 1/SPICE</td><td>0.1132</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/CIDEr</td><td>1.1836</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/Cosine</td><td>0.7597</td></tr><tr><td>000433.jpg/Prompt 1/Run 2/SPICE</td><td>0.1132</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/CIDEr</td><td>1.2861</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/Cosine</td><td>0.7381</td></tr><tr><td>000433.jpg/Prompt 2/Run 1/SPICE</td><td>0.0702</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/CIDEr</td><td>1.2861</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/Cosine</td><td>0.7381</td></tr><tr><td>000433.jpg/Prompt 2/Run 2/SPICE</td><td>0.0702</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/CIDEr</td><td>1.342</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/Cosine</td><td>0.5592</td></tr><tr><td>000433.jpg/Prompt 3/Run 1/SPICE</td><td>0.1463</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/CIDEr</td><td>1.342</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/Cosine</td><td>0.5592</td></tr><tr><td>000433.jpg/Prompt 3/Run 2/SPICE</td><td>0.1463</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/CIDEr</td><td>1.6458</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/Cosine</td><td>0.694</td></tr><tr><td>000433.jpg/Prompt 4/Run 1/SPICE</td><td>0.1471</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/CIDEr</td><td>1.6458</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/Cosine</td><td>0.694</td></tr><tr><td>000433.jpg/Prompt 4/Run 2/SPICE</td><td>0.1471</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/CIDEr</td><td>1.2437</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/Cosine</td><td>0.7318</td></tr><tr><td>000433.jpg/Prompt 5/Run 1/SPICE</td><td>0.08</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/CIDEr</td><td>1.2437</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/Cosine</td><td>0.7318</td></tr><tr><td>000433.jpg/Prompt 5/Run 2/SPICE</td><td>0.08</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/CIDEr</td><td>0.5312</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/Cosine</td><td>0.603</td></tr><tr><td>000433.jpg/Prompt 6/Run 1/SPICE</td><td>0.0889</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/CIDEr</td><td>0.5312</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/Cosine</td><td>0.603</td></tr><tr><td>000433.jpg/Prompt 6/Run 2/SPICE</td><td>0.0889</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/CIDEr</td><td>0.1797</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/Cosine</td><td>-0.0658</td></tr><tr><td>000481.jpg/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/CIDEr</td><td>0.1797</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/Cosine</td><td>-0.0658</td></tr><tr><td>000481.jpg/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/CIDEr</td><td>1.3614</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/Cosine</td><td>0.7046</td></tr><tr><td>000481.jpg/Prompt 2/Run 1/SPICE</td><td>0.137</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/CIDEr</td><td>1.3614</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/Cosine</td><td>0.7046</td></tr><tr><td>000481.jpg/Prompt 2/Run 2/SPICE</td><td>0.137</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/CIDEr</td><td>1.1909</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/Cosine</td><td>0.5974</td></tr><tr><td>000481.jpg/Prompt 3/Run 1/SPICE</td><td>0.1791</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/CIDEr</td><td>1.1909</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/Cosine</td><td>0.5974</td></tr><tr><td>000481.jpg/Prompt 3/Run 2/SPICE</td><td>0.1791</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/CIDEr</td><td>1.506</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/Cosine</td><td>0.6636</td></tr><tr><td>000481.jpg/Prompt 4/Run 1/SPICE</td><td>0.1538</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/CIDEr</td><td>1.506</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/Cosine</td><td>0.6636</td></tr><tr><td>000481.jpg/Prompt 4/Run 2/SPICE</td><td>0.1538</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/CIDEr</td><td>1.3445</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/Cosine</td><td>0.6266</td></tr><tr><td>000481.jpg/Prompt 5/Run 1/SPICE</td><td>0.1509</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/CIDEr</td><td>1.3445</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/Cosine</td><td>0.6266</td></tr><tr><td>000481.jpg/Prompt 5/Run 2/SPICE</td><td>0.1509</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/CIDEr</td><td>0.4679</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/Cosine</td><td>0.5323</td></tr><tr><td>000481.jpg/Prompt 6/Run 1/SPICE</td><td>0.069</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/CIDEr</td><td>0.4679</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/Cosine</td><td>0.5323</td></tr><tr><td>000481.jpg/Prompt 6/Run 2/SPICE</td><td>0.069</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/CIDEr</td><td>1.2354</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/Cosine</td><td>0.7314</td></tr><tr><td>000520.jpg/Prompt 1/Run 1/SPICE</td><td>0.1967</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/CIDEr</td><td>1.2354</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/Cosine</td><td>0.7314</td></tr><tr><td>000520.jpg/Prompt 1/Run 2/SPICE</td><td>0.1967</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/CIDEr</td><td>1.3525</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/Cosine</td><td>0.7027</td></tr><tr><td>000520.jpg/Prompt 2/Run 1/SPICE</td><td>0.2029</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/CIDEr</td><td>1.3525</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/Cosine</td><td>0.7027</td></tr><tr><td>000520.jpg/Prompt 2/Run 2/SPICE</td><td>0.2029</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/CIDEr</td><td>1.5135</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/Cosine</td><td>0.2845</td></tr><tr><td>000520.jpg/Prompt 3/Run 1/SPICE</td><td>0.0741</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/CIDEr</td><td>1.5135</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/Cosine</td><td>0.2845</td></tr><tr><td>000520.jpg/Prompt 3/Run 2/SPICE</td><td>0.0741</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/CIDEr</td><td>1.8993</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/Cosine</td><td>0.658</td></tr><tr><td>000520.jpg/Prompt 4/Run 1/SPICE</td><td>0.2154</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/CIDEr</td><td>1.8993</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/Cosine</td><td>0.658</td></tr><tr><td>000520.jpg/Prompt 4/Run 2/SPICE</td><td>0.2154</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/CIDEr</td><td>1.9017</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/Cosine</td><td>0.6778</td></tr><tr><td>000520.jpg/Prompt 5/Run 1/SPICE</td><td>0.1935</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/CIDEr</td><td>1.9017</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/Cosine</td><td>0.6778</td></tr><tr><td>000520.jpg/Prompt 5/Run 2/SPICE</td><td>0.1935</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/CIDEr</td><td>0.5232</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/Cosine</td><td>0.5296</td></tr><tr><td>000520.jpg/Prompt 6/Run 1/SPICE</td><td>0.1754</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/CIDEr</td><td>0.5232</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/Cosine</td><td>0.5296</td></tr><tr><td>000520.jpg/Prompt 6/Run 2/SPICE</td><td>0.1754</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/CIDEr</td><td>1.7677</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/Cosine</td><td>0.6013</td></tr><tr><td>000541.jpg/Prompt 1/Run 1/SPICE</td><td>0.1515</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/CIDEr</td><td>1.7677</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/Cosine</td><td>0.6013</td></tr><tr><td>000541.jpg/Prompt 1/Run 2/SPICE</td><td>0.1515</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/CIDEr</td><td>2.0563</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/Cosine</td><td>0.6281</td></tr><tr><td>000541.jpg/Prompt 2/Run 1/SPICE</td><td>0.2025</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/CIDEr</td><td>2.0563</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/Cosine</td><td>0.6281</td></tr><tr><td>000541.jpg/Prompt 2/Run 2/SPICE</td><td>0.2025</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/CIDEr</td><td>1.8941</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/Cosine</td><td>0.4846</td></tr><tr><td>000541.jpg/Prompt 3/Run 1/SPICE</td><td>0.1515</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/CIDEr</td><td>1.8941</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/Cosine</td><td>0.4846</td></tr><tr><td>000541.jpg/Prompt 3/Run 2/SPICE</td><td>0.1515</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/CIDEr</td><td>1.7013</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/Cosine</td><td>0.6692</td></tr><tr><td>000541.jpg/Prompt 4/Run 1/SPICE</td><td>0.1538</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/CIDEr</td><td>1.7013</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/Cosine</td><td>0.6692</td></tr><tr><td>000541.jpg/Prompt 4/Run 2/SPICE</td><td>0.1538</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/CIDEr</td><td>1.6902</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/Cosine</td><td>0.7031</td></tr><tr><td>000541.jpg/Prompt 5/Run 1/SPICE</td><td>0.209</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/CIDEr</td><td>1.6902</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/Cosine</td><td>0.7031</td></tr><tr><td>000541.jpg/Prompt 5/Run 2/SPICE</td><td>0.209</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/CIDEr</td><td>0.941</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/Cosine</td><td>0.5261</td></tr><tr><td>000541.jpg/Prompt 6/Run 1/SPICE</td><td>0.0635</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/CIDEr</td><td>0.941</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/Cosine</td><td>0.5261</td></tr><tr><td>000541.jpg/Prompt 6/Run 2/SPICE</td><td>0.0635</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/CIDEr</td><td>1.1674</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/Cosine</td><td>0.6196</td></tr><tr><td>000698.jpg/Prompt 1/Run 1/SPICE</td><td>0.1017</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/CIDEr</td><td>1.1674</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/Cosine</td><td>0.6196</td></tr><tr><td>000698.jpg/Prompt 1/Run 2/SPICE</td><td>0.1017</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/CIDEr</td><td>1.3754</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/Cosine</td><td>0.6891</td></tr><tr><td>000698.jpg/Prompt 2/Run 1/SPICE</td><td>0.1449</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/CIDEr</td><td>1.3754</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/Cosine</td><td>0.6891</td></tr><tr><td>000698.jpg/Prompt 2/Run 2/SPICE</td><td>0.1449</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/CIDEr</td><td>1.446</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/Cosine</td><td>0.4768</td></tr><tr><td>000698.jpg/Prompt 3/Run 1/SPICE</td><td>0.1231</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/CIDEr</td><td>1.446</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/Cosine</td><td>0.4768</td></tr><tr><td>000698.jpg/Prompt 3/Run 2/SPICE</td><td>0.1231</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/CIDEr</td><td>2.0443</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/Cosine</td><td>0.7138</td></tr><tr><td>000698.jpg/Prompt 4/Run 1/SPICE</td><td>0.3117</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/CIDEr</td><td>2.0443</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/Cosine</td><td>0.7138</td></tr><tr><td>000698.jpg/Prompt 4/Run 2/SPICE</td><td>0.3117</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/CIDEr</td><td>1.1348</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/Cosine</td><td>0.5379</td></tr><tr><td>000698.jpg/Prompt 5/Run 1/SPICE</td><td>0.1563</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/CIDEr</td><td>1.1348</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/Cosine</td><td>0.5379</td></tr><tr><td>000698.jpg/Prompt 5/Run 2/SPICE</td><td>0.1563</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/CIDEr</td><td>0.5024</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/Cosine</td><td>0.5202</td></tr><tr><td>000698.jpg/Prompt 6/Run 1/SPICE</td><td>0.1493</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/CIDEr</td><td>0.5024</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/Cosine</td><td>0.5202</td></tr><tr><td>000698.jpg/Prompt 6/Run 2/SPICE</td><td>0.1493</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/CIDEr</td><td>1.8876</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/Cosine</td><td>0.6712</td></tr><tr><td>000740.jpg/Prompt 1/Run 1/SPICE</td><td>0.1892</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/CIDEr</td><td>1.8876</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/Cosine</td><td>0.6712</td></tr><tr><td>000740.jpg/Prompt 1/Run 2/SPICE</td><td>0.1892</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/CIDEr</td><td>2.1702</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/Cosine</td><td>0.6751</td></tr><tr><td>000740.jpg/Prompt 2/Run 1/SPICE</td><td>0.186</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/CIDEr</td><td>2.1702</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/Cosine</td><td>0.6751</td></tr><tr><td>000740.jpg/Prompt 2/Run 2/SPICE</td><td>0.186</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/CIDEr</td><td>2.6539</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/Cosine</td><td>0.5493</td></tr><tr><td>000740.jpg/Prompt 3/Run 1/SPICE</td><td>0.2025</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/CIDEr</td><td>2.6539</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/Cosine</td><td>0.5493</td></tr><tr><td>000740.jpg/Prompt 3/Run 2/SPICE</td><td>0.2025</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/CIDEr</td><td>2.548</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/Cosine</td><td>0.6287</td></tr><tr><td>000740.jpg/Prompt 4/Run 1/SPICE</td><td>0.1628</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/CIDEr</td><td>2.548</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/Cosine</td><td>0.6287</td></tr><tr><td>000740.jpg/Prompt 4/Run 2/SPICE</td><td>0.1628</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/CIDEr</td><td>1.9656</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/Cosine</td><td>0.4954</td></tr><tr><td>000740.jpg/Prompt 5/Run 1/SPICE</td><td>0.1</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/CIDEr</td><td>1.9656</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/Cosine</td><td>0.4954</td></tr><tr><td>000740.jpg/Prompt 5/Run 2/SPICE</td><td>0.1</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/CIDEr</td><td>0.7992</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/Cosine</td><td>0.4747</td></tr><tr><td>000740.jpg/Prompt 6/Run 1/SPICE</td><td>0.0556</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/CIDEr</td><td>0.7992</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/Cosine</td><td>0.4747</td></tr><tr><td>000740.jpg/Prompt 6/Run 2/SPICE</td><td>0.0556</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/CIDEr</td><td>1.7244</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/Cosine</td><td>0.6565</td></tr><tr><td>000869.jpg/Prompt 1/Run 1/SPICE</td><td>0.1333</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/CIDEr</td><td>1.7244</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/Cosine</td><td>0.6565</td></tr><tr><td>000869.jpg/Prompt 1/Run 2/SPICE</td><td>0.1333</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/CIDEr</td><td>1.7353</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/Cosine</td><td>0.6125</td></tr><tr><td>000869.jpg/Prompt 2/Run 1/SPICE</td><td>0.1379</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/CIDEr</td><td>1.7353</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/Cosine</td><td>0.6125</td></tr><tr><td>000869.jpg/Prompt 2/Run 2/SPICE</td><td>0.1379</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/CIDEr</td><td>2.0561</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/Cosine</td><td>0.6218</td></tr><tr><td>000869.jpg/Prompt 3/Run 1/SPICE</td><td>0.1739</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/CIDEr</td><td>2.0561</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/Cosine</td><td>0.6218</td></tr><tr><td>000869.jpg/Prompt 3/Run 2/SPICE</td><td>0.1739</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/CIDEr</td><td>1.9034</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/Cosine</td><td>0.5862</td></tr><tr><td>000869.jpg/Prompt 4/Run 1/SPICE</td><td>0.1778</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/CIDEr</td><td>1.9034</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/Cosine</td><td>0.5862</td></tr><tr><td>000869.jpg/Prompt 4/Run 2/SPICE</td><td>0.1778</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/CIDEr</td><td>2.0065</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/Cosine</td><td>0.6694</td></tr><tr><td>000869.jpg/Prompt 5/Run 1/SPICE</td><td>0.1818</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/CIDEr</td><td>2.0065</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/Cosine</td><td>0.6694</td></tr><tr><td>000869.jpg/Prompt 5/Run 2/SPICE</td><td>0.1818</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/CIDEr</td><td>0.6033</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/Cosine</td><td>0.5694</td></tr><tr><td>000869.jpg/Prompt 6/Run 1/SPICE</td><td>0.1081</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/CIDEr</td><td>0.6033</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/Cosine</td><td>0.5694</td></tr><tr><td>000869.jpg/Prompt 6/Run 2/SPICE</td><td>0.1081</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/CIDEr</td><td>1.201</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/Cosine</td><td>0.5515</td></tr><tr><td>000889.jpg/Prompt 1/Run 1/SPICE</td><td>0.2051</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/CIDEr</td><td>1.201</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/Cosine</td><td>0.5515</td></tr><tr><td>000889.jpg/Prompt 1/Run 2/SPICE</td><td>0.2051</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/CIDEr</td><td>1.5205</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/Cosine</td><td>0.7991</td></tr><tr><td>000889.jpg/Prompt 2/Run 1/SPICE</td><td>0.2353</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/CIDEr</td><td>1.5205</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/Cosine</td><td>0.7991</td></tr><tr><td>000889.jpg/Prompt 2/Run 2/SPICE</td><td>0.2353</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/CIDEr</td><td>1.1849</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/Cosine</td><td>0.5741</td></tr><tr><td>000889.jpg/Prompt 3/Run 1/SPICE</td><td>0.12</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/CIDEr</td><td>1.1849</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/Cosine</td><td>0.5741</td></tr><tr><td>000889.jpg/Prompt 3/Run 2/SPICE</td><td>0.12</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/CIDEr</td><td>1.6244</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/Cosine</td><td>0.7769</td></tr><tr><td>000889.jpg/Prompt 4/Run 1/SPICE</td><td>0.2432</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/CIDEr</td><td>1.6244</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/Cosine</td><td>0.7769</td></tr><tr><td>000889.jpg/Prompt 4/Run 2/SPICE</td><td>0.2432</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/CIDEr</td><td>0.8876</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/Cosine</td><td>0.6833</td></tr><tr><td>000889.jpg/Prompt 5/Run 1/SPICE</td><td>0.1429</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/CIDEr</td><td>0.8876</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/Cosine</td><td>0.6833</td></tr><tr><td>000889.jpg/Prompt 5/Run 2/SPICE</td><td>0.1429</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/CIDEr</td><td>0.9763</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/Cosine</td><td>0.704</td></tr><tr><td>000889.jpg/Prompt 6/Run 1/SPICE</td><td>0.2143</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/CIDEr</td><td>0.9763</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/Cosine</td><td>0.704</td></tr><tr><td>000889.jpg/Prompt 6/Run 2/SPICE</td><td>0.2143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Prompt-Eval-Qwen2.5VL7B-CarDD</strong> at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/bevtg7g8</a><br> View project at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250524_201710-bevtg7g8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421306c-8eb6-4008-98ea-22e4eb3a640c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
