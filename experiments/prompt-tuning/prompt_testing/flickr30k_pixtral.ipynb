{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93361d37-7eac-4abb-97f9-faacc6d701b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Standard import failed for UnslothDPOTrainer: No module named 'UnslothDPOTrainer'. Using tempfile instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastVisionModel, FastLanguageModel\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "from datasets import load_from_disk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e52241-aec0-4f63-aaf8-bd76e51e5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgayanukaa\u001b[0m (\u001b[33mvlm-research\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250525_071110-8n9p54lk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk' target=\"_blank\">Prompt-Eval-Pixtral12B-Flickr30k</a></strong> to <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6dffaff4f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Prompting-Experiments\",\n",
    "    name=\"Prompt-Eval-Pixtral12B-Flickr30k\",\n",
    "    group=\"prompting-experiments\",\n",
    "    tags=[\"pixtral\", \"image-captioning\", \"prompting\", \"flickr30k\"],\n",
    "    notes=\"Comparing handcrafted prompting strategies across multiple images and prompt types.\",\n",
    "    config={\n",
    "        \"model\": \"unsloth/Pixtral-12B-2409\",\n",
    "        \"prompting\": \"handcrafted\",\n",
    "        \"num_prompts\": 6,\n",
    "        \"num_runs_per_prompt\": 2,\n",
    "        \"dataset\": \"flickr30k\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c59bc64-858c-48d1-bc34-f29f04f3edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Pixtral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A40. Num GPUs = 1. Max memory: 44.448 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Pixtral does not support SDPA - switching to eager!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcbfcbe4c7b4730ad6207c1bf6b3e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Pixtral-12B-2409\",\n",
    "    load_in_4bit = True,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decc91c6-c815-4ec1-8939-2f7fb22ffa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"unsloth/Pixtral-12B-2409\"\n",
    "\n",
    "model = FastVisionModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac930dd8-f59b-4361-bae0-c39f77143b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk(\"/workspace/data/filtered_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddd2b1d-955f-4085-827e-1e0a20c7f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test Dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'caption', 'sentids', 'split', 'img_id', 'filename'],\n",
      "    num_rows: 10\n",
      "})\n",
      "Loaded 10 image-caption entries\n",
      "\n",
      "ğŸ“Œ First 5 entries:\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F6DFBFFA950>, 'caption': ['Three Caucasian hikers in summer clothes walk a dirt path through a wooded meadow during the day.', 'Three people walking down a muddy dirt road on a cloudy day.', 'Three people are walking down a dirt road in the country.', 'Three people walking on a trail in the middle of the day.', 'Three people are walking down a dirt path.'], 'sentids': ['12500', '12501', '12502', '12503', '12504'], 'split': 'train', 'img_id': '2500', 'filename': '182169366.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=356x500 at 0x7F6DFBFFB5E0>, 'caption': ['A waitress in a black T-shirt and black shorts at Cafe Mambo serves a tray of beverages to a seated customer in a red tank top and black bandanna.', 'A waitress wearing black is talking to a man who is wearing a red shirt and bandanna.', 'A waitress talking with a man at an outside cafe.', 'A blond woman in a skirt serving food to a man.', 'Man ordering drinks from a waitress.'], 'sentids': ['12505', '12506', '12507', '12508', '12509'], 'split': 'train', 'img_id': '2501', 'filename': '182184279.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F6DFBFF8C40>, 'caption': ['Two young boys are walking over a wet section of pavement, one is holding a hat over his head, the other is holding an umbrella.', 'A child, carrying a closed blue umbrella, is walking with another child who is under a yellow umbrella, on a muddy path.', 'School children walking home after a rainstorm.', 'Two little boys walking home in the rain.', 'Young boys are walking in galoshes.'], 'sentids': ['12510', '12511', '12512', '12513', '12514'], 'split': 'train', 'img_id': '2502', 'filename': '182246705.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7F6DFBFFB7F0>, 'caption': ['Some sort of outdoor event with a clown wearing a name tag that says \"Toodles\".', 'Clown standing across the street from a large group of people.', 'A clown standing in front of a crowd along a street.', 'This clown is proud to be entertaining the crowd.', 'A clown is smiling for a picture during a parade.'], 'sentids': ['12515', '12516', '12517', '12518', '12519'], 'split': 'train', 'img_id': '2503', 'filename': '182396080.jpg'} \n",
      "\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F6DFBFF9480>, 'caption': ['Two people kneel on the snow and raise their arms with mountains behind them.', 'Two people jumping up with snow covered mountains in the background.', 'Two people raise their arms on a snowy hill in the mountains.', 'Two men raise their arms atop a snowy mountain.', 'Two snowboarders throw up their hands.'], 'sentids': ['12520', '12521', '12522', '12523', '12524'], 'split': 'train', 'img_id': '2504', 'filename': '182493240.jpg'} \n",
      "\n",
      "ğŸ“‹ Column types:\n",
      "{'image': Image(mode=None, decode=True, id=None), 'caption': [Value(dtype='string', id=None)], 'sentids': [Value(dtype='string', id=None)], 'split': Value(dtype='string', id=None), 'img_id': Value(dtype='string', id=None), 'filename': Value(dtype='string', id=None)}\n",
      "\n",
      "ğŸ” Size\n",
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered test Dataset:\")\n",
    "print(test_dataset)\n",
    "\n",
    "print(f\"Loaded {len(test_dataset)} image-caption entries\\n\")\n",
    "\n",
    "print(\"ğŸ“Œ First 5 entries:\")\n",
    "first_5 = test_dataset.select(range(5))\n",
    "for row in first_5:\n",
    "    print(row, \"\\n\")\n",
    "\n",
    "print(\"ğŸ“‹ Column types:\")\n",
    "print(test_dataset.features)\n",
    "\n",
    "print(\"\\nğŸ” Size\")\n",
    "print((len(test_dataset), len(test_dataset.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784e0a55-55b5-4388-a1df-333e034d2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total filenames with duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filename_counts = Counter(test_dataset[\"filename\"])\n",
    "\n",
    "# Print filenames with more than 1 occurrence\n",
    "for filename, count in filename_counts.items():\n",
    "    if count > 1:\n",
    "        print(f\"{filename}: {count} occurrences\")\n",
    "\n",
    "num_duplicates = sum(1 for count in filename_counts.values() if count > 1)\n",
    "print(f\"\\nTotal filenames with duplicates: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c963d366-f218-4c2a-9718-3498070a1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import TextStreamer\n",
    "import pandas as pd\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, filename: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image (by filename) from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt text (can include mask tokens)\n",
    "        filename (str): Filename of the image in the DataFrame\n",
    "        df (pd.DataFrame): DataFrame with 'filename' and 'image' columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, float, float]: (Generated output, inference time in seconds, VRAM used in GB)\n",
    "    \"\"\"\n",
    "    row = df[df[\"filename\"] == filename]\n",
    "    if row.empty:\n",
    "        print(f\"[ERROR] No image found with filename: {filename}\")\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    row = row.iloc[0]\n",
    "    image = row[\"image\"]\n",
    "    if isinstance(image, dict) and \"bytes\" in image:\n",
    "        from PIL import Image\n",
    "        from io import BytesIO\n",
    "        image = Image.open(BytesIO(image[\"bytes\"])).convert(\"RGB\")\n",
    "    caption = row[\"caption\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated() / 1024 / 1024 / 1024  # in GB\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"ğŸ”¹ Image: {filename}\")\n",
    "    print(f\"ğŸ§¾ Prompt: {prompt}\")\n",
    "    print(\"ğŸ“¤ Output:\")\n",
    "\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "    # Perform inference\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.5,\n",
    "        min_p=0.1,\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "\n",
    "    time_taken = round(end_time - start_time, 3)\n",
    "    vram_used = round(end_mem - start_mem, 3)\n",
    "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"â±ï¸ Time taken: {time_taken} sec | ğŸ§  VRAM used: {vram_used} GB\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    return decoded_output, time_taken, vram_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdbeb36-49d2-4931-95d9-6a8c14f39085",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_set_0 = [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a nature trail guide. Describe whatâ€™s happening in this scene to someone preparing for their first family hike.\",\n",
    "               \"There is a <text_1> walking on a <text_2> in this image.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_1= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\",\n",
    "               \"A <text_1> is standing beside a <text_2> who is sitting down at a table.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_2= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a weather reporter documenting childrenâ€™s routines during rainy mornings. Describe whatâ€™s going on in this image.\",\n",
    "               \"<text_1> are walking with <text_2> in the rain.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_3= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\",\n",
    "               \"A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_4= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\",\n",
    "               \"Two <text_1> are sitting on a snowy slope with their arms <text_2>.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_5= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\",\n",
    "               \"A <text_1> is behind a counter filled with <text_2> in a small shop.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_6= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\",\n",
    "               \"A <text_1> is using a laptop at a desk while two <text_2> are in the background.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_7= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a canine trainer assessing a working dogâ€™s field behavior. Describe the dogâ€™s posture and role based on the scene..\",\n",
    "               \"A <text_1> is wearing a vest and holding a <text_2> in its mouth.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_8= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\",\n",
    "               \"A <text_1> is walking while carrying <text_2> suspended from a pole.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "prompt_set_9= [\"\",\n",
    "              \"How many people are playing soccer in this scene?\",\n",
    "               \"An image of...\",\n",
    "               \"You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\",\n",
    "               \"A <text_1> is painting a replica of an artwork in front of <text_2>.\",\n",
    "               \"Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\"\n",
    "               ]\n",
    "PROMPT_LIST = [prompt_set_0, prompt_set_1, prompt_set_2, prompt_set_3, prompt_set_4, prompt_set_5, prompt_set_6, prompt_set_7, prompt_set_8, prompt_set_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88ca1509-6e9e-4adc-a197-1127f29066d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Running prompts for image: 182169366.jpg (img_id: 2500)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The group in the image features a group of hikers taking a hike. skulpture.|A group.</s>\n",
      "â±ï¸ Time taken: 1.934 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The group in the image features a group of hikers taking a hike. skulpture.|A group.</s>\n",
      "â±ï¸ Time taken: 1.892 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The scene depicts a group of people playing frisbee, which two dogs, suggesting that they are a bunch of, or near the field. hÃ©tÃ©rogÃ¨nes. Or, field that a group of people of them are to . A group two of people of them is a  a of the some are to the a of they is a some.</s>\n",
      "â±ï¸ Time taken: 4.502 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The scene depicts a group of people playing frisbee, which two dogs, suggesting that they are a bunch of, or near the field. hÃ©tÃ©rogÃ¨nes. Or, field that a group of people of them are to . A group two of people of them is a  a of the some are to the a of they is a some.</s>\n",
      "â±ï¸ Time taken: 4.228 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The term \"all the way\" is typically used in the context of a specific route or journey along a chosen path or course. konflik to avoid misunderstandings.</s>\n",
      "â±ï¸ Time taken: 2.065 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The term \"all the way\" is typically used in the context of a specific route or journey along a chosen path or course. konflik to avoid misunderstandings.</s>\n",
      "â±ï¸ Time taken: 2.087 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a nature trail guide. Describe whatâ€™s happ...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: You are a nature trail guide. Describe whatâ€™s happening in this scene to someone preparing for their first family hike.\n",
      "ğŸ“¤ Output:\n",
      "As you embark on your family hike, you'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth. The path's wide and well-trod, with only gentle slopes and informative markers to guide you. As you tread, you'll notice how the dappled light filters through the leaves, dotting the woodland floor with gold. The air'll be redolent with loam and chlorophyll, a earthy and green. You'll hear the rustle of leaves, the trill of birds, and mayhap the faintest whisper of a brook.\n",
      "\n",
      "Ahead\n",
      "â±ï¸ Time taken: 8.016 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a nature trail guide. Describe whatâ€™s happ...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: You are a nature trail guide. Describe whatâ€™s happening in this scene to someone preparing for their first family hike.\n",
      "ğŸ“¤ Output:\n",
      "As you embark on your family hike, you'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth. The path's wide and well-trod, with only gentle slopes and informative markers to guide you. As you tread, you'll notice how the dappled light filters through the leaves, dotting the woodland floor with gold. The air'll be redolent with loam and chlorophyll, a earthy and green. You'll hear the rustle of leaves, the trill of birds, and mayhap the faintest whisper of a brook.\n",
      "\n",
      "Ahead\n",
      "â±ï¸ Time taken: 7.177 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: There is a <text_1> walking on a <text_2> in this ...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: There is a <text_1> walking on a <text_2> in this image.\n",
      "ğŸ“¤ Output:\n",
      "The text-while walking on a- text- thei- the a and picking up- the a the in -a gathers- the inof -n the y at h- the a- the of- or- ant- the a igh- the a- our- m the e- the a- to- ar- the en- the if- the os- the h- to- a n- the i- to a- m- the i- a- m- the i- a- to- i- a- to- i- a- to- i- a- to- i-\n",
      "â±ï¸ Time taken: 7.606 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: There is a <text_1> walking on a <text_2> in this ...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: There is a <text_1> walking on a <text_2> in this image.\n",
      "ğŸ“¤ Output:\n",
      "The text-while walking on a- text- thei- the a and picking up- the a the in -a gathers- the inof -n the y at h- the a- the of- or- ant- the a igh- the a- our- m the e- the a- to- ar- the en- the if- the os- the h- to- a n- the i- to a- m- the i- a- m- the i- a- to- i- a- to- i- a- to- i- a- to- i-\n",
      "â±ï¸ Time taken: 7.734 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** People Hiking\n",
      " terc\n",
      "**Activity:** Hiking\n",
      "**Environment:** Forest\n",
      "**Additional Notes:** A group of hikers, including children, are seen hiking on a dirt path in a forested area. The hikers are equipped with backpacks and are walking along a designated trail.\n",
      "\n",
      "**Subject:** Mountain Bikers\n",
      "**Activity:** Mountain Biking\n",
      "**Environment:** Mountain Trail\n",
      "**Additional Notes:** Mountain bikers are seen riding on a trail in a forested area. The bikers are equipped with helmets and are riding along a designated trail.\n",
      "\n",
      "**Subject:** Runners\n",
      "**Activity:** Running\n",
      "â±ï¸ Time taken: 7.929 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182169366.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** People Hiking\n",
      " terc\n",
      "**Activity:** Hiking\n",
      "**Environment:** Forest\n",
      "**Additional Notes:** A group of hikers, including children, are seen hiking on a dirt path in a forested area. The hikers are equipped with backpacks and are walking along a designated trail.\n",
      "\n",
      "**Subject:** Mountain Bikers\n",
      "**Activity:** Mountain Biking\n",
      "**Environment:** Mountain Trail\n",
      "**Additional Notes:** Mountain bikers are seen riding on a trail in a forested area. The bikers are equipped with helmets and are riding along a designated trail.\n",
      "\n",
      "**Subject:** Runners\n",
      "**Activity:** Running\n",
      "â±ï¸ Time taken: 8.399 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182184279.jpg (img_id: 2501)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "Audiences, the crowd, and the crowd,an captions, the, the the the a the a theE 1923, the the 'veggs., 'the 232 , a 'thee 'this: a 'thee 'this3., ofthes, that 23000ve 200 a 'the 'the 13, a 'the 'that 3\n",
      "\n",
      "## Answer the a 'that 300 the 1, a 'this 23</s>\n",
      "â±ï¸ Time taken: 7.699 sec | ğŸ§  VRAM used: 0.266 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "Audiences, the crowd, and the crowd,an captions, the, the the the a the a theE 1923, the the 'veggs., 'the 232 , a 'thee 'this: a 'thee 'this3., ofthes, that 23000ve 200 a 'the 'the 13, a 'the 'that 3\n",
      "\n",
      "## Answer the a 'that 300 the 1, a 'this 23</s>\n",
      "â±ï¸ Time taken: 6.557 sec | ğŸ§  VRAM used: 0.266 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a woman in black and a man blowing blowing blowing bubbles with a lighter. etapod.</s>\n",
      "â±ï¸ Time taken: 1.629 sec | ğŸ§  VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a woman in black and a man blowing blowing blowing bubbles with a lighter. etapod.</s>\n",
      "â±ï¸ Time taken: 1.684 sec | ğŸ§  VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The woman is kissing a fake mustache mouth to a man who is eating a hot dog. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 1.614 sec | ğŸ§  VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The woman is kissing a fake mustache mouth to a man who is eating a hot dog. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 1.418 sec | ğŸ§  VRAM used: 0.267 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a food critic observing customer service a...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\n",
      "ğŸ“¤ Output:\n",
      "In the 1\n",
      "\n",
      "The image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads \"Cafe' and a man wearing a bandana and a rubber duck impression of a mustache. They are playfully ham it a game, with a rubber in his a bib, which is emblazoned \"In a rubber of a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is embl\n",
      "â±ï¸ Time taken: 8.087 sec | ğŸ§  VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a food critic observing customer service a...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: You are a food critic observing customer service at cafes. Describe the interaction happening in this scene.\n",
      "ğŸ“¤ Output:\n",
      "In the 1\n",
      "\n",
      "The image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads \"Cafe' and a man wearing a bandana and a rubber duck impression of a mustache. They are playfully ham it a game, with a rubber in his a bib, which is emblazoned \"In a rubber of a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is emblazoned \"In a bib, which is embl\n",
      "â±ï¸ Time taken: 9.053 sec | ğŸ§  VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is standing beside a <text_2> who is si...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is standing beside a <text_2> who is sitting down at a table.\n",
      "ğŸ“¤ Output:\n",
      "The structure of the sentence: A is the action, conforming a the in possessive a this the into in the to a our your a this soon of and with to the 2 2020s. The their 23 our this the the 10 and for a the our into 1 1 a the the 3 and for 2 a 100 this is the 1 a the 0 this has 3 a the 0 our 3 this 0 a 3 the 0 our 3 this 0 a 3 the 0 our 3 this 0\n",
      "â±ï¸ Time taken: 7.508 sec | ğŸ§  VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is standing beside a <text_2> who is si...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is standing beside a <text_2> who is sitting down at a table.\n",
      "ğŸ“¤ Output:\n",
      "The structure of the sentence: A is the action, conforming a the in possessive a this the into in the to a our your a this soon of and with to the 2 2020s. The their 23 our this the the 10 and for a the our into 1 1 a the the 3 and for 2 a 100 this is the 1 a the 0 this has 3 a the 0 our 3 this 0 a 3 the 0 our 3 this 0 a 3 the 0 our 3 this 0\n",
      "â±ï¸ Time taken: 8.271 sec | ğŸ§  VRAM used: 0.269 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Two people, a boy and a girl\n",
      " tercena\n",
      "**Activity:** The boy is kissing the girl on the cheek\n",
      "**Environment:** A crowded public place, maybe a mall\n",
      "**Additional Notes: Unterschied between their ages, casual clothing, public display of affection\n",
      "\n",
      "---\n",
      "\n",
      "It seems there is a significant difference in the ages of the two, as indicated by the difference in their physical appearances. Additionally, their casual clothing styles also reflect this age difference. The bold display of affection, kissing on the cheek in a public place, may also suggest a difference in their comfort levels with public displays of affection.</s>\n",
      "â±ï¸ Time taken: 8.189 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182184279.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Two people, a boy and a girl\n",
      " tercena\n",
      "**Activity:** The boy is kissing the girl on the cheek\n",
      "**Environment:** A crowded public place, maybe a mall\n",
      "**Additional Notes: Unterschied between their ages, casual clothing, public display of affection\n",
      "\n",
      "---\n",
      "\n",
      "It seems there is a significant difference in the ages of the two, as indicated by the difference in their physical appearances. Additionally, their casual clothing styles also reflect this age difference. The bold display of affection, kissing on the cheek in a public place, may also suggest a difference in their comfort levels with public displays of affection.</s>\n",
      "â±ï¸ Time taken: 7.54 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182246705.jpg (img_id: 2502)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The children are often seen walking down a dirt road with raincoat, Raining, each holding an umbrella. hÃ©tÃ©rogÃ¨nes, one with a backpack. The childreaching up to touch a bird sitting on a fence. Additional information provided: The children are wearing raincoats and rain boots. The ground is wet from the recent rain. The children seem to be enjoying themselves despite the wet conditions.</s>\n",
      "â±ï¸ Time taken: 5.296 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The children are often seen walking down a dirt road with raincoat, Raining, each holding an umbrella. hÃ©tÃ©rogÃ¨nes, one with a backpack. The childreaching up to touch a bird sitting on a fence. Additional information provided: The children are wearing raincoats and rain boots. The ground is wet from the recent rain. The children seem to be enjoying themselves despite the wet conditions.</s>\n",
      "â±ï¸ Time taken: 4.949 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts two young boys walking on a dirt road with umbrella. edukit.</s>\n",
      "â±ï¸ Time taken: 1.199 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts two young boys walking on a dirt road with umbrella. edukit.</s>\n",
      "â±ï¸ Time taken: 1.399 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The two children are playing with a colorful outdoor play area rug with a luge. edukasyon\n",
      "A:Q: What is the largest organellepsst their favorite game to play?</s>\n",
      "â±ï¸ Time taken: 2.802 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The two children are playing with a colorful outdoor play area rug with a luge. edukasyon\n",
      "A:Q: What is the largest organellepsst their favorite game to play?</s>\n",
      "â±ï¸ Time taken: 2.758 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a weather reporter documenting childrenâ€™s ...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: You are a weather reporter documenting childrenâ€™s routines during rainy mornings. Describe whatâ€™s going on in this image.\n",
      "ğŸ“¤ Output:\n",
      "In the midst of a lush, verdant garden, two young adventurers, each equipped with vibrant backpacks and umbreitas they embark on an expedition. The first adventurer, garbed in a blue raincoat and matching hat, toting a brilliant yellow parasol, strides forward, a blue backpack strapped securely to their back. Parallel to them, the second adventurer, cloaked in a red raincoat and matching hat, bears aloft a matching red parasol, a green backpack riding high on their shoulders. Their path, a winding trail of pebbles, meanders through the garden,\n",
      "â±ï¸ Time taken: 8.28 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a weather reporter documenting childrenâ€™s ...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: You are a weather reporter documenting childrenâ€™s routines during rainy mornings. Describe whatâ€™s going on in this image.\n",
      "ğŸ“¤ Output:\n",
      "In the midst of a lush, verdant garden, two young adventurers, each equipped with vibrant backpacks and umbreitas they embark on an expedition. The first adventurer, garbed in a blue raincoat and matching hat, toting a brilliant yellow parasol, strides forward, a blue backpack strapped securely to their back. Parallel to them, the second adventurer, cloaked in a red raincoat and matching hat, bears aloft a matching red parasol, a green backpack riding high on their shoulders. Their path, a winding trail of pebbles, meanders through the garden,\n",
      "â±ï¸ Time taken: 7.437 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: <text_1> are walking with <text_2> in the rain.\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: <text_1> are walking with <text_2> in the rain.\n",
      "ğŸ“¤ Output:\n",
      "The image depicts two small children, a young boy and a young girl, walking down a gravel path in a garden. The children are carrying a umbrella and a fishing net, and are wearing rain boots. They are passing a pond and flowers on the side of the path. The children seem to be on an adventure, exploring the outdoors.</s>\n",
      "â±ï¸ Time taken: 3.957 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: <text_1> are walking with <text_2> in the rain.\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: <text_1> are walking with <text_2> in the rain.\n",
      "ğŸ“¤ Output:\n",
      "The image depicts two small children, a young boy and a young girl, walking down a gravel path in a garden. The children are carrying a umbrella and a fishing net, and are wearing rain boots. They are passing a pond and flowers on the side of the path. The children seem to be on an adventure, exploring the outdoors.</s>\n",
      "â±ï¸ Time taken: 3.989 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Children playing with umbrea and backpacks\n",
      "**Activity: Children playing with toy umbrellas and toy cameras\n",
      "**Environment: Garden path with flowers and puddles\n",
      "**Additional Notes: The children are enjoying themselves, jumping in puddles with their toy umbrellas and cameras. They are having a great time outdoors in the garden, exploring and playing with their toys. The garden is beautiful with flowers and a path for the children to jump in the puddles.</s>\n",
      "â±ï¸ Time taken: 5.922 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182246705.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Children playing with umbrea and backpacks\n",
      "**Activity: Children playing with toy umbrellas and toy cameras\n",
      "**Environment: Garden path with flowers and puddles\n",
      "**Additional Notes: The children are enjoying themselves, jumping in puddles with their toy umbrellas and cameras. They are having a great time outdoors in the garden, exploring and playing with their toys. The garden is beautiful with flowers and a path for the children to jump in the puddles.</s>\n",
      "â±ï¸ Time taken: 5.941 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182396080.jpg (img_id: 2503)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and playful clown costume, 39;s[^ clown,Clown costume, Smurf (ï¿½omb in the ground, the in the person's the 2019a complete the 13, a the 15, a the 10, .16-7, .9a clown1, .</s>\n",
      "â±ï¸ Time taken: 4.302 sec | ğŸ§  VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and playful clown costume, 39;s[^ clown,Clown costume, Smurf (ï¿½omb in the ground, the in the person's the 2019a complete the 13, a the 15, a the 10, .16-7, .9a clown1, .</s>\n",
      "â±ï¸ Time taken: 4.763 sec | ğŸ§  VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and playful clown costume attire resembling Ronald McDonald's outfit, with a 16, withiba16 socrates with many people. edukie-better than3.</s>\n",
      "â±ï¸ Time taken: 3.245 sec | ğŸ§  VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and playful clown costume attire resembling Ronald McDonald's outfit, with a 16, withiba16 socrates with many people. edukie-better than3.</s>\n",
      "â±ï¸ Time taken: 3.26 sec | ğŸ§  VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and juggling outfit, consisting of aown, with a little girl Cray of funhouseplantation or location, with funnymouseiÂ­ theroni- in the crowd of and children n'tI- \" and the fun, a the a the - CLOWELLIS A WHOSE the the the a the -a  job the a the a the a the - in a the a the a the a the a the - show the a the 's the a the -e that 13006 the a the a 'a to the a ' to ' to a ' to\n",
      "â±ï¸ Time taken: 8.869 sec | ğŸ§  VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a colorful and juggling outfit, consisting of aown, with a little girl Cray of funhouseplantation or location, with funnymouseiÂ­ theroni- in the crowd of and children n'tI- \" and the fun, a the a the - CLOWELLIS A WHOSE the the the a the -a  job the a the a the a the - in a the a the a the a the a the - show the a the 's the a the -e that 13006 the a the a 'a to the a ' to ' to a ' to\n",
      "â±ï¸ Time taken: 7.499 sec | ğŸ§  VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a journalist covering a small-town parade....\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\n",
      "ğŸ“¤ Output:\n",
      "In the scene, aicularly clown costume, a colorful, the festive atmosphere of the festivities, a part of a clown's a colorful costume the merrifai??[^mischar with a festive the is a clown's a festive atmosphere the mwith a festive the merringly with a festive the merringly\n",
      "___\n",
      "a the migh with a the merringly\n",
      "a festive the charm of a festive the charmingly\n",
      "a festive the charmingly\n",
      "a festive the charmingly\n",
      "a the charmingly\n",
      "a festive the charmingly\n",
      "a the charm\n",
      "â±ï¸ Time taken: 7.812 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a journalist covering a small-town parade....\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: You are a journalist covering a small-town parade. Describe the role and setting of the clown in this festive scene.\n",
      "ğŸ“¤ Output:\n",
      "In the scene, aicularly clown costume, a colorful, the festive atmosphere of the festivities, a part of a clown's a colorful costume the merrifai??[^mischar with a festive the is a clown's a festive atmosphere the mwith a festive the merringly with a festive the merringly\n",
      "___\n",
      "a the migh with a the merringly\n",
      "a festive the charm of a festive the charmingly\n",
      "a festive the charmingly\n",
      "a festive the charmingly\n",
      "a the charmingly\n",
      "a festive the charmingly\n",
      "a the charm\n",
      "â±ï¸ Time taken: 7.929 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> with bright makeup and colorful clothes...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a person in the middle, for a is wearing colorful outfit and large shoes, with a costume.</s>\n",
      "â±ï¸ Time taken: 1.511 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> with bright makeup and colorful clothes...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> with bright makeup and colorful clothes stands near a <text_2> during an event.\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a person in the middle, for a is wearing colorful outfit and large shoes, with a costume.</s>\n",
      "â±ï¸ Time taken: 1.504 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      " terc: Performing as a clown at a. Performing as a. Brightly lit. festive and colorful costume with exaggerated makeup and a festive. Small town, festive with a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a fest\n",
      "â±ï¸ Time taken: 7.75 sec | ğŸ§  VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182396080.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      " terc: Performing as a clown at a. Performing as a. Brightly lit. festive and colorful costume with exaggerated makeup and a festive. Small town, festive with a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a festive. Carnival worker in a fest\n",
      "â±ï¸ Time taken: 7.99 sec | ğŸ§  VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182493240.jpg (img_id: 2504)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The sky with fluffy white snow\n",
      " kampanterrhea maintanhiu I've, the ize S the the aAnd this in the a the, 141, the a the, the the the the the a the e who13ssan dI'st the a 'in g o.</s>\n",
      "â±ï¸ Time taken: 4.032 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The sky with fluffy white snow\n",
      " kampanterrhea maintanhiu I've, the ize S the the aAnd this in the a the, 141, the a the, the the the the the a the e who13ssan dI'st the a 'in g o.</s>\n",
      "â±ï¸ Time taken: 3.933 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The group of people in the image seems to be playing soccer?</s>\n",
      "â±ï¸ Time taken: 1.001 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The group of people in the image seems to be playing soccer?</s>\n",
      "â±ï¸ Time taken: 1.011 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The sky is clear and blue. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 0.859 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The sky is clear and blue. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 0.791 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a winter sports photographer recounting a ...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\n",
      "ğŸ“¤ Output:\n",
      "In the heart of the majestic, snow-capped peaks stretched out before us, their triumphant poses, their jubilant, their jubilant, anted in jubilant, ant the sky, their joyous, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant\n",
      "â±ï¸ Time taken: 7.81 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a winter sports photographer recounting a ...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: You are a winter sports photographer recounting a joyful moment you captured. Describe the scene with vivid detail.\n",
      "ğŸ“¤ Output:\n",
      "In the heart of the majestic, snow-capped peaks stretched out before us, their triumphant poses, their jubilant, their jubilant, anted in jubilant, ant the sky, their joyous, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant the sky, ant\n",
      "â±ï¸ Time taken: 7.341 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Two <text_1> are sitting on a snowy slope with the...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: Two <text_1> are sitting on a snowy slope with their arms <text_2>.\n",
      "ğŸ“¤ Output:\n",
      "The sentence above the snow with their hands in the sky with their a on the ground, the a the a the a the in the a the a the in the a the a the in the  the  a the 2. baita the 2013.</s>\n",
      "â±ï¸ Time taken: 3.649 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Two <text_1> are sitting on a snowy slope with the...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: Two <text_1> are sitting on a snowy slope with their arms <text_2>.\n",
      "ğŸ“¤ Output:\n",
      "The sentence above the snow with their hands in the sky with their a on the ground, the a the a the a the in the a the a the in the a the a the in the  the  a the 2. baita the 2013.</s>\n",
      "â±ï¸ Time taken: 3.254 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Snowboarding\n",
      " tercane/em of aq: Snowboarding\n",
      "**e: Mountains\n",
      "**dditional Notes: he couple celebrating in the snow with the mountains in the background</s>\n",
      "â±ï¸ Time taken: 2.63 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182493240.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Snowboarding\n",
      " tercane/em of aq: Snowboarding\n",
      "**e: Mountains\n",
      "**dditional Notes: he couple celebrating in the snow with the mountains in the background</s>\n",
      "â±ï¸ Time taken: 2.489 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182503906.jpg (img_id: 2505)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The expansive grocery store with a wide variety of goods on shelves, ranging from candies to dried goods, with bulk, and other</s>\n",
      "â±ï¸ Time taken: 1.855 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The expansive grocery store with a wide variety of goods on shelves, ranging from candies to dried goods, with bulk, and other</s>\n",
      "â±ï¸ Time taken: 1.746 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The store is well stocked with a variety of goods on shelves. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 1.158 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The store is well stocked with a variety of goods on shelves. hÃ©tÃ©rogÃ¨nes.</s>\n",
      "â±ï¸ Time taken: 1.286 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The interior of a grocery store is very colorful and seems to be very large and large?</s>\n",
      "â±ï¸ Time taken: 1.417 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The interior of a grocery store is very colorful and seems to be very large and large?</s>\n",
      "â±ï¸ Time taken: 1.255 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a market researcher documenting traditiona...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\n",
      "ğŸ“¤ Output:\n",
      "The scene depicts a bustling, well-stocked traditional grocery store bustling with a variety of products. The store is characterized by its rustic charm, with wooden shelves stacked high with an assortment of canned goods, jars, and other staples. The store's interior is warmly illuminated by flickering light bulbs, casting a cozy glow over the scene.\n",
      "\n",
      "In the midst of the store, a boy is engrossed in his task, meticulously scooping cereal from a large bin into a bag. His focus is unwavering, a testament to his dedication to his duty.\n",
      "\n",
      "The store's atmosphere is\n",
      "â±ï¸ Time taken: 7.571 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a market researcher documenting traditiona...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: You are a market researcher documenting traditional grocery stores. Describe what the boy is doing and what the store looks like.\n",
      "ğŸ“¤ Output:\n",
      "The scene depicts a bustling, well-stocked traditional grocery store bustling with a variety of products. The store is characterized by its rustic charm, with wooden shelves stacked high with an assortment of canned goods, jars, and other staples. The store's interior is warmly illuminated by flickering light bulbs, casting a cozy glow over the scene.\n",
      "\n",
      "In the midst of the store, a boy is engrossed in his task, meticulously scooping cereal from a large bin into a bag. His focus is unwavering, a testament to his dedication to his duty.\n",
      "\n",
      "The store's atmosphere is\n",
      "â±ï¸ Time taken: 7.203 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is behind a counter filled with <text_2...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is behind a counter filled with <text_2> in a small shop.\n",
      "ğŸ“¤ Output:\n",
      "The contextually, a large store with a shelf of candy: every and where you're like of a lot and you've and only the is\n",
      "\n",
      "The store\n",
      "\n",
      "A story the a are the orbs.</s>\n",
      "â±ï¸ Time taken: 2.496 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is behind a counter filled with <text_2...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is behind a counter filled with <text_2> in a small shop.\n",
      "ğŸ“¤ Output:\n",
      "The contextually, a large store with a shelf of candy: every and where you're like of a lot and you've and only the is\n",
      "\n",
      "The store\n",
      "\n",
      "A story the a are the orbs.</s>\n",
      "â±ï¸ Time taken: 3.108 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Image of a large store with vast assortment of goods\n",
      " tercet\n",
      "**Activity:** Shoppers browsing and selecting items\n",
      "**Environment:** Busy indoor store with wide aisles of products\n",
      "**Additional Notes:** The store specializes in a huge selection of candies and snacks, with numerous bins of bulk candy and shelves of packaged goods. The store appears well-stocked and well-lit, with a classic, retro feel. There are signs in multiple languages, indicating a diverse customer base.</s>\n",
      "â±ï¸ Time taken: 6.06 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182503906.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Image of a large store with vast assortment of goods\n",
      " tercet\n",
      "**Activity:** Shoppers browsing and selecting items\n",
      "**Environment:** Busy indoor store with wide aisles of products\n",
      "**Additional Notes:** The store specializes in a huge selection of candies and snacks, with numerous bins of bulk candy and shelves of packaged goods. The store appears well-stocked and well-lit, with a classic, retro feel. There are signs in multiple languages, indicating a diverse customer base.</s>\n",
      "â±ï¸ Time taken: 6.242 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 1827287777.jpg (img_id: 2506)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The central image depicts a person sitting at a wooden desk, working on a laptop. maksimum. 2. There is also standing up, with crossed hands on the desk, and there is also standing, with crossed hands on the hip, looking at the laptop screen. The room have posters on the wall. One of the posters is pacis a comic book posters.</s>\n",
      "â±ï¸ Time taken: 4.539 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The central image depicts a person sitting at a wooden desk, working on a laptop. maksimum. 2. There is also standing up, with crossed hands on the desk, and there is also standing, with crossed hands on the hip, looking at the laptop screen. The room have posters on the wall. One of the posters is pacis a comic book posters.</s>\n",
      "â±ï¸ Time taken: 4.382 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a group of people in a room, with a laptop on a desk. maksimum.</s>\n",
      "â±ï¸ Time taken: 1.607 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a group of people in a room, with a laptop on a desk. maksimum.</s>\n",
      "â±ï¸ Time taken: 1.558 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a man sitting at a wooden desk, typing on a laptop. prouctions on the desk, including a headphones. The man is wearing a black and a black shirt with a black wristwatch. On the wall behind him, there are three posters.</s>\n",
      "â±ï¸ Time taken: 3.185 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a man sitting at a wooden desk, typing on a laptop. prouctions on the desk, including a headphones. The man is wearing a black and a black shirt with a black wristwatch. On the wall behind him, there are three posters.</s>\n",
      "â±ï¸ Time taken: 3.352 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are an IT workplace culture analyst. Describe ...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\n",
      "ğŸ“¤ Output:\n",
      "The work environment depicted in the image appears to portray a casual and informal office culture. The central figure is seen working on a laptop while seated on an oversized, unconventional office chair, which resembles a giant hand, suggesting a playful and relaxed atmosphere. The walls are adorned with humorous and lighthearted posters, reinforcing the informal vibe. Another individual is casually leaning against a wall, dressed in casual attire, further emphasizing the informal dress code. The presence of various tech gadgets, such as headphones and a laptop, indicates a tech-savvy and modern workplace. The overall scene suggests a dynamic and friendly team dynamic,\n",
      "â±ï¸ Time taken: 7.96 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are an IT workplace culture analyst. Describe ...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: You are an IT workplace culture analyst. Describe the work environment and team dynamic shown in this image.\n",
      "ğŸ“¤ Output:\n",
      "The work environment depicted in the image appears to portray a casual and informal office culture. The central figure is seen working on a laptop while seated on an oversized, unconventional office chair, which resembles a giant hand, suggesting a playful and relaxed atmosphere. The walls are adorned with humorous and lighthearted posters, reinforcing the informal vibe. Another individual is casually leaning against a wall, dressed in casual attire, further emphasizing the informal dress code. The presence of various tech gadgets, such as headphones and a laptop, indicates a tech-savvy and modern workplace. The overall scene suggests a dynamic and friendly team dynamic,\n",
      "â±ï¸ Time taken: 7.783 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is using a laptop at a desk while two <...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "ğŸ“¤ Output:\n",
      "Sure, here's a detailed summary of the passage, properly formatted and with the changes highlighted accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "\n",
      "Please replace the following text with the highlighted text.\n",
      "\n",
      "Original text: `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "Formatted and highlighted text:\n",
      "\n",
      "A `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "This revision ensures the text is properly formatted and the highlighted changes are incorporated.\n",
      "â±ï¸ Time taken: 7.184 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is using a laptop at a desk while two <...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "ğŸ“¤ Output:\n",
      "Sure, here's a detailed summary of the passage, properly formatted and with the changes highlighted accordingly.\n",
      "\n",
      "---\n",
      "\n",
      "A <text_1> is using a laptop at a desk while two <text_2> are in the background.\n",
      "\n",
      "Please replace the following text with the highlighted text.\n",
      "\n",
      "Original text: `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "Formatted and highlighted text:\n",
      "\n",
      "A `<text_1>` is using a laptop at a desk while two `<text_2>` are in the background.\n",
      "\n",
      "This revision ensures the text is properly formatted and the highlighted changes are incorporated.\n",
      "â±ï¸ Time taken: 7.208 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Man working on a laptop\n",
      "**Activity:** Sitting at a desk, using a laptop\n",
      "**Environment:** Office setting with a desk, chair, and posters on the wall\n",
      "**Additional Notes: **A man is intensely working on his laptop, seemingly in a casual office environment with humorous posters on the wall, including one depicting a character from a popular show. Another man is standing and observing the seated man, adding a casual and relaxed atmosphere to the workspace.</s>\n",
      "â±ï¸ Time taken: 6.096 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 1827287777.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Man working on a laptop\n",
      "**Activity:** Sitting at a desk, using a laptop\n",
      "**Environment:** Office setting with a desk, chair, and posters on the wall\n",
      "**Additional Notes: **A man is intensely working on his laptop, seemingly in a casual office environment with humorous posters on the wall, including one depicting a character from a popular show. Another man is standing and observing the seated man, adding a casual and relaxed atmosphere to the workspace.</s>\n",
      "â±ï¸ Time taken: 5.856 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 1827560917.jpg (img_id: 2507)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The dog is also laying on the grass. Î¤Î¿Ï… construct.</s>\n",
      "â±ï¸ Time taken: 0.93 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The dog is also laying on the grass. Î¤Î¿Ï… construct.</s>\n",
      "â±ï¸ Time taken: 0.922 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a playful pup with a soccer ball in its mouth. etaplaying with a \n",
      "\n",
      "From the nearby 13, 2 a the ground, a 2with a the 13 theF 2with a the 12with a 11 the 10with a 9 the 8with a 7 the 6with a 5 the 4with a 3 the 2with a 1with a 0the end.</s>\n",
      "â±ï¸ Time taken: 5.764 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a playful pup with a soccer ball in its mouth. etaplaying with a \n",
      "\n",
      "From the nearby 13, 2 a the ground, a 2with a the 13 theF 2with a the 12with a 11 the 10with a 9 the 8with a 7 the 6with a 5 the 4with a 3 the 2with a 1with a 0the end.</s>\n",
      "â±ï¸ Time taken: 5.739 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The object returned 3 0.653.</s>\n",
      "â±ï¸ Time taken: 0.931 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The object returned 3 0.653.</s>\n",
      "â±ï¸ Time taken: 0.931 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a canine trainer assessing a working dogâ€™s...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: You are a canine trainer assessing a working dogâ€™s field behavior. Describe the dogâ€™s posture and role based on the scene..\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a small, fluffy black and white dog wearing a reflective harness with an orange and green design on its back. The harness has reflective strips and a handle on top for leading. The dog is standing on patch of grass, looking eagerly upward, with an object in its mouth. appears to be tug toy, which is gripping in its jaws. The dog's ears are perked up, and its eyes are wide open, indicating excitement and focus. The scene suggests playful, outdoor activity, such as a game of fetch or tug-of-war. The harness and reflective strips on it suggest that the dog is well-equipped for\n",
      "â±ï¸ Time taken: 9.58 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a canine trainer assessing a working dogâ€™s...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: You are a canine trainer assessing a working dogâ€™s field behavior. Describe the dogâ€™s posture and role based on the scene..\n",
      "ğŸ“¤ Output:\n",
      "The image depicts a small, fluffy black and white dog wearing a reflective harness with an orange and green design on its back. The harness has reflective strips and a handle on top for leading. The dog is standing on patch of grass, looking eagerly upward, with an object in its mouth. appears to be tug toy, which is gripping in its jaws. The dog's ears are perked up, and its eyes are wide open, indicating excitement and focus. The scene suggests playful, outdoor activity, such as a game of fetch or tug-of-war. The harness and reflective strips on it suggest that the dog is well-equipped for\n",
      "â±ï¸ Time taken: 7.709 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is wearing a vest and holding a <text_2...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is wearing a vest and holding a <text_2> in its mouth.\n",
      "ğŸ“¤ Output:\n",
      "The given image is of a cute small black, white, and brown, with a  with long, thick, black, and white, long, thick, glossy black, white, and brown, with, glossy black, and white, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, glossy black, and white, with, thick, gloss white, and black, with, thick, glossy black\n",
      "â±ï¸ Time taken: 7.706 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is wearing a vest and holding a <text_2...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is wearing a vest and holding a <text_2> in its mouth.\n",
      "ğŸ“¤ Output:\n",
      "The given image is of a cute small black, white, and brown, with a  with long, thick, black, and white, long, thick, glossy black, white, and brown, with, glossy black, and white, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, gloss white, and black, with, thick, glossy black, and white, with, thick, gloss white, and black, with, thick, glossy black\n",
      "â±ï¸ Time taken: 7.563 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Dog playing with a toy\n",
      " terc\n",
      "**Activity:** Tug of War\n",
      "**Environment:** Park\n",
      "**Additional Notes:**\n",
      "- The dog appears to be a Border Terrier, known for their tenacity and agility.\n",
      "- The toy is a large, stick, suitable for a strong play.\n",
      "- The harness the dog is wearing is brightly colored, ensuring high visibility during outdoor activities.\n",
      "- The environment seems to be a natural, open space, ideal for play.\n",
      "- The dog's focused and engaged in the play, indicating enjoyment and stimulation.</s>\n",
      "â±ï¸ Time taken: 6.567 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 1827560917.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "**Subject:** Dog playing with a toy\n",
      " terc\n",
      "**Activity:** Tug of War\n",
      "**Environment:** Park\n",
      "**Additional Notes:**\n",
      "- The dog appears to be a Border Terrier, known for their tenacity and agility.\n",
      "- The toy is a large, stick, suitable for a strong play.\n",
      "- The harness the dog is wearing is brightly colored, ensuring high visibility during outdoor activities.\n",
      "- The environment seems to be a natural, open space, ideal for play.\n",
      "- The dog's focused and engaged in the play, indicating enjoyment and stimulation.</s>\n",
      "â±ï¸ Time taken: 6.79 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 182825639.jpg (img_id: 2508)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The depicted person, in the raincoat, and is outervuma that â€” the a on the, aoccupe ofief the a this, a ( s: a of red-in- a you`1. novemb hiss, 0.achs so f0]3, inand iful f, 's the, ol system.//</s>\n",
      "â±ï¸ Time taken: 4.172 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The depicted person, in the raincoat, and is outervuma that â€” the a on the, aoccupe ofief the a this, a ( s: a of red-in- a you`1. novemb hiss, 0.achs so f0]3, inand iful f, 's the, ol system.//</s>\n",
      "â±ï¸ Time taken: 4.611 sec | ğŸ§  VRAM used: 0.27 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The depicted scene features a child playing with a tricycle prop, specifically a type of small childâ€™s plaything. edukation, Kem as a activity, with a playardua nstrength, a devely of a game, with toy as a playarduild, with a to of a play as a thing, with a toy, with a toyouth, with a to be a thing, with a toy, with a to be of a game, with a to be of a play as a to be of a to, with a to be of a to, with a to be of a to,\n",
      "â±ï¸ Time taken: 8.478 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The depicted scene features a child playing with a tricycle prop, specifically a type of small childâ€™s plaything. edukation, Kem as a activity, with a playardua nstrength, a devely of a game, with toy as a playarduild, with a to of a play as a thing, with a toy, with a toyouth, with a to be a thing, with a toy, with a to be of a game, with a to be of a play as a to be of a to, with a to be of a to, with a to be of a to,\n",
      "â±ï¸ Time taken: 7.074 sec | ğŸ§  VRAM used: 0.272 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a conical hat and is pulling a string attached to a very large suitcase. etapathere attached to a leg of a the a the a on the line of the, a the line sofa the in the the roof the top: a the : // the of the the Nagi : the the : the - crosshat: the t- a : a 've : a to e: a ', a 1, a[an- a 1 a 1: the 1.</s>\n",
      "â±ï¸ Time taken: 6.546 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The person is wearing a conical hat and is pulling a string attached to a very large suitcase. etapathere attached to a leg of a the a the a on the line of the, a the line sofa the in the the roof the top: a the : // the of the the Nagi : the the : the - crosshat: the t- a : a 've : a to e: a ', a 1, a[an- a 1 a 1: the 1.</s>\n",
      "â±ï¸ Time taken: 6.336 sec | ğŸ§  VRAM used: 0.271 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a cultural anthropologist documenting trad...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\n",
      "ğŸ“¤ Output:\n",
      "In the image, a person is depicted engaging in the traditional street labor, specifically, they are seen carrying a large bundle strapped to their back using a traditional shoulder pole, a form of headwear, known as a coolie hat, is popular in many parts of a Southeast Asia. The person is dressed in a light- colored, long-sleeved shirt, light-colored pants with a distinctive pattern, and flip-flops. They are walking on a even, paved surface, adjacent to a plain, light-colored wall.\n",
      "\n",
      "The individual is transporting two large, woven baskets, one in each hand, suspended from end of a long\n",
      "â±ï¸ Time taken: 7.715 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a cultural anthropologist documenting trad...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: You are a cultural anthropologist documenting traditional street labor. Describe what the person is doing and how they are carrying the items.\n",
      "ğŸ“¤ Output:\n",
      "In the image, a person is depicted engaging in the traditional street labor, specifically, they are seen carrying a large bundle strapped to their back using a traditional shoulder pole, a form of headwear, known as a coolie hat, is popular in many parts of a Southeast Asia. The person is dressed in a light- colored, long-sleeved shirt, light-colored pants with a distinctive pattern, and flip-flops. They are walking on a even, paved surface, adjacent to a plain, light-colored wall.\n",
      "\n",
      "The individual is transporting two large, woven baskets, one in each hand, suspended from end of a long\n",
      "â±ï¸ Time taken: 7.614 sec | ğŸ§  VRAM used: 0.274 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is walking while carrying <text_2> susp...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is walking while carrying <text_2> suspended from a pole.\n",
      "ğŸ“¤ Output:\n",
      "Certainly, the term we are looking for is: \"A person walking while carrying _B a basket on a shoulder, \"basket\" is the a on and _the ____ is walking ____ is a ____ is a ____ is ____ is a ____ is ____ is a _is a _\"is a _\"is a _\"is a _\"or _is a _\"or _\"or _or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\n",
      "â±ï¸ Time taken: 7.15 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is walking while carrying <text_2> susp...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is walking while carrying <text_2> suspended from a pole.\n",
      "ğŸ“¤ Output:\n",
      "Certainly, the term we are looking for is: \"A person walking while carrying _B a basket on a shoulder, \"basket\" is the a on and _the ____ is walking ____ is a ____ is a ____ is ____ is a ____ is ____ is a _is a _\"is a _\"is a _\"is a _\"or _is a _\"or _\"or _or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\"or _\n",
      "â±ï¸ Time taken: 7.224 sec | ğŸ§  VRAM used: 0.273 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Playful and Whimsical Playtime Scene\n",
      "**Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "**Environment:** A sunny and bright, with a plain white wall and ground backdrop\n",
      "**Additional Notes:** The child seems to be enjoying the play, wearing mismatched outfit with a conical hat, and the scale is creatively used as a toy\n",
      "\n",
      "Here are the details in the specified format:\n",
      "\n",
      "- **Subject:** Playful Playtime Scene\n",
      "- **Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "- **Environment:** A sunny\n",
      "â±ï¸ Time taken: 7.189 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 182825639.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      "Subject: Playful and Whimsical Playtime Scene\n",
      "**Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "**Environment:** A sunny and bright, with a plain white wall and ground backdrop\n",
      "**Additional Notes:** The child seems to be enjoying the play, wearing mismatched outfit with a conical hat, and the scale is creatively used as a toy\n",
      "\n",
      "Here are the details in the specified format:\n",
      "\n",
      "- **Subject:** Playful Playtime Scene\n",
      "- **Activity:** A child is playfully balancing a basket scale with a conical hat and bags\n",
      "- **Environment:** A sunny\n",
      "â±ï¸ Time taken: 7.577 sec | ğŸ§  VRAM used: 0.276 GB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ” Running prompts for image: 18284727.jpg (img_id: 2509)\n",
      "------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: \n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The woman admiring, fascinated by a curator, [START\n",
      "\n",
      "## Image of a that you\"r by a description: aThis? with a letâ€™s a to:strengrossd by you attention:as off6l  be g for to bethat seems to:</s>\n",
      "â±ï¸ Time taken: 4.338 sec | ğŸ§  VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: \n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: \n",
      "ğŸ“¤ Output:\n",
      "The woman admiring, fascinated by a curator, [START\n",
      "\n",
      "## Image of a that you\"r by a description: aThis? with a letâ€™s a to:strengrossd by you attention:as off6l  be g for to bethat seems to:</s>\n",
      "â±ï¸ Time taken: 3.429 sec | ğŸ§  VRAM used: 0.253 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The woman is sitting in a chair, viewing 2pictures with ornate gilding. edukase available cognitive faily.</s>\n",
      "â±ï¸ Time taken: 1.689 sec | ğŸ§  VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: How many people are playing soccer in this scene?\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: How many people are playing soccer in this scene?\n",
      "ğŸ“¤ Output:\n",
      "The woman is sitting in a chair, viewing 2pictures with ornate gilding. edukase available cognitive faily.</s>\n",
      "â±ï¸ Time taken: 1.69 sec | ğŸ§  VRAM used: 0.255 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: An image of...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The artwork is being revered as a: a shrine. hÃ©tÃ©rogÃ¨nes</s>\n",
      "â±ï¸ Time taken: 0.951 sec | ğŸ§  VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: An image of...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: An image of...\n",
      "ğŸ“¤ Output:\n",
      "The artwork is being revered as a: a shrine. hÃ©tÃ©rogÃ¨nes</s>\n",
      "â±ï¸ Time taken: 0.959 sec | ğŸ§  VRAM used: 0.254 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: You are a museum docent giving a tour. Describe th...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\n",
      "ğŸ“¤ Output:\n",
      "As a woman in the art gallery, a young woman is standing in the GIF YOU aready to the latter, the latter and the a the better to the v: a the latter, only other. The '?seem to the more\n",
      "\n",
      "The woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\n",
      "â±ï¸ Time taken: 8.503 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: You are a museum docent giving a tour. Describe th...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: You are a museum docent giving a tour. Describe the activity of the woman in the context of the art gallery.\n",
      "ğŸ“¤ Output:\n",
      "As a woman in the art gallery, a young woman is standing in the GIF YOU aready to the latter, the latter and the a the better to the v: a the latter, only other. The '?seem to the more\n",
      "\n",
      "The woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\n",
      "â±ï¸ Time taken: 7.98 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: A <text_1> is painting a replica of an artwork in ...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is painting a replica of an artwork in front of <text_2>.\n",
      "ğŸ“¤ Output:\n",
      "A framed art[text_1[an_text:for a specific part attt:b: ament_that: a: anthisis more: a: an: athat: a: a: a: nn: a: a: a: nthat_an: a: a: nthat: a: n: a: n: a: n: a: n: a: n: a: n: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s\n",
      "â±ï¸ Time taken: 8.106 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: A <text_1> is painting a replica of an artwork in ...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: A <text_1> is painting a replica of an artwork in front of <text_2>.\n",
      "ğŸ“¤ Output:\n",
      "A framed art[text_1[an_text:for a specific part attt:b: ament_that: a: anthisis more: a: an: athat: a: a: a: nn: a: a: a: nthat_an: a: a: nthat: a: n: a: n: a: n: a: n: a: n: a: n: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s: a: s\n",
      "â±ï¸ Time taken: 7.712 sec | ğŸ§  VRAM used: 0.257 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 1 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      " terc?Subject: Museum Visit\n",
      "- Art Museum\n",
      "- Indoors\n",
      "- The person is indoors, inside a museum, admiring famous paintings\n",
      "\n",
      "Additional Notes: The person is holding a clipboard and examining the artwork closely, examining a painting in a museum, The person is in a museum, observing art, observing a painting in a gallery, the person is in an art museum, looking at a painting in a gallery, the person is in a museum, viewing art, the person is in an art gallery, gazing at a painting, the person is in a national museum, viewing art, the person is in an art\n",
      "â±ï¸ Time taken: 7.828 sec | ğŸ§  VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ” Run 2 for prompt: Describe using format - Subject:  \\_\\_\\_; Activity...\n",
      "ğŸ”¹ Image: 18284727.jpg\n",
      "ğŸ§¾ Prompt: Describe using format - Subject:  \\_\\_\\_; Activity:  \\_\\_\\_; Environment:  \\_\\_\\_; Additional Notes: \\_\\_\\_;\n",
      "ğŸ“¤ Output:\n",
      "***\n",
      " terc?Subject: Museum Visit\n",
      "- Art Museum\n",
      "- Indoors\n",
      "- The person is indoors, inside a museum, admiring famous paintings\n",
      "\n",
      "Additional Notes: The person is holding a clipboard and examining the artwork closely, examining a painting in a museum, The person is in a museum, observing art, observing a painting in a gallery, the person is in an art museum, looking at a painting in a gallery, the person is in a museum, viewing art, the person is in an art gallery, gazing at a painting, the person is in a national museum, viewing art, the person is in an art\n",
      "â±ï¸ Time taken: 7.2 sec | ğŸ§  VRAM used: 0.259 GB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_img_ids = [2500, 2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509]\n",
    "df = test_dataset.to_pandas()\n",
    "\n",
    "all_outputs = {}\n",
    "all_times = {}\n",
    "all_vram = {}\n",
    "\n",
    "# Loop through each image and its corresponding prompt set\n",
    "for i, img_id in enumerate(test_img_ids):\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(row) == 0:\n",
    "        print(f\"[WARNING] No image found with img_id {img_id}\")\n",
    "        continue\n",
    "\n",
    "    filename = row[0][\"filename\"]\n",
    "    prompts = PROMPT_LIST[i]\n",
    "\n",
    "    print(f\"\\nğŸ” Running prompts for image: {filename} (img_id: {img_id})\\n\" + \"-\"*60)\n",
    "\n",
    "    inference_outputs = []\n",
    "    inference_times = []\n",
    "    vram_usages = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        # Run the same prompt twice for the same image\n",
    "        for run in range(2):\n",
    "            print(f\"ğŸ” Run {run+1} for prompt: {prompt[:50]}{'...' if len(prompt) > 50 else ''}\")\n",
    "            output, time_taken, vram_used = run_vlm_inference(prompt, filename, df=df)\n",
    "            inference_outputs.append(output)\n",
    "            inference_times.append(time_taken)\n",
    "            vram_usages.append(vram_used)\n",
    "\n",
    "    # Save to overall dicts\n",
    "    all_outputs[img_id] = inference_outputs\n",
    "    all_times[img_id] = inference_times\n",
    "    all_vram[img_id] = vram_usages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70751f0-0a79-4b4a-88cd-9a9592bcc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_id in all_outputs:\n",
    "    print(f\"\\nğŸ–¼ï¸ Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (output, time_taken, vram_used) in enumerate(zip(all_outputs[img_id], all_times[img_id], all_vram[img_id])):\n",
    "        print(f\"ğŸ”¹ Prompt {i+1}\")\n",
    "        print(f\"ğŸ“ Output: {output}\")\n",
    "        print(f\"â±ï¸ Inference Time: {time_taken:.3f} sec\")\n",
    "        print(f\"ğŸ’¾ VRAM Used: {vram_used:.3f} GB\")\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e99ac1-5afc-474d-8471-8351b77b5df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f101e498-ff73-4b37-8284-dd304e242d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(reference_captions, generated_caption):\n",
    "    try:\n",
    "        total_score = 0.0\n",
    "        for caption in reference_captions:\n",
    "            ref_embed = sbert_model.encode(caption, convert_to_tensor=True)\n",
    "            gen_embed = sbert_model.encode(generated_caption, convert_to_tensor=True)\n",
    "            score = util.cos_sim(gen_embed, ref_embed).item()\n",
    "            total_score += score\n",
    "        avg_score = total_score / len(reference_captions) if reference_captions else 0.0\n",
    "        return avg_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing cosine similarity: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba995d08-78cc-482d-9b09-55188cae7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cider_spice_scores(reference_caption, generated_caption):\n",
    "    refs = {0: [reference_caption if reference_caption else \"\"]}\n",
    "    hypos = {0: [generated_caption if generated_caption else \"\"]}\n",
    "\n",
    "    # print(f\"Generated caption: {generated_caption}\")\n",
    "    # print(f\"Generated hypos: {hypos}\")\n",
    "\n",
    "    ptb = PTBTokenizer()\n",
    "    refs_tok = ptb.tokenize({i: [{\"caption\": c} for c in caps] for i, caps in refs.items()})\n",
    "    hypos_tok = ptb.tokenize({i: [{\"caption\": hypos[i][0]}] for i in hypos})\n",
    "\n",
    "    all_scores = {}\n",
    "\n",
    "    for scorer, name in [(Cider(), \"CIDEr\"), (Spice(), \"SPICE\")]:\n",
    "        try:\n",
    "            avg_score, _ = scorer.compute_score(refs_tok, hypos_tok)\n",
    "            if name == \"SPICE\":\n",
    "                # SPICE returns dicts per image\n",
    "                all_scores[name] = avg_score.get(\"All\", {}).get(\"f\", 0.0) if isinstance(avg_score, dict) else avg_score\n",
    "            else:\n",
    "                all_scores[name] = avg_score\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {name} scoring failed: {e}\")\n",
    "            all_scores[name] = 0.0\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23226fc-b171-4e37-b25d-225f6b6c09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cider import Cider\n",
    "\n",
    "PICKLE_PATH = \"/workspace/data/flickr-df.p\"\n",
    "\n",
    "def compute_cider2_score(reference_caption, generated_caption):\n",
    "    refs = {\"0\": reference_caption if isinstance(reference_caption, list) else [reference_caption]}\n",
    "    hypos = [{\"image_id\": \"0\", \"caption\": [generated_caption]}]  # Fix: caption should be a list\n",
    "\n",
    "    cider = Cider()\n",
    "    score, _ = cider.compute_score(refs, hypos, PICKLE_PATH)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7410ff99-e2d4-47e5-aede-1ffb4dc1778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_metrics(reference_caption, generated_caption):\n",
    "    cider_spice_scores = compute_cider_spice_scores(reference_caption, generated_caption)\n",
    "    cosine_sim = compute_cosine_similarity([reference_caption], generated_caption)\n",
    "    cider2 = compute_cider2_score(reference_caption, generated_caption)\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        #\"CIDEr\": round(cider_spice_scores.get(\"CIDEr\", 0.0), 4),\n",
    "        \"SPICE\": round(cider_spice_scores.get(\"SPICE\", 0.0), 4),\n",
    "        \"CIDEr\": round(cider2, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39061635-41c6-4673-8a5e-d32018ba2ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Evaluating image ID: 2500 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 133.93 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 523.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.581 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.148 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.538 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 303.68 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 422.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [0.404 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.983 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 277.90 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 536.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.376 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.361 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 321.60 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 334.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.373 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.287 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 170.64 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 472.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.320 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.064 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.7928 | SPICE: 0.0174 | CosSim: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 375.73 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 496.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 339.64 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 409.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 309.61 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 531.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 327.18 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 399.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 232.48 tokens per second.\n",
      "PTBTokenizer tokenized 20 tokens at 517.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.4 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.7928 | SPICE: 0.0174 | CosSim: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 458.06 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1845.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [2.242 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.348 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 319.22 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1628.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 284.50 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1798.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 799.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 280.18 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1860.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 793.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 234.69 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1509.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 686.2 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.9964 | SPICE: 0.056 | CosSim: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 452.49 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1836.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 710.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 333.35 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1710.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 755.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 254.81 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1613.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 805.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 327.04 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1799.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 767.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 203.54 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1411.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 780.2 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.9964 | SPICE: 0.056 | CosSim: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 435.56 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 858.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.924 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.912 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 327.99 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 891.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 826.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 252.19 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 725.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 302.02 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 905.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 231.38 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 879.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.9 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.6717 | SPICE: 0.0752 | CosSim: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 435.61 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 660.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 775.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 334.79 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 708.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 775.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 269.39 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 585.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 261.75 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 1018.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 596.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 262.93 tokens per second.\n",
      "PTBTokenizer tokenized 35 tokens at 800.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 739.0 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.6717 | SPICE: 0.0752 | CosSim: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 407.66 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3873.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.607 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 244.10 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3010.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.522 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 302.81 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3672.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.303 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 292.08 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2588.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.172 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 234.24 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3137.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.720 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.50 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.6765 | SPICE: 0.0234 | CosSim: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 500.02 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3175.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.17 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.90 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 317.94 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3094.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.941 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 232.00 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2367.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.584 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 306.19 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2312.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.267 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 237.58 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2774.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.384 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a nature trail guide describe what 's happening in this scene to someone preparing for their first family hike.as you embark on your family hike you 'll be greeted by a serene woodland trail winding through a canopy of mature oaks and verdant undergrowth the path 's wide and well-trod with only gentle slopes and informative markers to guide you as you tread you 'll notice how the dappled light filters through the leaves dotting the woodland floor with gold the air 'll be redolent with loam and chlorophyll a earthy and green you 'll hear the rustle of leaves the trill of birds and mayhap the faintest whisper of a brook ahead\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.90 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.6765 | SPICE: 0.0234 | CosSim: 0.2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 483.50 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3450.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.305 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 328.05 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2584.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 664.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 315.11 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3313.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 324.18 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2589.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 709.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 189.92 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3213.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.8 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.793 | SPICE: 0.0129 | CosSim: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 452.18 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3413.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 294.25 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3285.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.36 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 3347.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 690.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 261.10 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2885.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 823.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 155.48 tokens per second.\n",
      "PTBTokenizer tokenized 132 tokens at 2893.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.7 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.793 | SPICE: 0.0129 | CosSim: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 400.43 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3047.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [11.925 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 310.81 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3776.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [12.236 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 298.78 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3762.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [11.936 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.74 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 319.82 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3815.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [12.687 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 195.14 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 2954.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [14.12 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.14 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.9609 | SPICE: 0.0851 | CosSim: 0.3421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 469.65 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3598.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.77 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.70 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 343.58 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 4149.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.270 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.66 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 307.64 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3833.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [11.930 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.79 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 338.23 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3537.13 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [13.713 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 237.56 tokens per second.\n",
      "PTBTokenizer tokenized 157 tokens at 3765.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.825 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** people hiking terc ** activity ** hiking ** environment ** forest ** additional notes ** a group of hikers including children are seen hiking on a dirt path in a forested area the hikers are equipped with backpacks and are walking along a designated trail ** subject ** mountain bikers ** activity ** mountain biking ** environment ** mountain trail ** additional notes ** mountain bikers are seen riding on a trail in a forested area the bikers are equipped with helmets and are riding along a designated trail ** subject ** runners ** activity ** running\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.69 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.9609 | SPICE: 0.0851 | CosSim: 0.3421\n",
      "\n",
      "ğŸ” Evaluating image ID: 2501 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 764.16 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1960.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.968 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.410 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.315 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 437.05 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1813.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.461 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.374 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 274.20 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1951.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.391 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.300 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 255.25 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1765.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.321 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.132 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 153.51 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1919.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.308 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.138 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.6351 | SPICE: 0.0 | CosSim: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 752.00 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1580.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 789.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 443.94 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1921.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 279.96 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1907.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 305.74 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1861.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 120.03 tokens per second.\n",
      "PTBTokenizer tokenized 76 tokens at 1772.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 695.7 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.6351 | SPICE: 0.0 | CosSim: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 752.00 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 668.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.781 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.644 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 462.04 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 567.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 681.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 256.13 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 704.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 664.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 310.36 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 618.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 673.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 183.27 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 710.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.1 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.9186 | SPICE: 0.1083 | CosSim: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 731.95 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 683.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 712.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 437.95 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 701.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 234.33 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 629.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 322.43 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 654.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 182.71 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 676.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 699.5 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.9186 | SPICE: 0.1083 | CosSim: 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 797.20 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 541.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.563 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.357 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 390.64 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 444.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 218.96 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 473.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 769.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 226.94 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 501.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 654.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 148.50 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 503.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 829.6 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 1.2387 | SPICE: 0.1145 | CosSim: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 701.83 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 510.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 748.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 392.29 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 625.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 270.52 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 639.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 273.30 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 619.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 188.01 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 564.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.8 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 1.2387 | SPICE: 0.1145 | CosSim: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 723.35 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3278.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.241 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.08 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 413.52 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2938.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.411 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 348.32 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2570.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.871 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 308.50 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3064.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.536 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 143.97 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2838.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.355 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.13 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 1.0566 | SPICE: 0.074 | CosSim: 0.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 658.19 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2647.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.710 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 459.76 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3023.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.157 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 292.41 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3685.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.427 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.67 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3170.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.966 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.60 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 166.52 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3710.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.856 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a food critic observing customer service at cafes describe the interaction happening in this scene.in the 1 the image depicts a playful and humorous scene where a young woman in a novelty t-shirt that reads cafe and a man wearing a bandana and a rubber duck impression of a mustache they are playfully ham it a game with a rubber in his a bib which is emblazoned in a rubber of a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is emblazoned in a bib which is embl\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.77 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 1.0566 | SPICE: 0.074 | CosSim: 0.2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 634.20 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2716.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [6.124 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 478.75 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2746.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 744.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 274.37 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2647.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 644.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 290.51 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2508.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 159.96 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2687.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.3 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.7503 | SPICE: 0.0 | CosSim: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 696.58 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2389.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 391.40 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2118.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 274.61 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2772.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 285.90 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2743.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 165.48 tokens per second.\n",
      "PTBTokenizer tokenized 108 tokens at 2705.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 731.0 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.7503 | SPICE: 0.0 | CosSim: 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 629.52 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3386.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.871 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.51 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 384.04 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3737.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.912 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 226.45 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3478.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [13.581 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 262.90 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3823.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [13.395 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 155.70 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3698.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.705 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.57 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.6219 | SPICE: 0.0 | CosSim: 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 30 tokens at 784.88 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 4115.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.782 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 429.69 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 2960.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.416 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.10 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 254.02 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3648.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.309 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 273.07 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3725.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.386 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 158.31 tokens per second.\n",
      "PTBTokenizer tokenized 162 tokens at 3498.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [13.734 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** two people a boy and a girl tercena ** activity ** the boy is kissing the girl on the cheek ** environment ** a crowded public place maybe a mall ** additional notes unterschied between their ages casual clothing public display of affection it seems there is a significant difference in the ages of the two as indicated by the difference in their physical appearances additionally their casual clothing styles also reflect this age difference the bold display of affection kissing on the cheek in a public place may also suggest a difference in their comfort levels with public displays of affection\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.16 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.6219 | SPICE: 0.0 | CosSim: 0.1259\n",
      "\n",
      "ğŸ” Evaluating image ID: 2502 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 706.43 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1849.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.737 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.321 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 555.69 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1114.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.750 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.327 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 174.11 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1565.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.323 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.689 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 236.66 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1843.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.344 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.761 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 125.83 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1205.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.282 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.530 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.6511 | SPICE: 0.0571 | CosSim: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 620.80 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1701.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 768.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 649.66 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1711.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 211.10 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1902.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 777.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 234.21 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1833.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 686.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 183.69 tokens per second.\n",
      "PTBTokenizer tokenized 73 tokens at 1776.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 720.2 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.6511 | SPICE: 0.0571 | CosSim: 0.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 517.62 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 597.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.673 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.430 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 619.26 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 543.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 189.88 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 475.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 169.32 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 602.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 763.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 128.18 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 612.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.2 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.6971 | SPICE: 0.1101 | CosSim: 0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 629.42 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 584.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 551.42 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 588.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 693.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 193.38 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 608.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 210.23 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 621.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 175.04 tokens per second.\n",
      "PTBTokenizer tokenized 24 tokens at 676.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.4 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.6971 | SPICE: 0.1101 | CosSim: 0.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 705.54 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 886.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.933 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.578 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 508.21 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 758.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 757.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 207.07 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 880.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 865.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 191.38 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 633.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 911.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 131.75 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 696.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 845.3 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.4401 | SPICE: 0.0285 | CosSim: 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 629.37 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 770.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 878.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 501.51 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 771.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 863.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 142.57 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 785.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 857.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 194.03 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 796.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 883.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 118.88 tokens per second.\n",
      "PTBTokenizer tokenized 36 tokens at 765.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 846.7 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.4401 | SPICE: 0.0285 | CosSim: 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 598.13 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2316.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.879 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 548.21 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3046.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.359 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 188.60 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2959.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.964 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.35 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 190.47 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3015.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.361 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 118.64 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2195.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.713 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.71 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.5846 | SPICE: 0.0223 | CosSim: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 601.22 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3010.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [13.85 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 644.81 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2975.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [12.354 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.88 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 201.01 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3166.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.584 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 233.75 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 3047.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.864 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 159.79 tokens per second.\n",
      "PTBTokenizer tokenized 125 tokens at 2778.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.826 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a weather reporter documenting children 's routines during rainy mornings describe what 's going on in this image.in the midst of a lush verdant garden two young adventurers each equipped with vibrant backpacks and umbreitas they embark on an expedition the first adventurer garbed in a blue raincoat and matching hat toting a brilliant yellow parasol strides forward a blue backpack strapped securely to their back parallel to them the second adventurer cloaked in a red raincoat and matching hat bears aloft a matching red parasol a green backpack riding high on their shoulders their path a winding trail of pebbles meanders through the garden\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.78 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.5846 | SPICE: 0.0223 | CosSim: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 648.98 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1857.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.571 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.376 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 644.50 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1500.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 842.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 166.94 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1460.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 773.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 216.63 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1879.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 773.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 171.36 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1846.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 727.5 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.887 | SPICE: 0.0912 | CosSim: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 610.21 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1769.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 795.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 622.19 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1858.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 774.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 172.30 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1562.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 812.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 223.87 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1666.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 756.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 158.87 tokens per second.\n",
      "PTBTokenizer tokenized 75 tokens at 1635.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 810.2 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.887 | SPICE: 0.0912 | CosSim: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 710.70 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3121.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.816 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 682.50 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3044.06 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.631 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 176.90 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2683.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.384 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 221.81 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2219.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [8.760 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.73 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 148.77 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2896.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.327 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.15 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.3938 | SPICE: 0.0345 | CosSim: 0.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 28 tokens at 702.67 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2812.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.379 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 666.65 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3088.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.334 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 8 tokens at 201.14 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3460.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.940 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 233.33 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 2664.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.857 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.80 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 186.32 tokens per second.\n",
      "PTBTokenizer tokenized 126 tokens at 3056.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.246 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject children playing with umbrea and backpacks ** activity children playing with toy umbrellas and toy cameras ** environment garden path with flowers and puddles ** additional notes the children are enjoying themselves jumping in puddles with their toy umbrellas and cameras they are having a great time outdoors in the garden exploring and playing with their toys the garden is beautiful with flowers and a path for the children to jump in the puddles\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.95 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.3938 | SPICE: 0.0345 | CosSim: 0.2545\n",
      "\n",
      "ğŸ” Evaluating image ID: 2503 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 459.13 tokens per second.\n",
      "May 25, 2025 7:58:41 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1024.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.472 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.154 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.945 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 297.12 tokens per second.\n",
      "May 25, 2025 7:58:50 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 995.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.360 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.234 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 277.12 tokens per second.\n",
      "May 25, 2025 7:58:57 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 890.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.394 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.093 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 238.09 tokens per second.\n",
      "May 25, 2025 7:59:05 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 1042.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.350 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.554 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 237.19 tokens per second.\n",
      "May 25, 2025 7:59:12 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 951.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.401 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.122 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.6975 | SPICE: 0.0 | CosSim: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 353.69 tokens per second.\n",
      "May 25, 2025 7:59:20 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 883.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 848.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 314.60 tokens per second.\n",
      "May 25, 2025 7:59:21 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 738.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 871.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 237.01 tokens per second.\n",
      "May 25, 2025 7:59:23 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 849.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 231.52 tokens per second.\n",
      "May 25, 2025 7:59:24 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 827.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 927.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 215.12 tokens per second.\n",
      "May 25, 2025 7:59:26 AM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: ï¿½ (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 55 tokens at 897.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 825.9 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.6975 | SPICE: 0.0 | CosSim: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 385.41 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 713.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.944 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.149 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 259.24 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 882.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 818.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 305.30 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 910.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 184.88 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 864.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 752.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 279.83 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 822.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.1 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.6003 | SPICE: 0.0129 | CosSim: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 441.97 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 745.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 731.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 291.96 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 933.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 747.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 257.15 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 808.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 808.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 204.41 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 743.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 885.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 278.30 tokens per second.\n",
      "PTBTokenizer tokenized 38 tokens at 960.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.0 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.6003 | SPICE: 0.0129 | CosSim: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 453.90 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2707.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.109 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 289.85 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2568.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 886.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 237.83 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2290.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 936.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 206.00 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2383.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 805.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 221.86 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2426.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 886.9 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.9224 | SPICE: 0.0411 | CosSim: 0.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 335.47 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2175.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 856.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 254.91 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2106.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 851.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 224.26 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2333.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 917.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 187.00 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 1668.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 855.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 247.55 tokens per second.\n",
      "PTBTokenizer tokenized 109 tokens at 2396.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 846.4 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.9224 | SPICE: 0.0411 | CosSim: 0.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 386.84 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2358.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.766 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 283.79 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2565.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [4.384 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 243.37 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2766.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.10 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.946 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 259.30 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2840.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [3.838 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.243 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 252.89 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2218.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [4.100 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.792 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.9649 | SPICE: 0.0489 | CosSim: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 311.37 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2422.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.345 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 317.32 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2626.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [4.4 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.914 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 314.11 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2644.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [4.261 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.975 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 190.21 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 1953.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.960 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.826 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 201.61 tokens per second.\n",
      "PTBTokenizer tokenized 110 tokens at 2854.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.885 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a journalist covering a small-town parade describe the role and setting of the clown in this festive scene.in the scene aicularly clown costume a colorful the festive atmosphere of the festivities a part of a clown 's a colorful costume the merrifai ?? -lsb- ^ mischar with a festive the is a clown 's a festive atmosphere the mwith a festive the merringly with a festive the merringly ___ a the migh with a the merringly a festive the charm of a festive the charmingly a festive the charmingly a festive the charmingly a the charmingly a festive the charmingly a the charm\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.884 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.9649 | SPICE: 0.0489 | CosSim: 0.4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 450.72 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 836.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.122 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.571 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 269.27 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 875.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 846.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 264.12 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 912.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 212.38 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 803.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 836.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 238.41 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 820.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 878.9 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.8414 | SPICE: 0.041 | CosSim: 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 388.57 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 772.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 850.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 218.61 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 801.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 772.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 229.24 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 810.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 812.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 210.66 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 916.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 778.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 284.12 tokens per second.\n",
      "PTBTokenizer tokenized 37 tokens at 774.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 791.0 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.8414 | SPICE: 0.041 | CosSim: 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 395.13 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3592.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [15.80 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 294.36 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3268.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.777 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 205.87 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2223.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [16.161 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 22.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 215.19 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2568.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [15.898 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 21.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 238.19 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2767.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [16.270 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 22.39 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.5831 | SPICE: 0.0363 | CosSim: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 489.42 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3416.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [14.553 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 235.65 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 2376.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [15.484 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 21.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 242.72 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3369.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [15.921 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 21.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 219.57 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3734.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [15.109 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 20.89 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 210.89 tokens per second.\n",
      "PTBTokenizer tokenized 140 tokens at 3571.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [14.771 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc performing as a clown at a. performing as a. brightly lit festive and colorful costume with exaggerated makeup and a festive small town festive with a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a festive carnival worker in a fest\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.99 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.5831 | SPICE: 0.0363 | CosSim: 0.359\n",
      "\n",
      "ğŸ” Evaluating image ID: 2504 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 389.39 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1187.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.388 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.842 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.054 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 219.27 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1191.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.371 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.377 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 341.76 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1015.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.367 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.229 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 249.68 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1141.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.295 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 5.819 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 174.44 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1097.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.238 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.193 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.5696 | SPICE: 0.0 | CosSim: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 372.39 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1155.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 701.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.86 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1174.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 352.33 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 976.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 233.22 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1163.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 671.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 170.62 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1186.24 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 793.1 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.5696 | SPICE: 0.0 | CosSim: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 300.74 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 568.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.704 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.636 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 245.68 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 539.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 339.06 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 564.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 732.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 219.74 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 421.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 185.35 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 536.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.7 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.4388 | SPICE: 0.0623 | CosSim: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 386.04 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 428.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 316.53 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 520.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 744.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 321.06 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 510.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 250.14 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 538.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 751.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 171.46 tokens per second.\n",
      "PTBTokenizer tokenized 21 tokens at 573.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.8 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.4388 | SPICE: 0.0623 | CosSim: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 396.01 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 316.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.390 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.235 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 294.97 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 328.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 296.56 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 318.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 205.34 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 335.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 162.88 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 253.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.2 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.0445 | SPICE: 0.0 | CosSim: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 393.20 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 329.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 720.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 249.57 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 317.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 329.57 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 328.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 236.45 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 312.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 666.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 175.80 tokens per second.\n",
      "PTBTokenizer tokenized 13 tokens at 266.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.2 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.0445 | SPICE: 0.0 | CosSim: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 374.76 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3488.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.963 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 304.76 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3396.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.889 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 303.27 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3283.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.399 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.10 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 264.94 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3521.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.693 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 184.46 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3782.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.645 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.87 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.3567 | SPICE: 0.0 | CosSim: 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 313.31 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3407.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.815 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 327.08 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3537.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [11.612 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 270.49 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3231.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.457 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 261.41 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3462.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.228 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.88 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 162.52 tokens per second.\n",
      "PTBTokenizer tokenized 134 tokens at 3434.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.257 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a winter sports photographer recounting a joyful moment you captured describe the scene with vivid detail.in the heart of the majestic snow-capped peaks stretched out before us their triumphant poses their jubilant their jubilant anted in jubilant ant the sky their joyous ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant the sky ant\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.87 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.3567 | SPICE: 0.0 | CosSim: 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 367.26 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1519.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [2.634 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.407 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 316.28 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1625.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 325.07 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1447.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 763.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 243.95 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1159.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 774.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 147.41 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1142.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 742.0 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.9874 | SPICE: 0.0861 | CosSim: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 371.94 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1543.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 720.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 275.31 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1343.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 354.73 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1548.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 770.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 267.50 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1104.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 155.98 tokens per second.\n",
      "PTBTokenizer tokenized 61 tokens at 1508.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.7 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.9874 | SPICE: 0.0861 | CosSim: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 402.94 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1881.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [3.92 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.749 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 276.91 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1343.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 957.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 269.78 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1290.26 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 794.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 192.13 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1140.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 908.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 143.94 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1611.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 811.1 ms\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.5625 | SPICE: 0.0757 | CosSim: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 318.37 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1809.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 784.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 244.17 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1628.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 13 tokens at 343.46 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1776.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 250.77 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1469.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7 tokens at 188.93 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1524.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.7 ms\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.5625 | SPICE: 0.0757 | CosSim: 0.181\n",
      "\n",
      "ğŸ” Evaluating image ID: 2505 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 550.85 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 677.45 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.821 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.243 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.838 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 483.68 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 761.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.516 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.333 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 320.08 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 626.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.557 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.463 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 323.12 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 468.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.385 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.682 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 255.52 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 571.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.350 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.263 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.2962 | SPICE: 0.0707 | CosSim: 0.3579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 702.25 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 636.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 372.61 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 673.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 669.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 315.19 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 681.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 363.85 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 666.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 257.93 tokens per second.\n",
      "PTBTokenizer tokenized 25 tokens at 568.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.9 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.2962 | SPICE: 0.0707 | CosSim: 0.3579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 685.08 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 533.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.494 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.530 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 393.78 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 583.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 783.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 322.31 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 492.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 916.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 304.38 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 504.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 868.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 169.69 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 465.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 892.8 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.3344 | SPICE: 0.0348 | CosSim: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 572.47 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 257.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 864.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 360.81 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 446.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 916.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 207.28 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 390.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 866.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 264.58 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 465.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 937.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 218.14 tokens per second.\n",
      "PTBTokenizer tokenized 23 tokens at 395.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 852.1 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.3344 | SPICE: 0.0348 | CosSim: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 583.45 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 475.25 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [0.503 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.448 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 488.65 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 434.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 371.88 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 522.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 753.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 267.89 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 474.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 689.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 163.88 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 552.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 776.4 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.3534 | SPICE: 0.047 | CosSim: 0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 592.08 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 545.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 870.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 389.07 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 539.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 385.87 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 555.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 283.60 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 579.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 729.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 280.30 tokens per second.\n",
      "PTBTokenizer tokenized 22 tokens at 484.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 798.3 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.3534 | SPICE: 0.047 | CosSim: 0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 555.43 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3243.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [8.377 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.58 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 471.66 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2470.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.96 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 331.20 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3292.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.814 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 321.10 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2864.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [8.528 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 243.72 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 2385.72 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [9.282 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.55 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.6058 | SPICE: 0.0149 | CosSim: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 567.42 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3394.46 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.442 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 468.04 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3326.66 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.545 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 334.28 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3385.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.397 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.11 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 291.38 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3367.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [7.901 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 256.18 tokens per second.\n",
      "PTBTokenizer tokenized 130 tokens at 3013.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.205 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a market researcher documenting traditional grocery stores describe what the boy is doing and what the store looks like.the scene depicts a bustling well-stocked traditional grocery store bustling with a variety of products the store is characterized by its rustic charm with wooden shelves stacked high with an assortment of canned goods jars and other staples the store 's interior is warmly illuminated by flickering light bulbs casting a cozy glow over the scene in the midst of the store a boy is engrossed in his task meticulously scooping cereal from a large bin into a bag his focus is unwavering a testament to his dedication to his duty the store 's atmosphere is\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.79 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.6058 | SPICE: 0.0149 | CosSim: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 566.58 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 955.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [1.311 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.048 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 419.10 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1309.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 341.74 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1289.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 367.70 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1344.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 271.86 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1331.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.9 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.9624 | SPICE: 0.0745 | CosSim: 0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 708.94 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1274.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 400.42 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1281.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 399.43 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1257.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 662.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 325.47 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1313.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 267.39 tokens per second.\n",
      "PTBTokenizer tokenized 50 tokens at 1325.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 716.0 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.9624 | SPICE: 0.0745 | CosSim: 0.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 700.71 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3562.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.871 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 470.03 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3585.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.67 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.92 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 391.66 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3352.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.190 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.93 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 357.83 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3059.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [12.853 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 220.70 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3336.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.776 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.75 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.5758 | SPICE: 0.0421 | CosSim: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 767.47 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3287.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.810 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 365.81 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3432.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.892 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 15 tokens at 416.70 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3465.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.958 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 307.52 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3277.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [13.710 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 10 tokens at 171.03 tokens per second.\n",
      "PTBTokenizer tokenized 133 tokens at 3068.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.974 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** image of a large store with vast assortment of goods tercet ** activity ** shoppers browsing and selecting items ** environment ** busy indoor store with wide aisles of products ** additional notes ** the store specializes in a huge selection of candies and snacks with numerous bins of bulk candy and shelves of packaged goods the store appears well-stocked and well-lit with a classic retro feel there are signs in multiple languages indicating a diverse customer base\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.95 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.5758 | SPICE: 0.0421 | CosSim: 0.2835\n",
      "\n",
      "ğŸ” Evaluating image ID: 2506 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 798.68 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1726.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [1.96 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.727 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 635.60 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1902.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.721 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.153 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 691.83 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1885.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.777 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.656 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 399.15 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1748.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.586 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.266 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 340.70 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1815.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.371 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.096 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.7752 | SPICE: 0.0224 | CosSim: 0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 810.41 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1819.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 583.14 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1807.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 766.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 552.59 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1924.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 682.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 447.41 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1805.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 357.68 tokens per second.\n",
      "PTBTokenizer tokenized 72 tokens at 1879.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 744.7 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.7752 | SPICE: 0.0224 | CosSim: 0.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 798.55 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 627.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.721 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.155 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 610.18 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 572.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 673.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 631.38 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 452.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 781.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 448.48 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 603.97 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 726.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 361.82 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 597.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 679.9 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.7273 | SPICE: 0.0634 | CosSim: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 724.11 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 552.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 637.94 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 734.70 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 705.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 465.01 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 649.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 796.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 381.57 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 732.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 315.89 tokens per second.\n",
      "PTBTokenizer tokenized 28 tokens at 603.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 721.1 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.7273 | SPICE: 0.0634 | CosSim: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 659.17 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1148.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "Threads( StanfordCoreNLP ) [2.24 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.249 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 532.44 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 994.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 856.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 462.07 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1230.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 803.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 456.26 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1291.08 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 745.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 318.83 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1287.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 863.6 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 1.0687 | SPICE: 0.1026 | CosSim: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 636.42 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1128.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 866.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 450.31 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1235.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 897.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 418.54 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 978.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 819.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 398.81 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1155.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 923.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 222.21 tokens per second.\n",
      "PTBTokenizer tokenized 55 tokens at 1214.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 847.2 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 1.0687 | SPICE: 0.1026 | CosSim: 0.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 825.59 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3445.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.467 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.35 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 637.44 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3520.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.832 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 589.68 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3387.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.284 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 388.09 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3282.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [10.51 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 365.40 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3474.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [9.798 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.20 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.7204 | SPICE: 0.0221 | CosSim: 0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 826.00 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3416.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.224 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 506.93 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2819.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.702 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.48 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 671.57 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3413.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.133 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 440.79 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3345.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.956 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.69 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 294.23 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3291.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.399 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are an it workplace culture analyst describe the work environment and team dynamic shown in this image.the work environment depicted in the image appears to portray a casual and informal office culture the central figure is seen working on a laptop while seated on an oversized unconventional office chair which resembles a giant hand suggesting a playful and relaxed atmosphere the walls are adorned with humorous and lighthearted posters reinforcing the informal vibe another individual is casually leaning against a wall dressed in casual attire further emphasizing the informal dress code the presence of various tech gadgets such as headphones and a laptop indicates a tech-savvy and modern workplace the overall scene suggests a dynamic and friendly team dynamic\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.18 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.7204 | SPICE: 0.0221 | CosSim: 0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 805.73 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3704.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [5.751 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 628.31 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2771.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.111 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.58 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 681.82 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3216.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.70 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 534.67 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3304.41 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [6.90 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 292.02 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2627.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.805 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.57 s\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 1.3744 | SPICE: 0.0749 | CosSim: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 784.41 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3014.98 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [5.944 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.43 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 592.41 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3268.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [5.687 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 691.35 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 2466.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [6.262 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.65 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 459.88 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3241.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [6.8 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 376.57 tokens per second.\n",
      "PTBTokenizer tokenized 127 tokens at 3407.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [5.971 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"a <text_1> is using a laptop at a desk while two <text_2> are in the background.sure here 's a detailed summary of the passage properly formatted and with the changes highlighted accordingly a <text_1> is using a laptop at a desk while two <text_2> are in the background please replace the following text with the highlighted text original text <text_1> is using a laptop at a desk while two <text_2> are in the background formatted and highlighted text a <text_1> is using a laptop at a desk while two <text_2> are in the background this revision ensures the text is properly formatted and the highlighted changes are incorporated\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.49 s\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 1.3744 | SPICE: 0.0749 | CosSim: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 873.90 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3689.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.189 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.44 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 593.38 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3127.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.611 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.50 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 580.42 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3392.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.609 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 446.37 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2602.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.447 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 350.39 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3465.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.227 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.96 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 1.0363 | SPICE: 0.074 | CosSim: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 31 tokens at 838.36 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3619.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [8.387 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.20 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 587.64 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3193.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [8.482 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 26 tokens at 599.21 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 1983.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [8.438 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 362.16 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 2934.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [8.98 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 286.24 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3548.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [8.492 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject man working on a laptop ** activity ** sitting at a desk using a laptop ** environment ** office setting with a desk chair and posters on the wall ** additional notes ** a man is intensely working on his laptop seemingly in a casual office environment with humorous posters on the wall including one depicting a character from a popular show another man is standing and observing the seated man adding a casual and relaxed atmosphere to the workspace\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.22 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 1.0363 | SPICE: 0.074 | CosSim: 0.4598\n",
      "\n",
      "ğŸ” Evaluating image ID: 2507 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 485.73 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 268.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.533 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 416.87 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 271.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.421 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.422 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 266.12 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 318.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.358 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.188 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 249.96 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 324.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.368 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.334 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 275.61 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 312.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.422 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.500 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.4385 | SPICE: 0.1547 | CosSim: 0.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 376.21 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 293.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 749.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 336.75 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 247.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 721.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 222.80 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 291.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 792.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 246.33 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 299.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 243.66 tokens per second.\n",
      "PTBTokenizer tokenized 12 tokens at 307.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 791.9 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.4385 | SPICE: 0.1547 | CosSim: 0.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 432.76 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1574.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [3.259 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 351.80 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1721.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 737.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 260.67 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1651.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 297.16 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1625.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 814.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 219.16 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1786.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 761.3 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 1.282 | SPICE: 0.0278 | CosSim: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 351.08 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1597.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 776.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 386.76 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1445.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 788.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 214.03 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1661.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 730.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 211.66 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1279.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 895.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 247.31 tokens per second.\n",
      "PTBTokenizer tokenized 71 tokens at 1148.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 836.4 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 1.282 | SPICE: 0.0278 | CosSim: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 426.30 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 259.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.317 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.274 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 329.54 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 262.57 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 719.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 271.97 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 203.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 748.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 306.59 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 242.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 790.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 290.18 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 180.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 733.4 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.0 | SPICE: 0.0 | CosSim: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 397.55 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 182.40 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 783.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 377.97 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 240.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 742.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 226.89 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 223.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 675.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 209.87 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 242.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 265.43 tokens per second.\n",
      "PTBTokenizer tokenized 10 tokens at 237.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 738.4 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.0 | SPICE: 0.0 | CosSim: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 438.67 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3678.93 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.598 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 356.70 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3214.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.720 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 272.18 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3776.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.526 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 317.49 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3941.63 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.537 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 287.76 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3650.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [11.104 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.46 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 1.3056 | SPICE: 0.0843 | CosSim: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 476.65 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3867.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.423 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 367.54 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3652.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.492 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 253.58 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 2320.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.751 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 276.14 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 2211.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.404 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 306.44 tokens per second.\n",
      "PTBTokenizer tokenized 148 tokens at 3747.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.91 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a canine trainer assessing a working dog 's field behavior describe the dog 's posture and role based on the scene the image depicts a small fluffy black and white dog wearing a reflective harness with an orange and green design on its back the harness has reflective strips and a handle on top for leading the dog is standing on patch of grass looking eagerly upward with an object in its mouth appears to be tug toy which is gripping in its jaws the dog 's ears are perked up and its eyes are wide open indicating excitement and focus the scene suggests playful outdoor activity such as a game of fetch or tug-of-war the harness and reflective strips on it suggest that the dog is well-equipped for\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.58 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 1.3056 | SPICE: 0.0843 | CosSim: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 275.09 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3491.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.424 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.30 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 280.24 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3506.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 694.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 289.34 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3589.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 759.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 288.33 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3764.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 295.53 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3506.12 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 735.7 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.5089 | SPICE: 0.01 | CosSim: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 447.84 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3413.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 373.49 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3530.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 754.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 280.85 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3111.90 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 627.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.45 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3021.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 704.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 242.87 tokens per second.\n",
      "PTBTokenizer tokenized 135 tokens at 3201.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 786.2 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.5089 | SPICE: 0.01 | CosSim: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 434.05 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3627.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.342 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 384.71 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3901.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.121 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.85 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 296.67 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3739.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [9.726 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 291.14 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3605.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [9.682 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 272.64 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3603.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.302 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.25 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.8496 | SPICE: 0.0649 | CosSim: 0.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 413.58 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3847.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.96 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 373.89 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3732.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.893 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 103.27 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3740.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.839 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 277.90 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 2711.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [9.658 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 11 tokens at 279.19 tokens per second.\n",
      "PTBTokenizer tokenized 150 tokens at 3704.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.14 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ ** subject ** dog playing with a toy terc ** activity ** tug of war ** environment ** park ** additional notes ** the dog appears to be a border terrier known for their tenacity and agility the toy is a large stick suitable for a strong play the harness the dog is wearing is brightly colored ensuring high visibility during outdoor activities the environment seems to be a natural open space ideal for play the dog 's focused and engaged in the play indicating enjoyment and stimulation\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.53 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.8496 | SPICE: 0.0649 | CosSim: 0.3912\n",
      "\n",
      "ğŸ” Evaluating image ID: 2508 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 724.40 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1517.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [0.904 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.977 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.512 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 611.93 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1409.86 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.797 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.990 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 361.49 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1282.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.571 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.552 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.79 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1434.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.340 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.281 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 184.25 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1346.87 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.311 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.224 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.728 | SPICE: 0.0129 | CosSim: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 684.28 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1578.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 725.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 419.87 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1555.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 785.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 298.41 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1316.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 624.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 263.84 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1514.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 225.91 tokens per second.\n",
      "PTBTokenizer tokenized 60 tokens at 1493.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 722.3 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.728 | SPICE: 0.0129 | CosSim: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 684.05 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2917.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [6.343 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 648.04 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2938.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 611.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 348.03 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 3171.32 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 684.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 362.30 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 3139.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 674.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 220.29 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2988.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 693.4 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.8132 | SPICE: 0.0 | CosSim: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 689.14 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2873.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 588.87 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2748.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 720.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 353.33 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 3217.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 698.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 307.51 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2931.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 706.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 202.63 tokens per second.\n",
      "PTBTokenizer tokenized 121 tokens at 2453.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 758.1 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.8132 | SPICE: 0.0 | CosSim: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 669.47 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2407.11 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [4.274 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 9.896 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 645.59 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2504.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 701.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 341.71 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2571.49 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 309.54 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2472.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 736.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 225.92 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2492.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 735.3 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.9657 | SPICE: 0.0438 | CosSim: 0.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 573.85 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2567.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 693.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 495.49 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2635.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 723.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 336.73 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2362.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 734.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 315.63 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2616.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 737.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 210.92 tokens per second.\n",
      "PTBTokenizer tokenized 100 tokens at 2657.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 727.0 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.9657 | SPICE: 0.0438 | CosSim: 0.3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 498.06 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 2838.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.404 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 461.03 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3456.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [7.247 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 13.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 295.85 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3358.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.202 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 311.40 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3399.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.959 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.70 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 241.75 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 2584.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [6.935 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.42 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.9762 | SPICE: 0.0354 | CosSim: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 640.77 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3568.31 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.191 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 642.54 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3331.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.96 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.90 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 371.20 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3705.83 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.622 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 313.44 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3646.18 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [7.34 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 171.08 tokens per second.\n",
      "PTBTokenizer tokenized 139 tokens at 3490.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [6.981 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a cultural anthropologist documenting traditional street labor describe what the person is doing and how they are carrying the items.in the image a person is depicted engaging in the traditional street labor specifically they are seen carrying a large bundle strapped to their back using a traditional shoulder pole a form of headwear known as a coolie hat is popular in many parts of a southeast asia the person is dressed in a light colored long-sleeved shirt light-colored pants with a distinctive pattern and flip-flops they are walking on a even paved surface adjacent to a plain light-colored wall the individual is transporting two large woven baskets one in each hand suspended from end of a long\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 12.62 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.9762 | SPICE: 0.0354 | CosSim: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 644.98 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3358.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [5.146 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.77 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 603.31 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3220.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 703.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 367.60 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2938.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 771.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 321.57 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3268.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 184.88 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 2568.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 702.4 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.6563 | SPICE: 0.0138 | CosSim: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 628.58 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3094.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 688.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 599.16 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3438.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 711.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 378.22 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3457.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 718.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 256.29 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3317.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 197.25 tokens per second.\n",
      "PTBTokenizer tokenized 129 tokens at 3152.01 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 724.6 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.6563 | SPICE: 0.0138 | CosSim: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 673.92 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 4187.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.538 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 633.41 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 4102.50 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [13.223 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 351.43 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3888.39 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.269 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 295.58 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3745.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [12.880 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 224.71 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3715.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.734 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.36 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 0.7389 | SPICE: 0.0269 | CosSim: 0.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 27 tokens at 729.75 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 4075.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [12.844 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 24 tokens at 627.42 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3943.29 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [12.756 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 350.37 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3899.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [12.766 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 18.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 329.51 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 4228.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [13.924 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 9 tokens at 234.97 tokens per second.\n",
      "PTBTokenizer tokenized 158 tokens at 3632.10 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [13.685 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** subject playful and whimsical playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny and bright with a plain white wall and ground backdrop ** additional notes ** the child seems to be enjoying the play wearing mismatched outfit with a conical hat and the scale is creatively used as a toy here are the details in the specified format ** subject ** playful playtime scene ** activity ** a child is playfully balancing a basket scale with a conical hat and bags ** environment ** a sunny\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 19.45 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 0.7389 | SPICE: 0.0269 | CosSim: 0.1443\n",
      "\n",
      "ğŸ” Evaluating image ID: 2509 | Ground truths: 5 captions\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 457.79 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1099.51 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.574 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.825 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.974 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 371.27 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1014.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.688 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.741 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 389.49 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1051.16 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.550 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.078 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 269.47 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1148.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.431 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.739 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 304.89 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1083.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [0.348 seconds]\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.121 s\n",
      "ğŸ“ Prompt Run 1 | CIDEr: 0.9716 | SPICE: 0.0758 | CosSim: 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 493.83 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1103.78 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 710.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 371.62 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1254.23 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 708.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 416.07 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1151.82 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 743.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 289.51 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1187.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 707.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 299.66 tokens per second.\n",
      "PTBTokenizer tokenized 47 tokens at 1100.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 729.7 ms\n",
      "ğŸ“ Prompt Run 2 | CIDEr: 0.9716 | SPICE: 0.0758 | CosSim: 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 372.45 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 549.54 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.3 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Threads( StanfordCoreNLP ) [0.795 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.223 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 317.40 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 549.77 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 896.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 326.76 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 613.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 717.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 342.40 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 527.59 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 894.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 252.69 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 556.85 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 832.2 ms\n",
      "ğŸ“ Prompt Run 3 | CIDEr: 0.5861 | SPICE: 0.0584 | CosSim: 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 390.51 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 502.81 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 829.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 368.89 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 513.89 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 855.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 354.13 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 523.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 874.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 287.95 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 538.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 938.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 260.40 tokens per second.\n",
      "PTBTokenizer tokenized 27 tokens at 522.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 864.1 ms\n",
      "ğŸ“ Prompt Run 4 | CIDEr: 0.5861 | SPICE: 0.0584 | CosSim: 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 422.73 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 351.56 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [0.472 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.365 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 437.78 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 394.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 662.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 453.85 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 438.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 697.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 333.41 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 367.00 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 764.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 266.10 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 358.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 676.2 ms\n",
      "ğŸ“ Prompt Run 5 | CIDEr: 0.43 | SPICE: 0.1521 | CosSim: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 465.30 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 343.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 700.0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 426.95 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 419.55 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 748.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 420.83 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 394.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 796.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 295.29 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 401.37 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 843.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 252.71 tokens per second.\n",
      "PTBTokenizer tokenized 16 tokens at 397.65 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 760.0 ms\n",
      "ğŸ“ Prompt Run 6 | CIDEr: 0.43 | SPICE: 0.1521 | CosSim: 0.2722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 404.90 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3480.07 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.991 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 478.86 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3731.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.6 sec].\n",
      "Threads( StanfordCoreNLP ) [10.384 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.87 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 456.17 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3867.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.869 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 367.73 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3827.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.367 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 325.28 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3802.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.578 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.15 s\n",
      "ğŸ“ Prompt Run 7 | CIDEr: 0.9649 | SPICE: 0.0406 | CosSim: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 505.61 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3738.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.10 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 438.46 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3095.61 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.829 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 379.60 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3819.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.253 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 362.97 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3085.67 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [11.46 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 239.61 tokens per second.\n",
      "PTBTokenizer tokenized 145 tokens at 3377.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [11.309 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"you are a museum docent giving a tour describe the activity of the woman in the context of the art gallery.as a woman in the art gallery a young woman is standing in the gif you aready to the latter the latter and the a the better to the v a the latter only other the seem to the more the woman is the in the and to the of a the large and the of the and is the in the of the and the of the and the and the and the and the and the and the and the and the and the of the my the and the of the and the of the and the of the more the of the more the and the and the and the and the of\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.26 s\n",
      "ğŸ“ Prompt Run 8 | CIDEr: 0.9649 | SPICE: 0.0406 | CosSim: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 496.74 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3198.69 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [4.972 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 10.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 374.36 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3017.22 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 687.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 431.55 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3482.62 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 713.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 355.10 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2765.33 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 696.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 318.63 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3390.84 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 685.9 ms\n",
      "ğŸ“ Prompt Run 9 | CIDEr: 0.2888 | SPICE: 0.0232 | CosSim: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 422.37 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3343.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 680.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 460.25 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3366.38 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 692.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 401.21 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3299.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 691.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 346.26 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 3502.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 714.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 300.61 tokens per second.\n",
      "PTBTokenizer tokenized 128 tokens at 2669.76 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 749.9 ms\n",
      "ğŸ“ Prompt Run 10 | CIDEr: 0.2888 | SPICE: 0.0232 | CosSim: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 462.95 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3962.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.611 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 429.92 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3686.48 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.4 sec].\n",
      "Threads( StanfordCoreNLP ) [10.124 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 14.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 388.54 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4278.74 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.7 sec].\n",
      "Threads( StanfordCoreNLP ) [10.307 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.82 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 352.56 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4160.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.969 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.35 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 340.67 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3266.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.659 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.87 s\n",
      "ğŸ“ Prompt Run 11 | CIDEr: 1.0206 | SPICE: 0.0389 | CosSim: 0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 19 tokens at 410.60 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3748.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.5 sec].\n",
      "Threads( StanfordCoreNLP ) [10.650 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 18 tokens at 453.54 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4493.30 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.197 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 15.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 17 tokens at 356.10 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4250.53 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.767 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 14 tokens at 286.84 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 3542.34 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.8 sec].\n",
      "Threads( StanfordCoreNLP ) [10.514 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 12 tokens at 327.69 tokens per second.\n",
      "PTBTokenizer tokenized 159 tokens at 4096.35 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] CIDEr scoring failed: Cider.compute_score() missing 1 required positional argument: 'pfile_path'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.9 sec].\n",
      "Threads( StanfordCoreNLP ) [10.647 seconds]\n",
      "Error: Could not cache item to /workspace/pycocoevalcap/spice/cache with key:\n",
      "\"describe using format subject \\ _ \\ _ \\ _ activity \\ _ \\ _ \\ _ environment \\ _ \\ _ \\ _ additional notes \\ _ \\ _ \\ _ *** terc?subject museum visit art museum indoors the person is indoors inside a museum admiring famous paintings additional notes the person is holding a clipboard and examining the artwork closely examining a painting in a museum the person is in a museum observing art observing a painting in a gallery the person is in an art museum looking at a painting in a gallery the person is in a museum viewing art the person is in an art gallery gazing at a painting the person is in a national museum viewing art the person is in an art\"\n",
      "Caption may be too long\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 16.32 s\n",
      "ğŸ“ Prompt Run 12 | CIDEr: 1.0206 | SPICE: 0.0389 | CosSim: 0.2195\n"
     ]
    }
   ],
   "source": [
    "all_metrics_scores = {}\n",
    "\n",
    "for img_id, outputs in all_outputs.items():\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(row) == 0:\n",
    "        print(f\"[WARNING] No ground truth found for img_id {img_id}\")\n",
    "        continue\n",
    "\n",
    "    ground_truths = row[0][\"caption\"]  # This is a list of 5 captions\n",
    "    print(f\"\\nğŸ” Evaluating image ID: {img_id} | Ground truths: {len(ground_truths)} captions\\n{'-'*80}\")\n",
    "    \n",
    "    scores_for_image = []\n",
    "\n",
    "    for idx, gen_output in enumerate(outputs):  # 12 outputs (6 prompts x 2 runs)\n",
    "        cider_total, spice_total, cos_total = 0.0, 0.0, 0.0\n",
    "\n",
    "        for ref in ground_truths:\n",
    "            metrics = evaluate_all_metrics(ref, gen_output)\n",
    "            cider_total += metrics[\"CIDEr\"]\n",
    "            spice_total += metrics[\"SPICE\"]\n",
    "            cos_total += metrics[\"cosine_similarity\"]\n",
    "\n",
    "        n_refs = len(ground_truths)\n",
    "        avg_metrics = {\n",
    "            \"CIDEr\": round(cider_total / n_refs, 4),\n",
    "            \"SPICE\": round(spice_total / n_refs, 4),\n",
    "            \"cosine_similarity\": round(cos_total / n_refs, 4)\n",
    "        }\n",
    "\n",
    "        print(f\"ğŸ“ Prompt Run {idx+1} | CIDEr: {avg_metrics['CIDEr']} | SPICE: {avg_metrics['SPICE']} | CosSim: {avg_metrics['cosine_similarity']}\")\n",
    "        scores_for_image.append(avg_metrics)\n",
    "\n",
    "    all_metrics_scores[img_id] = scores_for_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06bb9241-3a16-469b-849c-eb7d669d0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¸ Image ID: 2500\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.7928  0.0174             0.3718\n",
      "Prompt 1 (Run 2)  0.7928  0.0174             0.3718\n",
      "Prompt 2 (Run 1)  0.9964  0.0560             0.0784\n",
      "Prompt 2 (Run 2)  0.9964  0.0560             0.0784\n",
      "Prompt 3 (Run 1)  0.6717  0.0752             0.1246\n",
      "Prompt 3 (Run 2)  0.6717  0.0752             0.1246\n",
      "Prompt 4 (Run 1)  0.6765  0.0234             0.2707\n",
      "Prompt 4 (Run 2)  0.6765  0.0234             0.2707\n",
      "Prompt 5 (Run 1)  0.7930  0.0129             0.2002\n",
      "Prompt 5 (Run 2)  0.7930  0.0129             0.2002\n",
      "Prompt 6 (Run 1)  0.9609  0.0851             0.3421\n",
      "Prompt 6 (Run 2)  0.9609  0.0851             0.3421\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2501\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.6351  0.0000             0.0286\n",
      "Prompt 1 (Run 2)  0.6351  0.0000             0.0286\n",
      "Prompt 2 (Run 1)  0.9186  0.1083             0.1067\n",
      "Prompt 2 (Run 2)  0.9186  0.1083             0.1067\n",
      "Prompt 3 (Run 1)  1.2387  0.1145             0.2026\n",
      "Prompt 3 (Run 2)  1.2387  0.1145             0.2026\n",
      "Prompt 4 (Run 1)  1.0566  0.0740             0.2917\n",
      "Prompt 4 (Run 2)  1.0566  0.0740             0.2917\n",
      "Prompt 5 (Run 1)  0.7503  0.0000             0.0718\n",
      "Prompt 5 (Run 2)  0.7503  0.0000             0.0718\n",
      "Prompt 6 (Run 1)  0.6219  0.0000             0.1259\n",
      "Prompt 6 (Run 2)  0.6219  0.0000             0.1259\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2502\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.6511  0.0571             0.5765\n",
      "Prompt 1 (Run 2)  0.6511  0.0571             0.5765\n",
      "Prompt 2 (Run 1)  0.6971  0.1101             0.3815\n",
      "Prompt 2 (Run 2)  0.6971  0.1101             0.3815\n",
      "Prompt 3 (Run 1)  0.4401  0.0285             0.1596\n",
      "Prompt 3 (Run 2)  0.4401  0.0285             0.1596\n",
      "Prompt 4 (Run 1)  0.5846  0.0223             0.3585\n",
      "Prompt 4 (Run 2)  0.5846  0.0223             0.3585\n",
      "Prompt 5 (Run 1)  0.8870  0.0912             0.5747\n",
      "Prompt 5 (Run 2)  0.8870  0.0912             0.5747\n",
      "Prompt 6 (Run 1)  0.3938  0.0345             0.2545\n",
      "Prompt 6 (Run 2)  0.3938  0.0345             0.2545\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2503\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.6975  0.0000             0.4794\n",
      "Prompt 1 (Run 2)  0.6975  0.0000             0.4794\n",
      "Prompt 2 (Run 1)  0.6003  0.0129             0.4146\n",
      "Prompt 2 (Run 2)  0.6003  0.0129             0.4146\n",
      "Prompt 3 (Run 1)  0.9224  0.0411             0.3351\n",
      "Prompt 3 (Run 2)  0.9224  0.0411             0.3351\n",
      "Prompt 4 (Run 1)  0.9649  0.0489             0.4755\n",
      "Prompt 4 (Run 2)  0.9649  0.0489             0.4755\n",
      "Prompt 5 (Run 1)  0.8414  0.0410             0.3653\n",
      "Prompt 5 (Run 2)  0.8414  0.0410             0.3653\n",
      "Prompt 6 (Run 1)  0.5831  0.0363             0.3590\n",
      "Prompt 6 (Run 2)  0.5831  0.0363             0.3590\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2504\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.5696  0.0000             0.1857\n",
      "Prompt 1 (Run 2)  0.5696  0.0000             0.1857\n",
      "Prompt 2 (Run 1)  0.4388  0.0623             0.0732\n",
      "Prompt 2 (Run 2)  0.4388  0.0623             0.0732\n",
      "Prompt 3 (Run 1)  0.0445  0.0000             0.0846\n",
      "Prompt 3 (Run 2)  0.0445  0.0000             0.0846\n",
      "Prompt 4 (Run 1)  0.3567  0.0000             0.2652\n",
      "Prompt 4 (Run 2)  0.3567  0.0000             0.2652\n",
      "Prompt 5 (Run 1)  0.9874  0.0861             0.4393\n",
      "Prompt 5 (Run 2)  0.9874  0.0861             0.4393\n",
      "Prompt 6 (Run 1)  0.5625  0.0757             0.1810\n",
      "Prompt 6 (Run 2)  0.5625  0.0757             0.1810\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2505\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.2962  0.0707             0.3579\n",
      "Prompt 1 (Run 2)  0.2962  0.0707             0.3579\n",
      "Prompt 2 (Run 1)  0.3344  0.0348             0.2155\n",
      "Prompt 2 (Run 2)  0.3344  0.0348             0.2155\n",
      "Prompt 3 (Run 1)  0.3534  0.0470             0.2959\n",
      "Prompt 3 (Run 2)  0.3534  0.0470             0.2959\n",
      "Prompt 4 (Run 1)  0.6058  0.0149             0.3983\n",
      "Prompt 4 (Run 2)  0.6058  0.0149             0.3983\n",
      "Prompt 5 (Run 1)  0.9624  0.0745             0.3357\n",
      "Prompt 5 (Run 2)  0.9624  0.0745             0.3357\n",
      "Prompt 6 (Run 1)  0.5758  0.0421             0.2835\n",
      "Prompt 6 (Run 2)  0.5758  0.0421             0.2835\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2506\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.7752  0.0224             0.3904\n",
      "Prompt 1 (Run 2)  0.7752  0.0224             0.3904\n",
      "Prompt 2 (Run 1)  0.7273  0.0634             0.3940\n",
      "Prompt 2 (Run 2)  0.7273  0.0634             0.3940\n",
      "Prompt 3 (Run 1)  1.0687  0.1026             0.5301\n",
      "Prompt 3 (Run 2)  1.0687  0.1026             0.5301\n",
      "Prompt 4 (Run 1)  0.7204  0.0221             0.3672\n",
      "Prompt 4 (Run 2)  0.7204  0.0221             0.3672\n",
      "Prompt 5 (Run 1)  1.3744  0.0749             0.3193\n",
      "Prompt 5 (Run 2)  1.3744  0.0749             0.3193\n",
      "Prompt 6 (Run 1)  1.0363  0.0740             0.4598\n",
      "Prompt 6 (Run 2)  1.0363  0.0740             0.4598\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2507\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.4385  0.1547             0.3283\n",
      "Prompt 1 (Run 2)  0.4385  0.1547             0.3283\n",
      "Prompt 2 (Run 1)  1.2820  0.0278             0.1898\n",
      "Prompt 2 (Run 2)  1.2820  0.0278             0.1898\n",
      "Prompt 3 (Run 1)  0.0000  0.0000             0.1331\n",
      "Prompt 3 (Run 2)  0.0000  0.0000             0.1331\n",
      "Prompt 4 (Run 1)  1.3056  0.0843             0.5652\n",
      "Prompt 4 (Run 2)  1.3056  0.0843             0.5652\n",
      "Prompt 5 (Run 1)  0.5089  0.0100             0.2607\n",
      "Prompt 5 (Run 2)  0.5089  0.0100             0.2607\n",
      "Prompt 6 (Run 1)  0.8496  0.0649             0.3912\n",
      "Prompt 6 (Run 2)  0.8496  0.0649             0.3912\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2508\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.7280  0.0129             0.0973\n",
      "Prompt 1 (Run 2)  0.7280  0.0129             0.0973\n",
      "Prompt 2 (Run 1)  0.8132  0.0000             0.0749\n",
      "Prompt 2 (Run 2)  0.8132  0.0000             0.0749\n",
      "Prompt 3 (Run 1)  0.9657  0.0438             0.3042\n",
      "Prompt 3 (Run 2)  0.9657  0.0438             0.3042\n",
      "Prompt 4 (Run 1)  0.9762  0.0354             0.4468\n",
      "Prompt 4 (Run 2)  0.9762  0.0354             0.4468\n",
      "Prompt 5 (Run 1)  0.6563  0.0138             0.2313\n",
      "Prompt 5 (Run 2)  0.6563  0.0138             0.2313\n",
      "Prompt 6 (Run 1)  0.7389  0.0269             0.1443\n",
      "Prompt 6 (Run 2)  0.7389  0.0269             0.1443\n",
      "============================================================\n",
      "\n",
      "ğŸ“¸ Image ID: 2509\n",
      "------------------------------------------------------------\n",
      "                   CIDEr   SPICE  cosine_similarity\n",
      "Prompt 1 (Run 1)  0.9716  0.0758             0.2805\n",
      "Prompt 1 (Run 2)  0.9716  0.0758             0.2805\n",
      "Prompt 2 (Run 1)  0.5861  0.0584             0.1856\n",
      "Prompt 2 (Run 2)  0.5861  0.0584             0.1856\n",
      "Prompt 3 (Run 1)  0.4300  0.1521             0.2722\n",
      "Prompt 3 (Run 2)  0.4300  0.1521             0.2722\n",
      "Prompt 4 (Run 1)  0.9649  0.0406             0.2351\n",
      "Prompt 4 (Run 2)  0.9649  0.0406             0.2351\n",
      "Prompt 5 (Run 1)  0.2888  0.0232             0.2990\n",
      "Prompt 5 (Run 2)  0.2888  0.0232             0.2990\n",
      "Prompt 6 (Run 1)  1.0206  0.0389             0.2195\n",
      "Prompt 6 (Run 2)  1.0206  0.0389             0.2195\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    print(f\"\\nğŸ“¸ Image ID: {img_id}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    df_temp = pd.DataFrame(scores)\n",
    "    prompt_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        prompt_num = (i // 2) + 1  # Prompts 1â€“6\n",
    "        run_num = (i % 2) + 1      # Run 1 or Run 2\n",
    "        prompt_labels.append(f\"Prompt {prompt_num} (Run {run_num})\")\n",
    "\n",
    "    df_temp.index = prompt_labels\n",
    "    print(df_temp.round(4))\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4105eb03-b144-401d-8020-6b2e1e714aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results table\n",
    "table = wandb.Table(columns=[\"img_id\", \"prompt_type\", \"run\", \"image\", \"ground_truth\", \"prediction\"])\n",
    "\n",
    "for img_id in all_outputs:\n",
    "    filename_row = df[df[\"img_id\"].astype(str) == str(img_id)]\n",
    "    if filename_row.empty:\n",
    "        continue\n",
    "\n",
    "    filename = filename_row.iloc[0][\"filename\"]\n",
    "    gt_captions = filename_row.iloc[0][\"caption\"]\n",
    "    image_row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))\n",
    "    if len(image_row) == 0:\n",
    "        continue\n",
    "    image_pil = image_row[0][\"image\"]  # This is already PIL.Image\n",
    "\n",
    "    for prompt_index in range(6):\n",
    "        for run in range(2):\n",
    "            row_idx = prompt_index * 2 + run\n",
    "            prediction = all_outputs[img_id][row_idx] if row_idx < len(all_outputs[img_id]) else \"N/A\"\n",
    "\n",
    "            table.add_data(\n",
    "                str(img_id),\n",
    "                f\"Prompt {prompt_index + 1}\",\n",
    "                f\"Run {run + 1}\",\n",
    "                wandb.Image(image_pil),\n",
    "                gt_captions[0],  # only logging first GT\n",
    "                prediction\n",
    "            )\n",
    "\n",
    "wandb.log({\"Prompting Comparison Results\": table})\n",
    "\n",
    "# Log metrics for each prompt run\n",
    "for img_id, scores in all_metrics_scores.items():\n",
    "    for i, score in enumerate(scores):\n",
    "        wandb.log({\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/CIDEr\": score[\"CIDEr\"],\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/SPICE\": score[\"SPICE\"],\n",
    "            f\"{img_id}/Prompt {i//2 + 1}/Run {i%2 + 1}/Cosine\": score[\"cosine_similarity\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b457f5c9-36a8-4888-84bd-9b14db901a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prompt_metrics_to_excel(\n",
    "    img_id: str,\n",
    "    model_name: str,\n",
    "    inference_outputs: list,\n",
    "    metrics: list,\n",
    "    inference_times: list,\n",
    "    vram_usages: list,\n",
    "    df: pd.DataFrame,\n",
    "    test_dataset,\n",
    "    output_excel_path: str = \"prompt_tuning_results_flickr_pixtral.xlsx\"\n",
    "):\n",
    "    from openpyxl import Workbook, load_workbook\n",
    "    from openpyxl.drawing.image import Image as ExcelImage\n",
    "    from openpyxl.styles import Alignment\n",
    "    from PIL import Image as PILImage\n",
    "    import os\n",
    "\n",
    "    # Extract from test_dataset using img_id\n",
    "    row = test_dataset.filter(lambda x: x[\"img_id\"] == str(img_id))[0]\n",
    "    filename = row[\"filename\"]\n",
    "    image_path = os.path.join(\"/workspace/data/filtered_dataset\", filename)\n",
    "    original_caption = row[\"caption\"]\n",
    "    original_caption_text = \"\\n\".join(original_caption) if isinstance(original_caption, list) else str(original_caption)\n",
    "\n",
    "    # Load or create Excel file\n",
    "    if os.path.exists(output_excel_path):\n",
    "        wb = load_workbook(output_excel_path)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Prompt Evaluation\"\n",
    "        headers = [\n",
    "            \"Model\", \"Image ID\", \"Image\", \"Original Captions\",\n",
    "            \"Prompt\", \"Output\", \"Inference Time (s)\", \"VRAM Used (GB)\",\n",
    "            \"CIDEr\", \"SPICE\", \"Cosine Similarity\"\n",
    "        ]\n",
    "        ws.append(headers)\n",
    "\n",
    "    start_row = ws.max_row + 1\n",
    "\n",
    "    # Write both runs (2x6 = 12 rows)\n",
    "        # Write both runs (2x6 = 12 rows) â€” run-wise grouping\n",
    "    for run in range(2):  # 0 = Run 1, 1 = Run 2\n",
    "        row_start = start_row + run * 6\n",
    "        for i in range(6):  # Prompt 1â€“6\n",
    "            idx = i * 2 + run  # FIXED: Correct index mapping\n",
    "            ws.append([\n",
    "                model_name,\n",
    "                img_id,\n",
    "                \"\",\n",
    "                original_caption_text,\n",
    "                f\"Prompt {i+1} (Run {run+1})\",\n",
    "                inference_outputs[idx],\n",
    "                inference_times[idx],\n",
    "                vram_usages[idx],\n",
    "                metrics[idx][\"CIDEr\"],\n",
    "                metrics[idx][\"SPICE\"],\n",
    "                metrics[idx][\"cosine_similarity\"]\n",
    "            ])\n",
    "\n",
    "        # Merge columns Aâ€“D separately for each run\n",
    "        for col in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            ws.merge_cells(f\"{col}{row_start}:{col}{row_start + 5}\")\n",
    "\n",
    "    # Apply formatting\n",
    "    align_top_wrap = Alignment(wrap_text=True, vertical=\"top\")\n",
    "    align_top = Alignment(vertical=\"top\")\n",
    "\n",
    "    for row in range(start_row, start_row + 12):\n",
    "        for col_letter in [\"A\", \"B\", \"C\", \"E\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top\n",
    "        for col_letter in [\"D\", \"F\"]:\n",
    "            ws[f\"{col_letter}{row}\"].alignment = align_top_wrap\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    # Set column widths\n",
    "    ws.column_dimensions[\"D\"].width = 50  # Captions\n",
    "    ws.column_dimensions[\"F\"].width = 50  # Output\n",
    "\n",
    "    # Insert image once (in first run)\n",
    "        # Embed image in first run row\n",
    "    if os.path.exists(image_path):\n",
    "        try:\n",
    "            print(f\"[INFO] Embedding image from path: {image_path}\")\n",
    "            pil_img = PILImage.open(image_path)\n",
    "            pil_img.thumbnail((300, 300))  # Resize for better fit\n",
    "\n",
    "            excel_img = ExcelImage(image_path)\n",
    "            excel_img.width = 150\n",
    "            excel_img.height = 150\n",
    "            excel_img.anchor = f\"C{start_row}\"  # Image embedded in first run row\n",
    "            ws.add_image(excel_img)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not embed image for {img_id}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Image path does not exist: {image_path}\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"âœ… Logged both runs for image {img_id} to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb947f87-7707-46c5-9edb-946600d699a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080be8ae8b144820a83dec7070581b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182169366.jpg\n",
      "âœ… Logged both runs for image 2500 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ee5dce6747405f8f8abf33084ac6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182184279.jpg\n",
      "âœ… Logged both runs for image 2501 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040b4d677a184a3d9ffb77cb2a35bdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182246705.jpg\n",
      "âœ… Logged both runs for image 2502 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37498ffa9f44d1eb1d007d6a2a0d0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182396080.jpg\n",
      "âœ… Logged both runs for image 2503 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f305450c0bfa4b98b2f17d0bd13e28a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182493240.jpg\n",
      "âœ… Logged both runs for image 2504 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f8c3b67a2645148616376dc6c69451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182503906.jpg\n",
      "âœ… Logged both runs for image 2505 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2afd2d3f41e49f2a03c938a36054eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/1827287777.jpg\n",
      "âœ… Logged both runs for image 2506 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4888002edeef4c34ba14e09b88794de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/1827560917.jpg\n",
      "âœ… Logged both runs for image 2507 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03deafaf2f84086995be4c08f1d2061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/182825639.jpg\n",
      "âœ… Logged both runs for image 2508 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79302fd799314339947f030d0381ee5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding image from path: /workspace/data/filtered_dataset/18284727.jpg\n",
      "âœ… Logged both runs for image 2509 to prompt_tuning_results_flickr_pixtral.xlsx\n"
     ]
    }
   ],
   "source": [
    "for img_id in all_outputs.keys():\n",
    "    log_prompt_metrics_to_excel(\n",
    "        img_id=img_id,\n",
    "        model_name=model_id,\n",
    "        inference_outputs=all_outputs[img_id],\n",
    "        metrics=all_metrics_scores[img_id],\n",
    "        inference_times=all_times[img_id],\n",
    "        vram_usages=all_vram[img_id],\n",
    "        df=df,\n",
    "        test_dataset=test_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d63bd375-8987-423e-aa9e-6831b8a85844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>2500/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2500/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2501/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2502/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2503/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2504/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2505/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2506/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2507/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2508/Prompt 6/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 1/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 2/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 3/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 4/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 5/Run 2/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 1/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 1/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 1/SPICE</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 2/CIDEr</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 2/Cosine</td><td>â–</td></tr><tr><td>2509/Prompt 6/Run 2/SPICE</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>2500/Prompt 1/Run 1/CIDEr</td><td>0.7928</td></tr><tr><td>2500/Prompt 1/Run 1/Cosine</td><td>0.3718</td></tr><tr><td>2500/Prompt 1/Run 1/SPICE</td><td>0.0174</td></tr><tr><td>2500/Prompt 1/Run 2/CIDEr</td><td>0.7928</td></tr><tr><td>2500/Prompt 1/Run 2/Cosine</td><td>0.3718</td></tr><tr><td>2500/Prompt 1/Run 2/SPICE</td><td>0.0174</td></tr><tr><td>2500/Prompt 2/Run 1/CIDEr</td><td>0.9964</td></tr><tr><td>2500/Prompt 2/Run 1/Cosine</td><td>0.0784</td></tr><tr><td>2500/Prompt 2/Run 1/SPICE</td><td>0.056</td></tr><tr><td>2500/Prompt 2/Run 2/CIDEr</td><td>0.9964</td></tr><tr><td>2500/Prompt 2/Run 2/Cosine</td><td>0.0784</td></tr><tr><td>2500/Prompt 2/Run 2/SPICE</td><td>0.056</td></tr><tr><td>2500/Prompt 3/Run 1/CIDEr</td><td>0.6717</td></tr><tr><td>2500/Prompt 3/Run 1/Cosine</td><td>0.1246</td></tr><tr><td>2500/Prompt 3/Run 1/SPICE</td><td>0.0752</td></tr><tr><td>2500/Prompt 3/Run 2/CIDEr</td><td>0.6717</td></tr><tr><td>2500/Prompt 3/Run 2/Cosine</td><td>0.1246</td></tr><tr><td>2500/Prompt 3/Run 2/SPICE</td><td>0.0752</td></tr><tr><td>2500/Prompt 4/Run 1/CIDEr</td><td>0.6765</td></tr><tr><td>2500/Prompt 4/Run 1/Cosine</td><td>0.2707</td></tr><tr><td>2500/Prompt 4/Run 1/SPICE</td><td>0.0234</td></tr><tr><td>2500/Prompt 4/Run 2/CIDEr</td><td>0.6765</td></tr><tr><td>2500/Prompt 4/Run 2/Cosine</td><td>0.2707</td></tr><tr><td>2500/Prompt 4/Run 2/SPICE</td><td>0.0234</td></tr><tr><td>2500/Prompt 5/Run 1/CIDEr</td><td>0.793</td></tr><tr><td>2500/Prompt 5/Run 1/Cosine</td><td>0.2002</td></tr><tr><td>2500/Prompt 5/Run 1/SPICE</td><td>0.0129</td></tr><tr><td>2500/Prompt 5/Run 2/CIDEr</td><td>0.793</td></tr><tr><td>2500/Prompt 5/Run 2/Cosine</td><td>0.2002</td></tr><tr><td>2500/Prompt 5/Run 2/SPICE</td><td>0.0129</td></tr><tr><td>2500/Prompt 6/Run 1/CIDEr</td><td>0.9609</td></tr><tr><td>2500/Prompt 6/Run 1/Cosine</td><td>0.3421</td></tr><tr><td>2500/Prompt 6/Run 1/SPICE</td><td>0.0851</td></tr><tr><td>2500/Prompt 6/Run 2/CIDEr</td><td>0.9609</td></tr><tr><td>2500/Prompt 6/Run 2/Cosine</td><td>0.3421</td></tr><tr><td>2500/Prompt 6/Run 2/SPICE</td><td>0.0851</td></tr><tr><td>2501/Prompt 1/Run 1/CIDEr</td><td>0.6351</td></tr><tr><td>2501/Prompt 1/Run 1/Cosine</td><td>0.0286</td></tr><tr><td>2501/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>2501/Prompt 1/Run 2/CIDEr</td><td>0.6351</td></tr><tr><td>2501/Prompt 1/Run 2/Cosine</td><td>0.0286</td></tr><tr><td>2501/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>2501/Prompt 2/Run 1/CIDEr</td><td>0.9186</td></tr><tr><td>2501/Prompt 2/Run 1/Cosine</td><td>0.1067</td></tr><tr><td>2501/Prompt 2/Run 1/SPICE</td><td>0.1083</td></tr><tr><td>2501/Prompt 2/Run 2/CIDEr</td><td>0.9186</td></tr><tr><td>2501/Prompt 2/Run 2/Cosine</td><td>0.1067</td></tr><tr><td>2501/Prompt 2/Run 2/SPICE</td><td>0.1083</td></tr><tr><td>2501/Prompt 3/Run 1/CIDEr</td><td>1.2387</td></tr><tr><td>2501/Prompt 3/Run 1/Cosine</td><td>0.2026</td></tr><tr><td>2501/Prompt 3/Run 1/SPICE</td><td>0.1145</td></tr><tr><td>2501/Prompt 3/Run 2/CIDEr</td><td>1.2387</td></tr><tr><td>2501/Prompt 3/Run 2/Cosine</td><td>0.2026</td></tr><tr><td>2501/Prompt 3/Run 2/SPICE</td><td>0.1145</td></tr><tr><td>2501/Prompt 4/Run 1/CIDEr</td><td>1.0566</td></tr><tr><td>2501/Prompt 4/Run 1/Cosine</td><td>0.2917</td></tr><tr><td>2501/Prompt 4/Run 1/SPICE</td><td>0.074</td></tr><tr><td>2501/Prompt 4/Run 2/CIDEr</td><td>1.0566</td></tr><tr><td>2501/Prompt 4/Run 2/Cosine</td><td>0.2917</td></tr><tr><td>2501/Prompt 4/Run 2/SPICE</td><td>0.074</td></tr><tr><td>2501/Prompt 5/Run 1/CIDEr</td><td>0.7503</td></tr><tr><td>2501/Prompt 5/Run 1/Cosine</td><td>0.0718</td></tr><tr><td>2501/Prompt 5/Run 1/SPICE</td><td>0</td></tr><tr><td>2501/Prompt 5/Run 2/CIDEr</td><td>0.7503</td></tr><tr><td>2501/Prompt 5/Run 2/Cosine</td><td>0.0718</td></tr><tr><td>2501/Prompt 5/Run 2/SPICE</td><td>0</td></tr><tr><td>2501/Prompt 6/Run 1/CIDEr</td><td>0.6219</td></tr><tr><td>2501/Prompt 6/Run 1/Cosine</td><td>0.1259</td></tr><tr><td>2501/Prompt 6/Run 1/SPICE</td><td>0</td></tr><tr><td>2501/Prompt 6/Run 2/CIDEr</td><td>0.6219</td></tr><tr><td>2501/Prompt 6/Run 2/Cosine</td><td>0.1259</td></tr><tr><td>2501/Prompt 6/Run 2/SPICE</td><td>0</td></tr><tr><td>2502/Prompt 1/Run 1/CIDEr</td><td>0.6511</td></tr><tr><td>2502/Prompt 1/Run 1/Cosine</td><td>0.5765</td></tr><tr><td>2502/Prompt 1/Run 1/SPICE</td><td>0.0571</td></tr><tr><td>2502/Prompt 1/Run 2/CIDEr</td><td>0.6511</td></tr><tr><td>2502/Prompt 1/Run 2/Cosine</td><td>0.5765</td></tr><tr><td>2502/Prompt 1/Run 2/SPICE</td><td>0.0571</td></tr><tr><td>2502/Prompt 2/Run 1/CIDEr</td><td>0.6971</td></tr><tr><td>2502/Prompt 2/Run 1/Cosine</td><td>0.3815</td></tr><tr><td>2502/Prompt 2/Run 1/SPICE</td><td>0.1101</td></tr><tr><td>2502/Prompt 2/Run 2/CIDEr</td><td>0.6971</td></tr><tr><td>2502/Prompt 2/Run 2/Cosine</td><td>0.3815</td></tr><tr><td>2502/Prompt 2/Run 2/SPICE</td><td>0.1101</td></tr><tr><td>2502/Prompt 3/Run 1/CIDEr</td><td>0.4401</td></tr><tr><td>2502/Prompt 3/Run 1/Cosine</td><td>0.1596</td></tr><tr><td>2502/Prompt 3/Run 1/SPICE</td><td>0.0285</td></tr><tr><td>2502/Prompt 3/Run 2/CIDEr</td><td>0.4401</td></tr><tr><td>2502/Prompt 3/Run 2/Cosine</td><td>0.1596</td></tr><tr><td>2502/Prompt 3/Run 2/SPICE</td><td>0.0285</td></tr><tr><td>2502/Prompt 4/Run 1/CIDEr</td><td>0.5846</td></tr><tr><td>2502/Prompt 4/Run 1/Cosine</td><td>0.3585</td></tr><tr><td>2502/Prompt 4/Run 1/SPICE</td><td>0.0223</td></tr><tr><td>2502/Prompt 4/Run 2/CIDEr</td><td>0.5846</td></tr><tr><td>2502/Prompt 4/Run 2/Cosine</td><td>0.3585</td></tr><tr><td>2502/Prompt 4/Run 2/SPICE</td><td>0.0223</td></tr><tr><td>2502/Prompt 5/Run 1/CIDEr</td><td>0.887</td></tr><tr><td>2502/Prompt 5/Run 1/Cosine</td><td>0.5747</td></tr><tr><td>2502/Prompt 5/Run 1/SPICE</td><td>0.0912</td></tr><tr><td>2502/Prompt 5/Run 2/CIDEr</td><td>0.887</td></tr><tr><td>2502/Prompt 5/Run 2/Cosine</td><td>0.5747</td></tr><tr><td>2502/Prompt 5/Run 2/SPICE</td><td>0.0912</td></tr><tr><td>2502/Prompt 6/Run 1/CIDEr</td><td>0.3938</td></tr><tr><td>2502/Prompt 6/Run 1/Cosine</td><td>0.2545</td></tr><tr><td>2502/Prompt 6/Run 1/SPICE</td><td>0.0345</td></tr><tr><td>2502/Prompt 6/Run 2/CIDEr</td><td>0.3938</td></tr><tr><td>2502/Prompt 6/Run 2/Cosine</td><td>0.2545</td></tr><tr><td>2502/Prompt 6/Run 2/SPICE</td><td>0.0345</td></tr><tr><td>2503/Prompt 1/Run 1/CIDEr</td><td>0.6975</td></tr><tr><td>2503/Prompt 1/Run 1/Cosine</td><td>0.4794</td></tr><tr><td>2503/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>2503/Prompt 1/Run 2/CIDEr</td><td>0.6975</td></tr><tr><td>2503/Prompt 1/Run 2/Cosine</td><td>0.4794</td></tr><tr><td>2503/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>2503/Prompt 2/Run 1/CIDEr</td><td>0.6003</td></tr><tr><td>2503/Prompt 2/Run 1/Cosine</td><td>0.4146</td></tr><tr><td>2503/Prompt 2/Run 1/SPICE</td><td>0.0129</td></tr><tr><td>2503/Prompt 2/Run 2/CIDEr</td><td>0.6003</td></tr><tr><td>2503/Prompt 2/Run 2/Cosine</td><td>0.4146</td></tr><tr><td>2503/Prompt 2/Run 2/SPICE</td><td>0.0129</td></tr><tr><td>2503/Prompt 3/Run 1/CIDEr</td><td>0.9224</td></tr><tr><td>2503/Prompt 3/Run 1/Cosine</td><td>0.3351</td></tr><tr><td>2503/Prompt 3/Run 1/SPICE</td><td>0.0411</td></tr><tr><td>2503/Prompt 3/Run 2/CIDEr</td><td>0.9224</td></tr><tr><td>2503/Prompt 3/Run 2/Cosine</td><td>0.3351</td></tr><tr><td>2503/Prompt 3/Run 2/SPICE</td><td>0.0411</td></tr><tr><td>2503/Prompt 4/Run 1/CIDEr</td><td>0.9649</td></tr><tr><td>2503/Prompt 4/Run 1/Cosine</td><td>0.4755</td></tr><tr><td>2503/Prompt 4/Run 1/SPICE</td><td>0.0489</td></tr><tr><td>2503/Prompt 4/Run 2/CIDEr</td><td>0.9649</td></tr><tr><td>2503/Prompt 4/Run 2/Cosine</td><td>0.4755</td></tr><tr><td>2503/Prompt 4/Run 2/SPICE</td><td>0.0489</td></tr><tr><td>2503/Prompt 5/Run 1/CIDEr</td><td>0.8414</td></tr><tr><td>2503/Prompt 5/Run 1/Cosine</td><td>0.3653</td></tr><tr><td>2503/Prompt 5/Run 1/SPICE</td><td>0.041</td></tr><tr><td>2503/Prompt 5/Run 2/CIDEr</td><td>0.8414</td></tr><tr><td>2503/Prompt 5/Run 2/Cosine</td><td>0.3653</td></tr><tr><td>2503/Prompt 5/Run 2/SPICE</td><td>0.041</td></tr><tr><td>2503/Prompt 6/Run 1/CIDEr</td><td>0.5831</td></tr><tr><td>2503/Prompt 6/Run 1/Cosine</td><td>0.359</td></tr><tr><td>2503/Prompt 6/Run 1/SPICE</td><td>0.0363</td></tr><tr><td>2503/Prompt 6/Run 2/CIDEr</td><td>0.5831</td></tr><tr><td>2503/Prompt 6/Run 2/Cosine</td><td>0.359</td></tr><tr><td>2503/Prompt 6/Run 2/SPICE</td><td>0.0363</td></tr><tr><td>2504/Prompt 1/Run 1/CIDEr</td><td>0.5696</td></tr><tr><td>2504/Prompt 1/Run 1/Cosine</td><td>0.1857</td></tr><tr><td>2504/Prompt 1/Run 1/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 1/Run 2/CIDEr</td><td>0.5696</td></tr><tr><td>2504/Prompt 1/Run 2/Cosine</td><td>0.1857</td></tr><tr><td>2504/Prompt 1/Run 2/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 2/Run 1/CIDEr</td><td>0.4388</td></tr><tr><td>2504/Prompt 2/Run 1/Cosine</td><td>0.0732</td></tr><tr><td>2504/Prompt 2/Run 1/SPICE</td><td>0.0623</td></tr><tr><td>2504/Prompt 2/Run 2/CIDEr</td><td>0.4388</td></tr><tr><td>2504/Prompt 2/Run 2/Cosine</td><td>0.0732</td></tr><tr><td>2504/Prompt 2/Run 2/SPICE</td><td>0.0623</td></tr><tr><td>2504/Prompt 3/Run 1/CIDEr</td><td>0.0445</td></tr><tr><td>2504/Prompt 3/Run 1/Cosine</td><td>0.0846</td></tr><tr><td>2504/Prompt 3/Run 1/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 3/Run 2/CIDEr</td><td>0.0445</td></tr><tr><td>2504/Prompt 3/Run 2/Cosine</td><td>0.0846</td></tr><tr><td>2504/Prompt 3/Run 2/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 4/Run 1/CIDEr</td><td>0.3567</td></tr><tr><td>2504/Prompt 4/Run 1/Cosine</td><td>0.2652</td></tr><tr><td>2504/Prompt 4/Run 1/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 4/Run 2/CIDEr</td><td>0.3567</td></tr><tr><td>2504/Prompt 4/Run 2/Cosine</td><td>0.2652</td></tr><tr><td>2504/Prompt 4/Run 2/SPICE</td><td>0</td></tr><tr><td>2504/Prompt 5/Run 1/CIDEr</td><td>0.9874</td></tr><tr><td>2504/Prompt 5/Run 1/Cosine</td><td>0.4393</td></tr><tr><td>2504/Prompt 5/Run 1/SPICE</td><td>0.0861</td></tr><tr><td>2504/Prompt 5/Run 2/CIDEr</td><td>0.9874</td></tr><tr><td>2504/Prompt 5/Run 2/Cosine</td><td>0.4393</td></tr><tr><td>2504/Prompt 5/Run 2/SPICE</td><td>0.0861</td></tr><tr><td>2504/Prompt 6/Run 1/CIDEr</td><td>0.5625</td></tr><tr><td>2504/Prompt 6/Run 1/Cosine</td><td>0.181</td></tr><tr><td>2504/Prompt 6/Run 1/SPICE</td><td>0.0757</td></tr><tr><td>2504/Prompt 6/Run 2/CIDEr</td><td>0.5625</td></tr><tr><td>2504/Prompt 6/Run 2/Cosine</td><td>0.181</td></tr><tr><td>2504/Prompt 6/Run 2/SPICE</td><td>0.0757</td></tr><tr><td>2505/Prompt 1/Run 1/CIDEr</td><td>0.2962</td></tr><tr><td>2505/Prompt 1/Run 1/Cosine</td><td>0.3579</td></tr><tr><td>2505/Prompt 1/Run 1/SPICE</td><td>0.0707</td></tr><tr><td>2505/Prompt 1/Run 2/CIDEr</td><td>0.2962</td></tr><tr><td>2505/Prompt 1/Run 2/Cosine</td><td>0.3579</td></tr><tr><td>2505/Prompt 1/Run 2/SPICE</td><td>0.0707</td></tr><tr><td>2505/Prompt 2/Run 1/CIDEr</td><td>0.3344</td></tr><tr><td>2505/Prompt 2/Run 1/Cosine</td><td>0.2155</td></tr><tr><td>2505/Prompt 2/Run 1/SPICE</td><td>0.0348</td></tr><tr><td>2505/Prompt 2/Run 2/CIDEr</td><td>0.3344</td></tr><tr><td>2505/Prompt 2/Run 2/Cosine</td><td>0.2155</td></tr><tr><td>2505/Prompt 2/Run 2/SPICE</td><td>0.0348</td></tr><tr><td>2505/Prompt 3/Run 1/CIDEr</td><td>0.3534</td></tr><tr><td>2505/Prompt 3/Run 1/Cosine</td><td>0.2959</td></tr><tr><td>2505/Prompt 3/Run 1/SPICE</td><td>0.047</td></tr><tr><td>2505/Prompt 3/Run 2/CIDEr</td><td>0.3534</td></tr><tr><td>2505/Prompt 3/Run 2/Cosine</td><td>0.2959</td></tr><tr><td>2505/Prompt 3/Run 2/SPICE</td><td>0.047</td></tr><tr><td>2505/Prompt 4/Run 1/CIDEr</td><td>0.6058</td></tr><tr><td>2505/Prompt 4/Run 1/Cosine</td><td>0.3983</td></tr><tr><td>2505/Prompt 4/Run 1/SPICE</td><td>0.0149</td></tr><tr><td>2505/Prompt 4/Run 2/CIDEr</td><td>0.6058</td></tr><tr><td>2505/Prompt 4/Run 2/Cosine</td><td>0.3983</td></tr><tr><td>2505/Prompt 4/Run 2/SPICE</td><td>0.0149</td></tr><tr><td>2505/Prompt 5/Run 1/CIDEr</td><td>0.9624</td></tr><tr><td>2505/Prompt 5/Run 1/Cosine</td><td>0.3357</td></tr><tr><td>2505/Prompt 5/Run 1/SPICE</td><td>0.0745</td></tr><tr><td>2505/Prompt 5/Run 2/CIDEr</td><td>0.9624</td></tr><tr><td>2505/Prompt 5/Run 2/Cosine</td><td>0.3357</td></tr><tr><td>2505/Prompt 5/Run 2/SPICE</td><td>0.0745</td></tr><tr><td>2505/Prompt 6/Run 1/CIDEr</td><td>0.5758</td></tr><tr><td>2505/Prompt 6/Run 1/Cosine</td><td>0.2835</td></tr><tr><td>2505/Prompt 6/Run 1/SPICE</td><td>0.0421</td></tr><tr><td>2505/Prompt 6/Run 2/CIDEr</td><td>0.5758</td></tr><tr><td>2505/Prompt 6/Run 2/Cosine</td><td>0.2835</td></tr><tr><td>2505/Prompt 6/Run 2/SPICE</td><td>0.0421</td></tr><tr><td>2506/Prompt 1/Run 1/CIDEr</td><td>0.7752</td></tr><tr><td>2506/Prompt 1/Run 1/Cosine</td><td>0.3904</td></tr><tr><td>2506/Prompt 1/Run 1/SPICE</td><td>0.0224</td></tr><tr><td>2506/Prompt 1/Run 2/CIDEr</td><td>0.7752</td></tr><tr><td>2506/Prompt 1/Run 2/Cosine</td><td>0.3904</td></tr><tr><td>2506/Prompt 1/Run 2/SPICE</td><td>0.0224</td></tr><tr><td>2506/Prompt 2/Run 1/CIDEr</td><td>0.7273</td></tr><tr><td>2506/Prompt 2/Run 1/Cosine</td><td>0.394</td></tr><tr><td>2506/Prompt 2/Run 1/SPICE</td><td>0.0634</td></tr><tr><td>2506/Prompt 2/Run 2/CIDEr</td><td>0.7273</td></tr><tr><td>2506/Prompt 2/Run 2/Cosine</td><td>0.394</td></tr><tr><td>2506/Prompt 2/Run 2/SPICE</td><td>0.0634</td></tr><tr><td>2506/Prompt 3/Run 1/CIDEr</td><td>1.0687</td></tr><tr><td>2506/Prompt 3/Run 1/Cosine</td><td>0.5301</td></tr><tr><td>2506/Prompt 3/Run 1/SPICE</td><td>0.1026</td></tr><tr><td>2506/Prompt 3/Run 2/CIDEr</td><td>1.0687</td></tr><tr><td>2506/Prompt 3/Run 2/Cosine</td><td>0.5301</td></tr><tr><td>2506/Prompt 3/Run 2/SPICE</td><td>0.1026</td></tr><tr><td>2506/Prompt 4/Run 1/CIDEr</td><td>0.7204</td></tr><tr><td>2506/Prompt 4/Run 1/Cosine</td><td>0.3672</td></tr><tr><td>2506/Prompt 4/Run 1/SPICE</td><td>0.0221</td></tr><tr><td>2506/Prompt 4/Run 2/CIDEr</td><td>0.7204</td></tr><tr><td>2506/Prompt 4/Run 2/Cosine</td><td>0.3672</td></tr><tr><td>2506/Prompt 4/Run 2/SPICE</td><td>0.0221</td></tr><tr><td>2506/Prompt 5/Run 1/CIDEr</td><td>1.3744</td></tr><tr><td>2506/Prompt 5/Run 1/Cosine</td><td>0.3193</td></tr><tr><td>2506/Prompt 5/Run 1/SPICE</td><td>0.0749</td></tr><tr><td>2506/Prompt 5/Run 2/CIDEr</td><td>1.3744</td></tr><tr><td>2506/Prompt 5/Run 2/Cosine</td><td>0.3193</td></tr><tr><td>2506/Prompt 5/Run 2/SPICE</td><td>0.0749</td></tr><tr><td>2506/Prompt 6/Run 1/CIDEr</td><td>1.0363</td></tr><tr><td>2506/Prompt 6/Run 1/Cosine</td><td>0.4598</td></tr><tr><td>2506/Prompt 6/Run 1/SPICE</td><td>0.074</td></tr><tr><td>2506/Prompt 6/Run 2/CIDEr</td><td>1.0363</td></tr><tr><td>2506/Prompt 6/Run 2/Cosine</td><td>0.4598</td></tr><tr><td>2506/Prompt 6/Run 2/SPICE</td><td>0.074</td></tr><tr><td>2507/Prompt 1/Run 1/CIDEr</td><td>0.4385</td></tr><tr><td>2507/Prompt 1/Run 1/Cosine</td><td>0.3283</td></tr><tr><td>2507/Prompt 1/Run 1/SPICE</td><td>0.1547</td></tr><tr><td>2507/Prompt 1/Run 2/CIDEr</td><td>0.4385</td></tr><tr><td>2507/Prompt 1/Run 2/Cosine</td><td>0.3283</td></tr><tr><td>2507/Prompt 1/Run 2/SPICE</td><td>0.1547</td></tr><tr><td>2507/Prompt 2/Run 1/CIDEr</td><td>1.282</td></tr><tr><td>2507/Prompt 2/Run 1/Cosine</td><td>0.1898</td></tr><tr><td>2507/Prompt 2/Run 1/SPICE</td><td>0.0278</td></tr><tr><td>2507/Prompt 2/Run 2/CIDEr</td><td>1.282</td></tr><tr><td>2507/Prompt 2/Run 2/Cosine</td><td>0.1898</td></tr><tr><td>2507/Prompt 2/Run 2/SPICE</td><td>0.0278</td></tr><tr><td>2507/Prompt 3/Run 1/CIDEr</td><td>0</td></tr><tr><td>2507/Prompt 3/Run 1/Cosine</td><td>0.1331</td></tr><tr><td>2507/Prompt 3/Run 1/SPICE</td><td>0</td></tr><tr><td>2507/Prompt 3/Run 2/CIDEr</td><td>0</td></tr><tr><td>2507/Prompt 3/Run 2/Cosine</td><td>0.1331</td></tr><tr><td>2507/Prompt 3/Run 2/SPICE</td><td>0</td></tr><tr><td>2507/Prompt 4/Run 1/CIDEr</td><td>1.3056</td></tr><tr><td>2507/Prompt 4/Run 1/Cosine</td><td>0.5652</td></tr><tr><td>2507/Prompt 4/Run 1/SPICE</td><td>0.0843</td></tr><tr><td>2507/Prompt 4/Run 2/CIDEr</td><td>1.3056</td></tr><tr><td>2507/Prompt 4/Run 2/Cosine</td><td>0.5652</td></tr><tr><td>2507/Prompt 4/Run 2/SPICE</td><td>0.0843</td></tr><tr><td>2507/Prompt 5/Run 1/CIDEr</td><td>0.5089</td></tr><tr><td>2507/Prompt 5/Run 1/Cosine</td><td>0.2607</td></tr><tr><td>2507/Prompt 5/Run 1/SPICE</td><td>0.01</td></tr><tr><td>2507/Prompt 5/Run 2/CIDEr</td><td>0.5089</td></tr><tr><td>2507/Prompt 5/Run 2/Cosine</td><td>0.2607</td></tr><tr><td>2507/Prompt 5/Run 2/SPICE</td><td>0.01</td></tr><tr><td>2507/Prompt 6/Run 1/CIDEr</td><td>0.8496</td></tr><tr><td>2507/Prompt 6/Run 1/Cosine</td><td>0.3912</td></tr><tr><td>2507/Prompt 6/Run 1/SPICE</td><td>0.0649</td></tr><tr><td>2507/Prompt 6/Run 2/CIDEr</td><td>0.8496</td></tr><tr><td>2507/Prompt 6/Run 2/Cosine</td><td>0.3912</td></tr><tr><td>2507/Prompt 6/Run 2/SPICE</td><td>0.0649</td></tr><tr><td>2508/Prompt 1/Run 1/CIDEr</td><td>0.728</td></tr><tr><td>2508/Prompt 1/Run 1/Cosine</td><td>0.0973</td></tr><tr><td>2508/Prompt 1/Run 1/SPICE</td><td>0.0129</td></tr><tr><td>2508/Prompt 1/Run 2/CIDEr</td><td>0.728</td></tr><tr><td>2508/Prompt 1/Run 2/Cosine</td><td>0.0973</td></tr><tr><td>2508/Prompt 1/Run 2/SPICE</td><td>0.0129</td></tr><tr><td>2508/Prompt 2/Run 1/CIDEr</td><td>0.8132</td></tr><tr><td>2508/Prompt 2/Run 1/Cosine</td><td>0.0749</td></tr><tr><td>2508/Prompt 2/Run 1/SPICE</td><td>0</td></tr><tr><td>2508/Prompt 2/Run 2/CIDEr</td><td>0.8132</td></tr><tr><td>2508/Prompt 2/Run 2/Cosine</td><td>0.0749</td></tr><tr><td>2508/Prompt 2/Run 2/SPICE</td><td>0</td></tr><tr><td>2508/Prompt 3/Run 1/CIDEr</td><td>0.9657</td></tr><tr><td>2508/Prompt 3/Run 1/Cosine</td><td>0.3042</td></tr><tr><td>2508/Prompt 3/Run 1/SPICE</td><td>0.0438</td></tr><tr><td>2508/Prompt 3/Run 2/CIDEr</td><td>0.9657</td></tr><tr><td>2508/Prompt 3/Run 2/Cosine</td><td>0.3042</td></tr><tr><td>2508/Prompt 3/Run 2/SPICE</td><td>0.0438</td></tr><tr><td>2508/Prompt 4/Run 1/CIDEr</td><td>0.9762</td></tr><tr><td>2508/Prompt 4/Run 1/Cosine</td><td>0.4468</td></tr><tr><td>2508/Prompt 4/Run 1/SPICE</td><td>0.0354</td></tr><tr><td>2508/Prompt 4/Run 2/CIDEr</td><td>0.9762</td></tr><tr><td>2508/Prompt 4/Run 2/Cosine</td><td>0.4468</td></tr><tr><td>2508/Prompt 4/Run 2/SPICE</td><td>0.0354</td></tr><tr><td>2508/Prompt 5/Run 1/CIDEr</td><td>0.6563</td></tr><tr><td>2508/Prompt 5/Run 1/Cosine</td><td>0.2313</td></tr><tr><td>2508/Prompt 5/Run 1/SPICE</td><td>0.0138</td></tr><tr><td>2508/Prompt 5/Run 2/CIDEr</td><td>0.6563</td></tr><tr><td>2508/Prompt 5/Run 2/Cosine</td><td>0.2313</td></tr><tr><td>2508/Prompt 5/Run 2/SPICE</td><td>0.0138</td></tr><tr><td>2508/Prompt 6/Run 1/CIDEr</td><td>0.7389</td></tr><tr><td>2508/Prompt 6/Run 1/Cosine</td><td>0.1443</td></tr><tr><td>2508/Prompt 6/Run 1/SPICE</td><td>0.0269</td></tr><tr><td>2508/Prompt 6/Run 2/CIDEr</td><td>0.7389</td></tr><tr><td>2508/Prompt 6/Run 2/Cosine</td><td>0.1443</td></tr><tr><td>2508/Prompt 6/Run 2/SPICE</td><td>0.0269</td></tr><tr><td>2509/Prompt 1/Run 1/CIDEr</td><td>0.9716</td></tr><tr><td>2509/Prompt 1/Run 1/Cosine</td><td>0.2805</td></tr><tr><td>2509/Prompt 1/Run 1/SPICE</td><td>0.0758</td></tr><tr><td>2509/Prompt 1/Run 2/CIDEr</td><td>0.9716</td></tr><tr><td>2509/Prompt 1/Run 2/Cosine</td><td>0.2805</td></tr><tr><td>2509/Prompt 1/Run 2/SPICE</td><td>0.0758</td></tr><tr><td>2509/Prompt 2/Run 1/CIDEr</td><td>0.5861</td></tr><tr><td>2509/Prompt 2/Run 1/Cosine</td><td>0.1856</td></tr><tr><td>2509/Prompt 2/Run 1/SPICE</td><td>0.0584</td></tr><tr><td>2509/Prompt 2/Run 2/CIDEr</td><td>0.5861</td></tr><tr><td>2509/Prompt 2/Run 2/Cosine</td><td>0.1856</td></tr><tr><td>2509/Prompt 2/Run 2/SPICE</td><td>0.0584</td></tr><tr><td>2509/Prompt 3/Run 1/CIDEr</td><td>0.43</td></tr><tr><td>2509/Prompt 3/Run 1/Cosine</td><td>0.2722</td></tr><tr><td>2509/Prompt 3/Run 1/SPICE</td><td>0.1521</td></tr><tr><td>2509/Prompt 3/Run 2/CIDEr</td><td>0.43</td></tr><tr><td>2509/Prompt 3/Run 2/Cosine</td><td>0.2722</td></tr><tr><td>2509/Prompt 3/Run 2/SPICE</td><td>0.1521</td></tr><tr><td>2509/Prompt 4/Run 1/CIDEr</td><td>0.9649</td></tr><tr><td>2509/Prompt 4/Run 1/Cosine</td><td>0.2351</td></tr><tr><td>2509/Prompt 4/Run 1/SPICE</td><td>0.0406</td></tr><tr><td>2509/Prompt 4/Run 2/CIDEr</td><td>0.9649</td></tr><tr><td>2509/Prompt 4/Run 2/Cosine</td><td>0.2351</td></tr><tr><td>2509/Prompt 4/Run 2/SPICE</td><td>0.0406</td></tr><tr><td>2509/Prompt 5/Run 1/CIDEr</td><td>0.2888</td></tr><tr><td>2509/Prompt 5/Run 1/Cosine</td><td>0.299</td></tr><tr><td>2509/Prompt 5/Run 1/SPICE</td><td>0.0232</td></tr><tr><td>2509/Prompt 5/Run 2/CIDEr</td><td>0.2888</td></tr><tr><td>2509/Prompt 5/Run 2/Cosine</td><td>0.299</td></tr><tr><td>2509/Prompt 5/Run 2/SPICE</td><td>0.0232</td></tr><tr><td>2509/Prompt 6/Run 1/CIDEr</td><td>1.0206</td></tr><tr><td>2509/Prompt 6/Run 1/Cosine</td><td>0.2195</td></tr><tr><td>2509/Prompt 6/Run 1/SPICE</td><td>0.0389</td></tr><tr><td>2509/Prompt 6/Run 2/CIDEr</td><td>1.0206</td></tr><tr><td>2509/Prompt 6/Run 2/Cosine</td><td>0.2195</td></tr><tr><td>2509/Prompt 6/Run 2/SPICE</td><td>0.0389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Prompt-Eval-Pixtral12B-Flickr30k</strong> at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments/runs/8n9p54lk</a><br> View project at: <a href='https://wandb.ai/vlm-research/Prompting-Experiments' target=\"_blank\">https://wandb.ai/vlm-research/Prompting-Experiments</a><br>Synced 5 W&B file(s), 1 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250525_071110-8n9p54lk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b889630-f0f8-42e4-ae82-605c96f76d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
