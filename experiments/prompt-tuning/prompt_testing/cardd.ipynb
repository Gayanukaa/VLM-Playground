{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5405616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_caption_dataset(\n",
    "    image_folder: str,\n",
    "    captions_json: str,\n",
    "    caption_strategy: str = 'first'\n",
    ") -> pd.DataFrame:\n",
    "    with open(captions_json, 'r') as f:\n",
    "        captions_data = json.load(f)\n",
    "\n",
    "    data = []\n",
    "    for filename, caption_list in captions_data.items():\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            caption = caption_list if caption_strategy == 'first' else random.choice(caption_list)\n",
    "            data.append({\"image\": image, \"caption\": caption, \"filename\": filename})\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {filename}: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\"  # change if needed\n",
    "#unsloth/Pixtral-12B-2409-bnb-4bit\n",
    "\n",
    "model, tokenizer, _, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    "    device_map = \"auto\"\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71501eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/workspace/data/filtered_images\"\n",
    "captions_json = \"/workspace/data/merged_output.json\"\n",
    "\n",
    "df = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(f\"Loaded {len(df)} image-caption pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d52628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Œ First 5 entries:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"ðŸ“‹ Column types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nðŸ”Ž Size\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "def run_vlm_inference(prompt: str, image_index: int, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Perform inference on a given image from the dataframe using a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The text prompt to use (can include mask tokens like <text_1>)\n",
    "        image_index (int): The index of the image in the dataframe\n",
    "        df (pd.DataFrame): DataFrame returned by create_image_caption_dataset\n",
    "    \"\"\"\n",
    "    if image_index >= len(df):\n",
    "        print(\"[ERROR] Image index out of bounds.\")\n",
    "        return\n",
    "\n",
    "    row = df.iloc[image_index]\n",
    "    image = row[\"image\"]\n",
    "    filename = row[\"filename\"]\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=image, text=input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    print(f\"ðŸ”¹ Image: {filename}\")\n",
    "    print(f\"ðŸ§¾ Prompt: {prompt}\")\n",
    "    print(\"ðŸ“¤ Output:\")\n",
    "\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a134307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1: No Prompt (Image only, no textual instruction provided)\n",
    "prompt_1 = \"\"\n",
    "output_1 = run_vlm_inference(prompt_1, image_index=0, df=df)\n",
    "\n",
    "# Prompt 2: Noisy Prompt\n",
    "prompt_2 = \"Describe &&damage 12 sedan driveâ€™ this !!image.\"\n",
    "output_2 = run_vlm_inference(prompt_2, image_index=0, df=df)\n",
    "\n",
    "# Prompt 3: Hand-Crafted (\"An image of...\")\n",
    "prompt_3 = \"An image of a damaged car parked on the side of the road.\"\n",
    "output_3 = run_vlm_inference(prompt_3, image_index=0, df=df)\n",
    "\n",
    "# Prompt 4: Descriptive Prompt with Roleplay / Stylistic Instruction\n",
    "prompt_4 = (\n",
    "    \"You are an insurance claims assessor. Provide a detailed description of the carâ€™s condition.\"\n",
    ")\n",
    "output_4 = run_vlm_inference(prompt_4, image_index=0, df=df)\n",
    "\n",
    "# Prompt 5: Masked Prompt\n",
    "prompt_5 = (\n",
    "    \"This <part_1> of the car has <damage_type_1>. The severity appears to be <severity_1>. \"\n",
    "    \"Additional notes: <text_1>.\"\n",
    ")\n",
    "output_5 = run_vlm_inference(prompt_5, image_index=0, df=df)\n",
    "\n",
    "# Prompt 6: Format-Guided with Sample Answer Structure\n",
    "prompt_6 = (\n",
    "    \"Describe using format - Damage Type: ___; Affected Part: ___; Severity: ___; Notes: ___\"\n",
    ")\n",
    "output_6 = run_vlm_inference(prompt_6, image_index=0, df=df)\n",
    "\n",
    "\n",
    "inference_outputs = [output_1, output_2, output_3, output_4, output_5, output_6]\n",
    "ground_truths = df.iloc[0]['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_cosine_similarity(pred, ref):\n",
    "    embeddings = sbert_model.encode([pred, ref])\n",
    "    return float(cosine_similarity([embeddings[0]], [embeddings[1]])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def compute_meteor(pred, ref):\n",
    "    return float(meteor_score([word_tokenize(ref)], word_tokenize(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.cider.cider import Cider\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "def compute_cider(pred, ref):\n",
    "    pred_dict = {\"0\": [pred]}\n",
    "    ref_dict = {\"0\": [ref]}\n",
    "\n",
    "    # write to temp files\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w+\", delete=False) as pred_file, \\\n",
    "         tempfile.NamedTemporaryFile(mode=\"w+\", delete=False) as ref_file:\n",
    "\n",
    "        json.dump(pred_dict, pred_file)\n",
    "        json.dump(ref_dict, ref_file)\n",
    "        pred_file.flush()\n",
    "        ref_file.flush()\n",
    "\n",
    "        scorer = Cider()\n",
    "        score, _ = scorer.compute_score(ref_dict, pred_dict)\n",
    "\n",
    "    os.remove(pred_file.name)\n",
    "    os.remove(ref_file.name)\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def compute_spice_like(pred, ref):\n",
    "    pred_nouns = {word for word, pos in pos_tag(word_tokenize(pred)) if pos.startswith(\"NN\")}\n",
    "    ref_nouns = {word for word, pos in pos_tag(word_tokenize(ref)) if pos.startswith(\"NN\")}\n",
    "\n",
    "    intersection = len(pred_nouns & ref_nouns)\n",
    "    union = len(pred_nouns | ref_nouns) or 1\n",
    "    return round(intersection / union, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_inference_metrics(pred, ref):\n",
    "    return {\n",
    "        \"cosine_similarity\": compute_cosine_similarity(pred, ref),\n",
    "        \"meteor\": compute_meteor(pred, ref),\n",
    "        \"cider\": compute_cider(pred, ref),\n",
    "        \"spice_proxy\": compute_spice_like(pred, ref),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621aca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for i, gen in enumerate(inference_outputs):\n",
    "    print(f\"\\nPrompt {i+1} Output:\\n{gen}\\nReference:\\n{ground_truths}\")\n",
    "    scores = evaluate_inference_metrics(gen, ground_truths)\n",
    "    all_scores.append(scores)\n",
    "\n",
    "import pandas as pd\n",
    "score_df = pd.DataFrame(all_scores, index=[f\"Prompt {i+1}\" for i in range(6)])\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
