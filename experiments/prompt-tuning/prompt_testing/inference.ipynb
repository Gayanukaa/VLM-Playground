{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea56a6",
   "metadata": {},
   "source": [
    "# Flickr30K load test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef188d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from prompt_inference_utils import evaluate_batch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "with open('/workspace/data/dataset_flickr30k.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "image_entries = json_data['images']\n",
    "test_filenames = [image['filename'] for image in image_entries if image['split'] == 'test'][:50]\n",
    "\n",
    "flickr30k_test = load_dataset(\"nlphuji/flickr30k\", split=\"test\")\n",
    "test_dataset = flickr30k_test.filter(lambda example: example['filename'] in test_filenames)\n",
    "\n",
    "print(\"Filtered test Dataset:\")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb764e",
   "metadata": {},
   "source": [
    "# CarDD test imageset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fcbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from inference_utils import evaluate_prompt\n",
    "import pandas as pd\n",
    "from load_dataframe import create_image_caption_dataset\n",
    "from prompt_inference_utils import evaluate_batch\n",
    "import json\n",
    "\n",
    "image_folder = \"/workspace/data/filtered_images\"\n",
    "captions_json = \"/workspace/data/merged_output.json\"\n",
    "\n",
    "test_dataset = create_image_caption_dataset(image_folder, captions_json)\n",
    "print(test_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list_1 = [\"Describe this image\", \"An image of ...\"]\n",
    "prompt_list_2 = [\"Describe this image\", \"An image of ...\"]\n",
    "prompts_total_list = [prompt_list_1, prompt_list_2]\n",
    "samples = [10, 2]\n",
    "\n",
    "# Set this to false for the CarDD dataset\n",
    "multiple_refs = True\n",
    "\n",
    "dfs = evaluate_batch(prompts_total_list, test_dataset, samples, multiple_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, df in enumerate(dfs, start=1):\n",
    "#    filename = f\"prompt{i}.csv\"\n",
    "#    df.to_csv(filename, index=False)\n",
    "#    print(f\"âœ… Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d556a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dfs, start=1):\n",
    "    avg_cider = df[\"CIDEr\"].mean()\n",
    "    avg_spice = df[\"SPICE\"].mean()\n",
    "    avg_meteor = df[\"METEOR\"].mean()\n",
    "    avg_cos_sim = df[\"semantic_similarity\"].mean()\n",
    "\n",
    "    print(f\"Prompt{i}: CIDEr={avg_cider:.4f}, SPICE={avg_spice:.4f}, METEOR={avg_meteor:.4f}, CosineSim={avg_cos_sim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
