{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key: str | None = os.getenv(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_url = 'https://openrouter.ai/api/v1/chat/completions'\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Image Captioning (Descriptive Ability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742623102-RqMpuggLG26LfPhv5vDq\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742623102,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Based on the image, the farmer appears to be **harvesting wheat**. \\n\\nHere's what points to that conclusion:\\n\\n*   **Ripe Wheat Field:** The field is full of mature wheat plants, ready for harvest.\\n*   **Tractor with Cutting Attachment:** The tractor has what looks like a header attachment (likely a combine harvester head) positioned over the wheat field. This is used to cut and gather the wheat.\\n*   **Farmer's Position:** The farmer is seated in the tractor, presumably operating it to harvest the crop.\\n\\n\\n\\nLet me know if you would like to analyze anything else in the image!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 279,\n",
      "        \"completion_tokens\": 131,\n",
      "        \"total_tokens\": 410\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture1.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'What is the farmer doing in the image?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742623124-NvtaiJYzENtn6Dk8RQk2\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742623124,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's a detailed description of the background in the image:\\n\\n**Overall Impression:** The background strongly contributes to a warm, rural, and golden atmosphere. It showcases a typical agricultural landscape, bathed in either a sunset or sunrise light.\\n\\n**Key Elements:**\\n\\n*   **Fields:** The dominant feature of the background is a vast field of ripe wheat or a similar grain. The stalks appear golden and dense, stretching far into the distance.\\n*   **Trees:** A line of trees is visible in the background, bordering the field. They're somewhat blurred due to distance and shallow depth of field, but appear to be mature trees with green foliage. The placement of the trees behind add to a natural, rural vista.\\n*   **Sky:** Above the trees and the golden fields, is a sky awash in warm colors. It's predominantly yellow and orange, suggesting either a sunset or sunrise. There are subtle gradations of color within the sky, implying diffused light. \\n*   **Atmospheric Haze:** Slight haze or dust is present, which softens the details of the distant elements and intensifies the golden glow. It lends a sense of depth and distance to the scene.\\n\\n**Overall Tone:** The background establishes a scene of peacefulness, hard work, and the abundance of the harvest. The warm, golden light adds a pleasant and inviting quality.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 279,\n",
      "        \"completion_tokens\": 282,\n",
      "        \"total_tokens\": 561\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture1.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'Describe the background of the image in detail.'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Visual Question Answering (VQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742623163-JRNBgHZr7bQaaBd5paeO\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742623163,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"\\nBased on the image, the child's raincoat is **yellow**.\\n\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 18,\n",
      "        \"completion_tokens\": 17,\n",
      "        \"total_tokens\": 35\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture2.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'What color is the child\\'s raincoat?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634047-3BKCH9PhU2yUhscvaE56\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634047,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Based on the image, the child is definitively **not playing alone**. There are two dogs nearby who appear to be playing with the child. They are both wearing raincoats, and the child is also wearing a raincoat, suggesting they are all enjoying the rainy weather together.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 285,\n",
      "        \"completion_tokens\": 55,\n",
      "        \"total_tokens\": 340\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture2.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'Is the child in the image playing alone or is there an animal nearby?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Object detection and Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634089-z03GUmeIuQV2t6Bqng8h\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634089,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's a breakdown of the distinct objects I can identify on the desk from the image:\\n\\n1. **MacBook (x2):** Two laptops are on the desk.\\n2. **Plant in Pot:** A vibrant green and red plant in a terracotta pot.\\n3. **Spiral Notebook:** A notebook with handwritten notes.\\n4. **Coffee Cup:** A Starbucks coffee cup.\\n5. **Wooden Desk:** The surface itself.\\n6. **Window Shade:** To the left of the laptops.\\n7. **Window Shade:** to the right of the laptops. \\n8. **Window:** There's a discernible window through the shades.\\n9. **Wall:** The wall behind the desk and window. \\n\\nThat's a total of **9 distinct objects**. Let me know if you'd like me to look for anything else!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 281,\n",
      "        \"completion_tokens\": 180,\n",
      "        \"total_tokens\": 461\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture3.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'How many distinct objects can you identify on the desk?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634075-7eHciTpGSRuYRLdZtd3s\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634075,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's a breakdown of the electronic devices I can identify in the image:\\n\\n*   **Two MacBook laptops:**  There are two open MacBook laptops on the wooden table. One seems to be showing a CAD-like program, and the other is displaying a document or spreadsheet.\\n*   **A Starbucks cup:** The cup with the Starbucks logo is an indicator of a possible electronic payment device if the coffee was purchased with a card or phone.\\n\\n\\n\\nLet me know if you want me to look for anything else in the image!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 280,\n",
      "        \"completion_tokens\": 109,\n",
      "        \"total_tokens\": 389\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture3.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'Can you detect any electronic devices in the image?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Scene Understanding & Context Awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634121-tNyex1sfLZV177Jo3kgo\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634121,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Based on the image, the car should **stop**. Here's why:\\n\\n*   **Pedestrians in the Crosswalk:** There are multiple pedestrians already in the crosswalk and more waiting to cross. It's the driver's responsibility to yield to them.\\n*   **Traffic Signals:** It looks like there is a traffic light, and pedestrians are likely waiting for the \\\"walk\\\" signal.\\n*   **Pedestrian Ahead:** The person in the foreground appears to be about to enter the crosswalk.\\n\\n\\n\\nIt's crucial for the driver to prioritize the safety of pedestrians.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 281,\n",
      "        \"completion_tokens\": 123,\n",
      "        \"total_tokens\": 404\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture4.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'text', 'text': 'Should the car stop or continue moving in this image?'},\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742625799-5yUdHOD3Opno93MqmCel\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742625799,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Based on the image, the red traffic light indicates that **vehicles must stop**. This is a standard meaning of a red light across most places.\\n\\nHere's what we can see that confirms this:\\n\\n*   **The light is illuminated red:** This is the visual cue for drivers to halt.\\n*   **Cars are stopped:** The white car in the foreground is clearly stopped at the crosswalk.\\n\\n\\n\\nLet me know if you'd like me to analyze anything else in the picture!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 280,\n",
      "        \"completion_tokens\": 102,\n",
      "        \"total_tokens\": 382\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture4.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'What does the red traffic light indicate for vehicles?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Text-Image Matching (Multimodal Consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634258-ClQPDEYukfUIg8BAtXoi\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634258,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's the breakdown:\\n\\n*   **The image clearly shows a woman engrossed in a book outdoors.** She's sitting on a blanket and holding a book open, looking intently at the pages.\\n*   **There's no indication of soccer or any related activity.**\\n\\nTherefore, **(A) \\\"A woman enjoying a peaceful reading session outdoors\\\"** is the much better and accurate caption.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 303,\n",
      "        \"completion_tokens\": 85,\n",
      "        \"total_tokens\": 388\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture5.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'Which caption better describes the image: (A) \\\"A woman enjoying a peaceful reading session outdoors\\\" or (B) \\\"A woman playing soccer in the park\\\"?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634275-xllYXvV1h5uDcntlfn1j\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634275,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here are the elements in the image that indicate it's a sunny day:\\n\\n*   **Bright Lighting:** The image is generally well-lit, suggesting ample sunlight.\\n*   **Shadows:** Notice the distinct shadows cast by the woman and the trees behind her.  This indicates a strong light source (the sun).\\n*   **Warm Color Tone:** Although the image might be edited, there is a generally warm tone to the colors, which is typical of a sunny day.\\n*  **Clear Skies:** While we don't see the entire sky, the glimpse of the background suggests clear, blue skies.\\n\\n\\n\\nLet me know if you'd like me to analyze any other aspects of the image!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 283,\n",
      "        \"completion_tokens\": 148,\n",
      "        \"total_tokens\": 431\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture5.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'What elements in this image indicate that it is a sunny day?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Optical Character Recognition (OCR) & Text-in-Image Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742625842-HaBTL02i8r0MvC8uMf3h\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742625842,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"The main headline of the newspaper in the image is: **\\\"MEN WALK ON MOON\\\"**.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 279,\n",
      "        \"completion_tokens\": 21,\n",
      "        \"total_tokens\": 300\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture6.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'What is the main headline of the newspaper?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742625875-boCS2CchbsN0Xb7S4lE3\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742625875,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"The text on the newspaper clearly suggests a **historical event.**\\n\\nHere's why:\\n\\n*   **Headline:** \\\"MEN WALK ON MOON; ASTRONAUTS LAND ON PLAIN; COLLECT ROCKS, PLANT FLAG\\\" - This directly refers to the Apollo 11 moon landing, a documented occurrence in 1969.\\n*   **Newspaper Name:**  \\\"The New York Times\\\" - A real and reputable news organization.\\n*   **Image:** The image on the newspaper shows a photograph which is reminiscent of the iconic pictures taken during the moon landing.\\n\\nTherefore, the image and text work together to depict real, historical events rather than a fictional one.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 280,\n",
      "        \"completion_tokens\": 143,\n",
      "        \"total_tokens\": 423\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images\\Picture6.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'Does the text suggest a historical or fictional event?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Commonsense & Logical Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634449-n1H4BIe6u72fR8lm1gvp\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634449,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Okay, let's break down the situation depicted in the image.\\n\\n**Is it normal for a dog to wear glasses and read a newspaper?**\\n\\nNo, it's not normal. Here's why:\\n\\n*   **Dogs Don't Need Glasses:** Dogs have different vision than humans. They don't experience the need for corrective lenses like nearsightedness or farsightedness in the way we do. While dogs *can* have eye conditions (like cataracts or glaucoma), these typically require different kinds of veterinary treatment and don't necessitate glasses.\\n*   **Dogs Can't Read:** Even if a dog had perfect eyesight, they wouldn't be able to interpret the symbols and language in a newspaper. Dogs perceive the world primarily through scent and movement, and they don't have the cognitive ability to decode written text.\\n*   **It's an Anthropomorphic Representation:** The image is a fun, whimsical depiction of human-like qualities being applied to animals (anthropomorphism). It's meant to be humorous or charming, not realistic.\\n\\n**Why the Image Exists and is Popular**\\n\\n*   **Humor/Cute Factor:** The image is inherently funny because of the contrast between the dog's natural behavior and the human activities it's mimicking.\\n*   **Appealing to Pet Lovers:** Many people love to imagine their pets having human personalities and doing human things. The image taps into this sentiment.\\n\\n\\n\\n**In short**: The image is a playful fantasy and not a depiction of something that happens in the real world.\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 289,\n",
      "        \"completion_tokens\": 324,\n",
      "        \"total_tokens\": 613\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images/Picture7.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'Is it normal for a dog to wear glasses and read a newspaper? Why or why not?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634481-IC8hbgMtLA11E5xxAhjE\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634481,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's what's unusual about the scene:\\n\\n*   **Animals Reading a Newspaper:** The most striking thing is that a dog wearing glasses is holding a newspaper and appears to be reading it, with a cat looking on! This is a clear anthropomorphism - attributing human traits to animals.\\n*   **The Newspaper Headline:** The newspaper headline says \\\"REESEBESY\\\" which is playfully nonsensical.\\n\\n\\n\\nIt's a charming and whimsical image!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 277,\n",
      "        \"completion_tokens\": 96,\n",
      "        \"total_tokens\": 373\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images/Picture7.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'What is unusual about this scene?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Zero-Shot & Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634535-InRN9V8W6TWojfrSXNpp\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634535,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Here's a breakdown of the object in the image and its differences from a real cat:\\n\\n**What it is:**\\n\\nThe image depicts a **robotic cat**, also sometimes referred to as a \\\"steampunk cat\\\" or \\\"mechanical feline.\\\" It's a whimsical fusion of a domestic cat and intricate, clockwork-like machinery.\\n\\n**How it differs from a real cat:**\\n\\nHere's a list of key differences, categorized:\\n\\n*   **Physical Structure:**\\n    *   **Materials:** Instead of fur, bones, and organic tissue, this \\\"cat\\\" is made of metal (likely brass or bronze, given the color and aesthetic), gears, pipes, and other mechanical components.\\n    *   **Skeletal/Muscular System:** A real cat has a complex skeletal and muscular system for movement. This robotic cat relies on intricate levers, pistons, and electric motors (likely unseen within the design) for its motion.\\n    *   **Appendages:** The paws and legs are obviously artificial and metallic, with visible joints and mechanisms.\\n    *   **Rigidity:**  Real cats are flexible and can manipulate their bodies in numerous ways. The mechanical cat is likely more rigid, though the clever design gives the illusion of flexibility.\\n*   **Biological vs. Mechanical Functions:**\\n    *   **Breathing:** A real cat breathes using lungs.  This mechanical cat doesn't need to breathe.\\n    *   **Digestion/Elimination:** Cats consume food and eliminate waste. This robotic cat likely doesn't.\\n    *   **Senses:** Real cats have natural senses (sight, hearing, smell, taste, touch) adapted for survival. This mechanical cat might have sensors (cameras, microphones, etc.) that mimic certain senses, but not in the same biological way.\\n    *   **Reproduction/Growth:** Cats reproduce and grow physically. This mechanical cat is manufactured.\\n*   **Texture & Appearance:**\\n    *   **Fur vs. Metal:** The texture is entirely different. A real cat has soft, warm fur. This device has a cold, metallic feel.\\n    *   **Expression:**  While the artist has captured a cat-like expression (particularly the eyes), a real cat\\u2019s expressions are driven by complex emotions and muscle movements.\\n\\n\\n\\nLet me know if you'd like a deeper dive into a particular aspect!\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 285,\n",
      "        \"completion_tokens\": 494,\n",
      "        \"total_tokens\": 779\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images/Picture8.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'What is this object, and how does it differ from a real cat?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"gen-1742634573-2Rk2I9RAC4HEtpM5t0jk\",\n",
      "    \"provider\": \"Chutes\",\n",
      "    \"model\": \"google/gemma-3-12b-it\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1742634573,\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"native_finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"Okay, let's analyze the image of this steampunk-style robotic cat and guess its potential functions. Given its design, here are a few possibilities, broken down by likelihood and degree of complexity:\\n\\n**High Probability & Simpler Functions:**\\n\\n*   **Surveillance/Patrol:** This is the most likely. The focused gaze, sturdy build, and mechanical limbs suggest it's designed for movement and observation. It could be patrolling an area, monitoring security, or gathering information.  The steampunk aesthetic points to a past era where manual and observational tasks might be performed by specialized robots.\\n*   **Guardian/Companion:** The slightly endearing appearance (it still has a cat face!) alongside the robust build hints it could be a guardian or even a companion robot.  Protecting a person, property, or acting as a loyal mechanical friend.\\n*   **Search and Rescue (Small Areas):** It could be designed to navigate confined spaces or rubble, searching for small objects or even people. Its size and agility seem suited for this.\\n\\n**Medium Probability & More Complex Functions:**\\n\\n*   **Messenger/Courier:** The mechanical legs and sturdy frame allow for delivery of small but important items or messages. \\n*   **Data Collection/Sensor Platform:** All that gear suggests it might be carrying sensors (temperature, pressure, motion). It could be collecting environmental data or performing scientific measurements.  The steampunk design could tie into an era of exploration and measurement.\\n*   **Mechanical Pest Control:** While less endearing, the metal claws suggest it could have been used to protect crops or interiors from rodents or other pests.\\n\\n**Lower Probability & Very Complex Functions:**\\n\\n*   **Heavy Lifting/Manipulation (Small Scale):** The powerful legs and mechanical paws *could* indicate some capacity for lifting or manipulating small objects, but its overall design doesn't seem to strongly support this.\\n*   **Combat/Security (Limited):** It has a menacing look, but its function likely wouldn't be to fight. Instead, it might provide a deterrent or a very limited defense capability.\\n\\n**Design Elements Suggesting Function:**\\n\\n*   **Legs & Feet:** Clearly built for locomotion over rough terrain.\\n*   **Mechanical Body:** The extensive mechanical gear work supports that it provides functionality rather than just looking robotic.\\n*   **Head & Eyes:** The cat's expression and focus suggest observation and awareness. Its sharp eyes imply that it's capable of precise targeting.\\n*   **Overall Steampunk Aesthetic:** Suggests a mechanical functionality that is focused on specific tasks.\\n\\n\\n\\n**My overall best guess, based on the image, is that this robotic cat is primarily designed for surveillance and patrol, possibly augmented with some sensor collection capabilities.**\\n\\nDo you have any other details about the image that might help narrow down the possibilities?\",\n",
      "                \"refusal\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 286,\n",
      "        \"completion_tokens\": 580,\n",
      "        \"total_tokens\": 866\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images/Picture8.jpg'\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "data = {\n",
    "    'model': 'google/gemma-3-12b-it:free',\n",
    "    'messages': [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{image_base64}'}},\n",
    "                {'type': 'text', 'text': 'Based on the image, can you guess the possible functions of this robotic cat?'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
