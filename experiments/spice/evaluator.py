import os
import json
import subprocess
from nltk import download as nltk_download
from nltk.corpus import wordnet

# Ensure WordNet is available
nltk_download('wordnet', quiet=True)
nltk_download('omw-1.4', quiet=True)

BASE_DIR  = os.path.dirname(__file__)
SPICE_JAR = os.path.join(BASE_DIR, 'SPICE-1.0', 'spice-1.0.jar')

def _run_spice(input_json: str, output_json: str, detailed: bool, log_fn=None) -> dict:
    if not os.path.isfile(SPICE_JAR):
        raise FileNotFoundError(f"SPICE jar not found at {SPICE_JAR}")

    cmd = ['java', '-Xmx8G', '-jar', SPICE_JAR, input_json]
    if detailed:
        cmd.append('-detailed')
    cmd += ['-out', output_json, '-silent']

    if log_fn:
        log_fn(f"> {' '.join(cmd)}")

    # Stream output line by line
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    for line in proc.stdout:
        if log_fn:
            log_fn(line.rstrip())
    ret = proc.wait()
    if ret != 0:
        raise RuntimeError(f"SPICE exited {ret}")

    # Load JSON
    with open(output_json, 'r') as f:
        results = json.load(f)
    if not isinstance(results, list) or len(results) != 1:
        raise ValueError(f"Unexpected SPICE output: {results}")
    return results[0]

def _wordnet_match(w1: str, w2: str) -> bool:
    if w1 == w2:
        return True
    syns1 = {l.name() for s in wordnet.synsets(w1) for l in s.lemmas()}
    syns2 = {l.name() for s in wordnet.synsets(w2) for l in s.lemmas()}
    return bool(syns1 & syns2)

def precision_recall_f1(hyp_tups: list, ref_tups: list) -> tuple:
    matched, used = 0, set()
    for h in hyp_tups:
        for i, r in enumerate(ref_tups):
            if i in used: continue
            if all(_wordnet_match(str(h[j]), str(r[j])) for j in range(len(h))):
                matched += 1
                used.add(i)
                break
    p = matched / len(hyp_tups) if hyp_tups else 0.0
    r = matched / len(ref_tups) if ref_tups else 0.0
    f1 = (2*p*r/(p+r)) if (p+r) else 0.0
    return p, r, f1

class SpiceEvaluator:
    def __init__(self, cache_dir='spice_cache'):
        self.cache_dir = os.path.join(BASE_DIR, cache_dir)
        os.makedirs(self.cache_dir, exist_ok=True)

    def evaluate(self, candidate: str, references: list, log_fn=None) -> dict:
        if log_fn: log_fn("ðŸ”§ Preparing input JSON...")
        inp = os.path.join(self.cache_dir, 'inp.json')
        with open(inp, 'w') as f:
            json.dump([{"image_id":0, "test":candidate, "refs":references}], f)
        if log_fn: log_fn(f"âœ… Wrote input to {inp}")

        outp = os.path.join(self.cache_dir, 'out.json')
        if log_fn: log_fn("ðŸš€ Running SPICE...")
        result = _run_spice(inp, outp, detailed=True, log_fn=log_fn)
        if log_fn: log_fn(f"âœ… SPICE output in {outp}")

        # Extract SPICE metrics
        sc = result['scores']['All']
        sp_p = sc.get('pr', 0.0)
        sp_r = sc.get('re', 0.0)
        sp_f = sc.get('f', 0.0)
        if log_fn: log_fn(f"ðŸ“Š SPICE -> Precision: {sp_p:.3f}, Recall: {sp_r:.3f}, F1: {sp_f:.3f}")

        # Extract tuples
        test_block = result.get('test_tuples', [])
        ref_block  = result.get('ref_tuples', [])
        test_tups  = [e['tuple'] for e in test_block]
        ref_tups   = [e['tuple'] for e in ref_block]
        if log_fn: log_fn(f"ðŸŒ³ Parsed {len(test_tups)} test tuples and {len(ref_tups)} reference tuples")

        # Compute tuple-level binary F1 (optional)
        p, r, bf1 = precision_recall_f1(test_tups, ref_tups)
        if log_fn: log_fn(f"âœ… Tuple-level binary F1: {bf1:.3f}")

        return {
            'spice_precision': sp_p,
            'spice_recall':    sp_r,
            'spice_f1':        sp_f,
            'precision':       p,
            'recall':          r,
            'binary_f1':       bf1,
            'test_tuples':     test_tups,
            'ref_tuples':      ref_tups
        }
